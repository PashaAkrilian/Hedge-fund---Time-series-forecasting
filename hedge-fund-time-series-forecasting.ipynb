{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105581,"databundleVersionId":15271735,"sourceType":"competition"}],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Data & Initial Inspection","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 1 — Load Data & Initial Inspection (ONE CELL, Kaggle)\n# Paths (given):\n#   /kaggle/input/ts-forecasting/train.parquet\n#   /kaggle/input/ts-forecasting/test.parquet\n# Output globals:\n#   df_train, df_test, TARGET_COL, ID_COL, WEIGHT_COL, TIME_COL, CAT_COLS, FEAT_COLS, NUM_COLS\n# ============================================================\n\nimport os, gc\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\npd.set_option(\"display.max_columns\", 200)\npd.set_option(\"display.width\", 200)\n\nTRAIN_PATH = Path(\"/kaggle/input/ts-forecasting/train.parquet\")\nTEST_PATH  = Path(\"/kaggle/input/ts-forecasting/test.parquet\")\n\nfor p in [TRAIN_PATH, TEST_PATH]:\n    if not p.exists():\n        raise FileNotFoundError(f\"Missing file: {p}\")\n\nprint(\"Loading parquet...\")\ndf_train = pd.read_parquet(TRAIN_PATH)\ndf_test  = pd.read_parquet(TEST_PATH)\n\nprint(\"\\n==================== BASIC SHAPES ====================\")\nprint(\"train:\", df_train.shape)\nprint(\"test :\", df_test.shape)\n\nprint(\"\\n==================== COLUMNS ====================\")\nprint(\"train cols:\", len(df_train.columns))\nprint(\"test  cols:\", len(df_test.columns))\n\n# ---- Standard column names (from competition description)\nID_COL     = \"id\"\nWEIGHT_COL = \"weight\"\nTIME_COL   = \"ts_index\"\nBASE_CATS  = [\"code\", \"sub_code\", \"sub_category\", \"horizon\"]\n\n# ---- Detect target column (must exist in train, not in test)\ntrain_only_cols = [c for c in df_train.columns if c not in df_test.columns]\n# remove any obviously non-target extras if present\ntrain_only_cols = [c for c in train_only_cols if c not in [ID_COL, WEIGHT_COL, TIME_COL] + BASE_CATS]\n\n# Prefer common target names if present\npreferred_names = [\"target\", \"y\", \"label\", \"value\", \"prediction_target\"]\nTARGET_COL = None\nfor name in preferred_names:\n    if name in df_train.columns and name not in df_test.columns:\n        TARGET_COL = name\n        break\n\nif TARGET_COL is None:\n    # If exactly one train-only col remains -> pick it\n    if len(train_only_cols) == 1:\n        TARGET_COL = train_only_cols[0]\n    else:\n        # Fallback: pick numeric column(s) absent in test\n        cand = []\n        for c in [c for c in df_train.columns if c not in df_test.columns]:\n            if pd.api.types.is_numeric_dtype(df_train[c]):\n                cand.append(c)\n        # remove known non-target just in case\n        cand = [c for c in cand if c not in [WEIGHT_COL, TIME_COL]]\n        if len(cand) == 1:\n            TARGET_COL = cand[0]\n        elif len(cand) > 1:\n            # pick the one with highest variance (usually the true target)\n            vars_ = {c: float(np.nanvar(df_train[c].to_numpy(dtype=np.float64))) for c in cand}\n            TARGET_COL = sorted(vars_.items(), key=lambda kv: kv[1], reverse=True)[0][0]\n            print(\"\\n[WARN] Multiple numeric train-only cols found; picked by variance:\", TARGET_COL)\n        else:\n            # last resort: if any train-only cols exist, pick the first\n            if len([c for c in df_train.columns if c not in df_test.columns]) > 0:\n                TARGET_COL = [c for c in df_train.columns if c not in df_test.columns][0]\n                print(\"\\n[WARN] Could not confidently detect target; picked first train-only col:\", TARGET_COL)\n            else:\n                raise RuntimeError(\"Could not detect target column (no train-only columns).\")\n\nprint(\"\\n==================== KEY COLS ====================\")\nprint(\"ID_COL     :\", ID_COL, \"| exists:\", ID_COL in df_train.columns and ID_COL in df_test.columns)\nprint(\"TIME_COL   :\", TIME_COL, \"| exists:\", TIME_COL in df_train.columns and TIME_COL in df_test.columns)\nprint(\"WEIGHT_COL :\", WEIGHT_COL, \"| exists:\", WEIGHT_COL in df_train.columns and WEIGHT_COL in df_test.columns)\nprint(\"TARGET_COL :\", TARGET_COL, \"| exists in train:\", TARGET_COL in df_train.columns, \"| exists in test:\", TARGET_COL in df_test.columns)\n\n# ---- Determine categorical columns that exist\nCAT_COLS = [c for c in BASE_CATS if c in df_train.columns]\n# Also include any object/category cols (excluding id)\nfor c in df_train.columns:\n    if c == ID_COL or c == TARGET_COL:\n        continue\n    if pd.api.types.is_object_dtype(df_train[c]) or str(df_train[c].dtype).startswith(\"category\"):\n        if c not in CAT_COLS:\n            CAT_COLS.append(c)\n\n# ---- Determine feature columns (exclude id, target, weight; keep everything else)\nEXCLUDE = set([ID_COL, TARGET_COL, WEIGHT_COL])\nFEAT_COLS = [c for c in df_train.columns if c not in EXCLUDE]\n\n# ---- Determine numeric feature columns\nNUM_COLS = [c for c in FEAT_COLS if pd.api.types.is_numeric_dtype(df_train[c]) and c != WEIGHT_COL]\n\nprint(\"\\n==================== QUICK CHECKS ====================\")\n# id uniqueness\nif ID_COL in df_train.columns:\n    print(\"train id unique:\", df_train[ID_COL].nunique(), \"/\", len(df_train))\nif ID_COL in df_test.columns:\n    print(\"test  id unique:\", df_test[ID_COL].nunique(), \"/\", len(df_test))\n\n# ts_index ranges\nif TIME_COL in df_train.columns and TIME_COL in df_test.columns:\n    print(\"train ts_index range:\", int(df_train[TIME_COL].min()), \"->\", int(df_train[TIME_COL].max()))\n    print(\"test  ts_index range:\", int(df_test[TIME_COL].min()),  \"->\", int(df_test[TIME_COL].max()))\n\n# horizon distribution (small peek)\nif \"horizon\" in df_train.columns:\n    print(\"\\ntrain horizon value counts (top):\")\n    print(df_train[\"horizon\"].value_counts(dropna=False).head(10))\nif \"horizon\" in df_test.columns:\n    print(\"\\ntest horizon value counts (top):\")\n    print(df_test[\"horizon\"].value_counts(dropna=False).head(10))\n\n# missingness summary (top 15 columns)\nprint(\"\\n==================== MISSING VALUES (TOP) ====================\")\nmiss_train = df_train.isna().mean().sort_values(ascending=False)\nmiss_test  = df_test.isna().mean().sort_values(ascending=False)\nprint(\"train missing rate top 15:\")\nprint(miss_train.head(15))\nprint(\"\\ntest missing rate top 15:\")\nprint(miss_test.head(15))\n\n# target stats\nif TARGET_COL in df_train.columns and pd.api.types.is_numeric_dtype(df_train[TARGET_COL]):\n    y = df_train[TARGET_COL].to_numpy(dtype=np.float64)\n    print(\"\\n==================== TARGET STATS ====================\")\n    print(\"count:\", np.isfinite(y).sum(), \" / \", len(y))\n    print(\"mean :\", float(np.nanmean(y)))\n    print(\"std  :\", float(np.nanstd(y)))\n    print(\"min  :\", float(np.nanmin(y)))\n    print(\"p1   :\", float(np.nanpercentile(y, 1)))\n    print(\"p50  :\", float(np.nanpercentile(y, 50)))\n    print(\"p99  :\", float(np.nanpercentile(y, 99)))\n    print(\"max  :\", float(np.nanmax(y)))\n\n# weight stats (reminder: do NOT use as feature)\nif WEIGHT_COL in df_train.columns and pd.api.types.is_numeric_dtype(df_train[WEIGHT_COL]):\n    w = df_train[WEIGHT_COL].to_numpy(dtype=np.float64)\n    print(\"\\n==================== WEIGHT STATS (NOT A FEATURE) ====================\")\n    print(\"mean :\", float(np.nanmean(w)))\n    print(\"min  :\", float(np.nanmin(w)))\n    print(\"p50  :\", float(np.nanpercentile(w, 50)))\n    print(\"p99  :\", float(np.nanpercentile(w, 99)))\n    print(\"max  :\", float(np.nanmax(w)))\n\nprint(\"\\n==================== FEATURE SET SUMMARY ====================\")\nprint(\"CAT_COLS :\", CAT_COLS)\nprint(\"NUM_COLS :\", len(NUM_COLS), \"(numeric features excluding weight/target/id)\")\nprint(\"FEAT_COLS:\", len(FEAT_COLS), \"(all usable columns excluding target and weight; id excluded)\")\n\nprint(\"\\n==================== HEAD (train) ====================\")\ndisplay(df_train.head(3))\nprint(\"\\n==================== HEAD (test) ====================\")\ndisplay(df_test.head(3))\n\ngc.collect()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sanity Checks & Leakage Rules Setup","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 2 — Sanity Checks & Leakage Rules Setup (ONE CELL, Kaggle)\n# Assumes STAGE 1 already ran and created:\n#   df_train, df_test, TARGET_COL, ID_COL, TIME_COL, CAT_COLS, FEAT_COLS\n# This stage:\n# - Validates schema and uniqueness\n# - Confirms time ordering (train < test)\n# - Sets leakage-safe column lists\n# - Defines \"DO NOT USE\" columns and lightweight guards\n# Outputs/Globals:\n#   DO_NOT_USE_COLS, FEATURE_COLS_NUM, FEATURE_COLS_CAT, FEATURE_COLS_ALL\n#   TRAIN_MAX_TS, TEST_MIN_TS, TEST_MAX_TS\n# ============================================================\n\nimport gc, re\nimport numpy as np\nimport pandas as pd\n\n# ----------------------------\n# 0) Require STAGE 1 globals\n# ----------------------------\nneed = [\"df_train\",\"df_test\",\"TARGET_COL\",\"ID_COL\",\"TIME_COL\",\"CAT_COLS\",\"FEAT_COLS\"]\nfor k in need:\n    if k not in globals():\n        raise RuntimeError(f\"Missing global '{k}'. Jalankan STAGE 1 dulu.\")\n\nassert isinstance(df_train, pd.DataFrame) and isinstance(df_test, pd.DataFrame)\n\n# ----------------------------\n# 1) Core column existence\n# ----------------------------\nmust_in_train = [ID_COL, TIME_COL, TARGET_COL]\nmust_in_test  = [ID_COL, TIME_COL]\nfor c in must_in_train:\n    if c not in df_train.columns:\n        raise RuntimeError(f\"Train missing required column: {c}\")\nfor c in must_in_test:\n    if c not in df_test.columns:\n        raise RuntimeError(f\"Test missing required column: {c}\")\n\n# Optional: weight may exist only in train\nWEIGHT_COL = \"weight\"\nhas_weight_train = WEIGHT_COL in df_train.columns\nhas_weight_test  = WEIGHT_COL in df_test.columns\n\nprint(\"==================== STAGE 2: SANITY ====================\")\nprint(\"Has weight in train:\", has_weight_train, \"| in test:\", has_weight_test)\nif has_weight_test:\n    print(\"[WARN] weight also exists in test. We'll still exclude it as a feature.\")\nprint(\"Target col:\", TARGET_COL)\n\n# ----------------------------\n# 2) ID uniqueness checks\n# ----------------------------\nntr = len(df_train)\nnts = len(df_test)\n\nnuniq_tr = df_train[ID_COL].nunique(dropna=False)\nnuniq_ts = df_test[ID_COL].nunique(dropna=False)\n\nif nuniq_tr != ntr:\n    dup = df_train[df_train[ID_COL].duplicated(keep=False)][ID_COL].head(10).tolist()\n    raise RuntimeError(f\"Train id not unique: {nuniq_tr}/{ntr}. Example dups: {dup}\")\nif nuniq_ts != nts:\n    dup = df_test[df_test[ID_COL].duplicated(keep=False)][ID_COL].head(10).tolist()\n    raise RuntimeError(f\"Test id not unique: {nuniq_ts}/{nts}. Example dups: {dup}\")\n\nintersect = np.intersect1d(df_train[ID_COL].values, df_test[ID_COL].values)\nif len(intersect) > 0:\n    print(f\"[WARN] Train/Test share {len(intersect)} ids (unexpected). Example:\", intersect[:5])\n\nprint(\"ID uniqueness: OK\")\n\n# ----------------------------\n# 3) Time ordering checks\n# ----------------------------\nif not pd.api.types.is_integer_dtype(df_train[TIME_COL]) and not pd.api.types.is_numeric_dtype(df_train[TIME_COL]):\n    raise RuntimeError(f\"{TIME_COL} in train is not numeric.\")\nif not pd.api.types.is_integer_dtype(df_test[TIME_COL]) and not pd.api.types.is_numeric_dtype(df_test[TIME_COL]):\n    raise RuntimeError(f\"{TIME_COL} in test is not numeric.\")\n\nTRAIN_MAX_TS = int(np.nanmax(df_train[TIME_COL].values))\nTRAIN_MIN_TS = int(np.nanmin(df_train[TIME_COL].values))\nTEST_MIN_TS  = int(np.nanmin(df_test[TIME_COL].values))\nTEST_MAX_TS  = int(np.nanmax(df_test[TIME_COL].values))\n\nprint(\"Train ts_index range:\", TRAIN_MIN_TS, \"->\", TRAIN_MAX_TS)\nprint(\"Test  ts_index range:\", TEST_MIN_TS,  \"->\", TEST_MAX_TS)\n\n# Expect test period after train; allow small overlaps but flag loudly\nif TEST_MIN_TS <= TRAIN_MAX_TS:\n    print(\"[WARN] Test min ts_index <= Train max ts_index. Check competition rules / possible overlap.\")\nelse:\n    print(\"Time ordering (train -> test): OK (test starts after train).\")\n\n# ----------------------------\n# 4) Leakage rules + feature lists\n# ----------------------------\n# DO NOT USE columns as model input features:\n# - id, target, and weight (even if present in train/test)\nDO_NOT_USE_COLS = {ID_COL, TARGET_COL, WEIGHT_COL}\n\n# Basic categorical feature columns: from STAGE 1 CAT_COLS\nFEATURE_COLS_CAT = [c for c in CAT_COLS if c not in DO_NOT_USE_COLS and c in df_train.columns]\n\n# Numeric candidate features: all numeric columns except forbidden\nnumeric_cols = [c for c in df_train.columns if pd.api.types.is_numeric_dtype(df_train[c])]\nFEATURE_COLS_NUM = [c for c in numeric_cols if c not in DO_NOT_USE_COLS and c != TIME_COL]  # exclude ts_index by default\n\n# Full feature set used by \"tabular model\" baseline:\nFEATURE_COLS_ALL = FEATURE_COLS_CAT + FEATURE_COLS_NUM\n\nprint(\"\\n==================== FEATURE LISTS ====================\")\nprint(\"Categorical features:\", FEATURE_COLS_CAT)\nprint(\"Numeric features (excluding ts_index):\", len(FEATURE_COLS_NUM))\nprint(\"Total features:\", len(FEATURE_COLS_ALL))\n\n# ----------------------------\n# 5) Minimal integrity checks (dtypes, NaNs)\n# ----------------------------\n# Categorical columns should exist in both train and test\nmissing_cats_test = [c for c in FEATURE_COLS_CAT if c not in df_test.columns]\nif missing_cats_test:\n    raise RuntimeError(f\"Categorical cols missing in test: {missing_cats_test}\")\n\n# Numeric columns should exist in both train and test for inference\nmissing_num_test = [c for c in FEATURE_COLS_NUM if c not in df_test.columns]\nif missing_num_test:\n    # It's possible, but unusual; better fail fast\n    raise RuntimeError(f\"Numeric feature cols missing in test: {missing_num_test[:10]} ... ({len(missing_num_test)} total)\")\n\n# Check target has no NaN (important)\ny_nan = df_train[TARGET_COL].isna().mean()\nprint(\"\\nTarget NaN rate:\", float(y_nan))\nif y_nan > 0:\n    print(\"[WARN] Target has missing values. We'll need to drop or impute target rows later (usually drop).\")\n\n# Weight sanity (if exists)\nif has_weight_train:\n    w = df_train[WEIGHT_COL].to_numpy(dtype=np.float64)\n    w_nan = np.isnan(w).mean()\n    w_neg = np.mean(w < 0)\n    w_zero = np.mean(w == 0)\n    print(\"\\n==================== WEIGHT SANITY (TRAIN) ====================\")\n    print(\"NaN rate:\", float(w_nan), \"| negative rate:\", float(w_neg), \"| zero rate:\", float(w_zero))\n    if w_neg > 0:\n        print(\"[WARN] Found negative weights. Usually unexpected; we'll handle carefully later.\")\n\n# ----------------------------\n# 6) Leakage-safe reminders (printed)\n# ----------------------------\nprint(\"\\n==================== LEAKAGE RULES (REMINDER) ====================\")\nprint(\"- Do NOT use 'weight' as a feature (only as sample_weight).\")\nprint(\"- Any preprocessing (imputer/encoder/scaler) must be fit on TRAIN-FOLD only.\")\nprint(\"- Any time-based features (rolling/expanding) must be computed with shift(1) per group.\")\nprint(\"- Do NOT compute statistics using future rows (ts_index > t) for predicting time t.\")\nprint(\"- Avoid fitting encoders on train+test combined.\")\n\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Implement Official Metric","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 3 — Implement Official Metric (ONE CELL, Kaggle)\n# Assumes STAGE 1–2 already ran and created:\n#   df_train, df_test, TARGET_COL, ID_COL, TIME_COL, (optional) WEIGHT_COL=\"weight\"\n# This stage:\n# - Implements competition metric exactly\n# - Adds helpers to score arrays / dataframes\n# - Provides a few baselines sanity checks (zero, weighted-mean)\n# Outputs/Globals:\n#   weighted_rmse_score, score_df, score_arrays\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\n\n# ----------------------------\n# 0) Require minimal globals\n# ----------------------------\nneed = [\"df_train\", \"TARGET_COL\", \"ID_COL\", \"TIME_COL\"]\nfor k in need:\n    if k not in globals():\n        raise RuntimeError(f\"Missing global '{k}'. Jalankan STAGE 1–2 dulu.\")\n\nWEIGHT_COL = \"weight\"\nHAS_W = WEIGHT_COL in df_train.columns\n\n# ----------------------------\n# 1) Official metric (as provided by host)\n# ----------------------------\ndef _clip01(x: float) -> float:\n    return float(np.minimum(np.maximum(x, 0.0), 1.0))\n\ndef weighted_rmse_score(y_target, y_pred, w) -> float:\n    \"\"\"\n    Competition metric:\n      denom = sum(w * y^2)\n      ratio = sum(w * (y - yhat)^2) / denom\n      score = sqrt( 1 - clip01(ratio) )\n    \"\"\"\n    y_target = np.asarray(y_target, dtype=np.float64)\n    y_pred   = np.asarray(y_pred, dtype=np.float64)\n    w        = np.asarray(w, dtype=np.float64)\n\n    # Robust guards\n    if y_target.shape != y_pred.shape or y_target.shape != w.shape:\n        raise ValueError(f\"Shape mismatch: y={y_target.shape}, yhat={y_pred.shape}, w={w.shape}\")\n\n    # If denom is 0, the metric is ill-defined; return 0 safely\n    denom = np.sum(w * (y_target ** 2))\n    if not np.isfinite(denom) or denom <= 0:\n        return 0.0\n\n    ratio = np.sum(w * ((y_target - y_pred) ** 2)) / denom\n    clipped = _clip01(ratio)\n    val = 1.0 - clipped\n    # Numerical safety\n    val = max(val, 0.0)\n    return float(np.sqrt(val))\n\n# ----------------------------\n# 2) Convenience wrappers\n# ----------------------------\ndef score_arrays(y_true: np.ndarray, y_pred: np.ndarray, w: np.ndarray | None = None) -> float:\n    if w is None:\n        w = np.ones_like(y_true, dtype=np.float64)\n    return weighted_rmse_score(y_true, y_pred, w)\n\ndef score_df(df: pd.DataFrame, y_col: str, pred_col: str, w_col: str = \"weight\") -> float:\n    if w_col not in df.columns:\n        w = np.ones(len(df), dtype=np.float64)\n    else:\n        w = df[w_col].to_numpy(dtype=np.float64)\n    return weighted_rmse_score(df[y_col].to_numpy(dtype=np.float64),\n                               df[pred_col].to_numpy(dtype=np.float64),\n                               w)\n\n# ----------------------------\n# 3) Sanity check on train (simple baselines)\n# ----------------------------\nprint(\"==================== STAGE 3: OFFICIAL METRIC ====================\")\ny = df_train[TARGET_COL].to_numpy(dtype=np.float64)\n\nif HAS_W:\n    w = df_train[WEIGHT_COL].to_numpy(dtype=np.float64)\nelse:\n    w = np.ones_like(y, dtype=np.float64)\n\n# Baseline A: predict 0\npred0 = np.zeros_like(y, dtype=np.float64)\ns0 = weighted_rmse_score(y, pred0, w)\n\n# Baseline B: predict weighted mean (best constant under weighted MSE)\n# Use small epsilon to avoid /0\nw_sum = float(np.sum(w))\nc = float(np.sum(w * y) / (w_sum + 1e-18))\npredc = np.full_like(y, c, dtype=np.float64)\nsc = weighted_rmse_score(y, predc, w)\n\n# Baseline C: predict unweighted median (often robust)\nm = float(np.median(y))\npredm = np.full_like(y, m, dtype=np.float64)\nsm = weighted_rmse_score(y, predm, w)\n\nprint(f\"Using weight column: {HAS_W}\")\nprint(f\"Baseline (predict 0)            score = {s0:.6f}\")\nprint(f\"Baseline (predict w-mean {c:.6f}) score = {sc:.6f}\")\nprint(f\"Baseline (predict median {m:.6f}) score = {sm:.6f}\")\n\n# Some extra diagnostics about denom / ratio scaling\ndenom = float(np.sum(w * (y ** 2)))\nsse0  = float(np.sum(w * ((y - pred0) ** 2)))\nratio0 = sse0 / denom if denom > 0 else np.nan\nprint(\"\\nDiagnostics:\")\nprint(f\"denom sum(w*y^2) = {denom:.6e}\")\nprint(f\"ratio(predict0)  = {ratio0:.6f}  (should be ~1.0 => score~0)\")\n\nprint(\"\\nGlobals exported: weighted_rmse_score, score_arrays, score_df\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Time-based Validation Split","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 4 — Time-based Validation Split (Leakage-Safe CV) (ONE CELL, Kaggle)\n# Assumes STAGE 1–3 already ran and created:\n#   df_train, df_test, ID_COL, TIME_COL, TARGET_COL, CAT_COLS\n#\n# This stage:\n# - Builds walk-forward (blocked) time splits on ts_index\n# - Optionally makes splits per-horizon (recommended later), but here we create a global fold id\n# - Exports df_folds (id -> fold) and adds df_train[\"fold\"]\n#\n# Outputs/Globals:\n#   df_folds, df_train (with 'fold'), FOLD_CFG\n#   fold_boundaries (list of dicts)\n#\n# Notes:\n# - We use last portion of time as validation windows.\n# - Training for fold k uses all data with ts_index <= train_end\n#   Validation uses (train_end, valid_end] (strict future)\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\n\n# ----------------------------\n# 0) Require\n# ----------------------------\nneed = [\"df_train\", \"ID_COL\", \"TIME_COL\"]\nfor k in need:\n    if k not in globals():\n        raise RuntimeError(f\"Missing global '{k}'. Jalankan STAGE 1–3 dulu.\")\n\n# ----------------------------\n# 1) Config (tune-friendly)\n# ----------------------------\n# Number of folds (walk-forward windows)\nN_FOLDS = 4\n\n# Validation window size in ts_index units.\n# If None, we auto-set based on the last ~20% of time span.\nVALID_WINDOW = None  # e.g., 150, 200, 300; or None for auto\n\n# Gap between train_end and valid_start to reduce leakage via feature smoothing (usually 0 is OK)\nGAP = 0\n\n# Ensure we validate only on the tail period (mimics test)\nTAIL_FRACTION = 0.25  # last 25% of time used to place validation windows\n\n# Minimum validation samples per fold (fail-fast if too small)\nMIN_VALID_ROWS = 200_000\n\n# ----------------------------\n# 2) Prepare timeline\n# ----------------------------\nts = df_train[TIME_COL].to_numpy(dtype=np.int64)\nts_min = int(ts.min())\nts_max = int(ts.max())\nts_unique = np.unique(ts)\nts_unique.sort()\n\nspan = ts_max - ts_min + 1\ntail_start_ts = int(ts_min + (1.0 - TAIL_FRACTION) * span)\ntail_start_ts = max(tail_start_ts, ts_min)\n\n# determine VALID_WINDOW\nif VALID_WINDOW is None:\n    tail_span = ts_max - tail_start_ts + 1\n    # split tail into N_FOLDS windows, with a bit of buffer\n    VALID_WINDOW = max(1, int(np.floor(tail_span / (N_FOLDS + 0.5))))\nVALID_WINDOW = int(VALID_WINDOW)\n\n# Build fold boundaries ending at ts_max\n# Fold k validates on (train_end, valid_end], where valid_end increases toward ts_max\nfold_boundaries = []\nvalid_end = ts_max\nfor k in range(N_FOLDS-1, -1, -1):\n    valid_start = valid_end - VALID_WINDOW + 1\n    # ensure validation window stays in tail\n    if valid_start < tail_start_ts:\n        valid_start = tail_start_ts\n    train_end = valid_start - 1 - GAP\n    fold_boundaries.append({\n        \"fold\": k,\n        \"train_end\": int(train_end),\n        \"valid_start\": int(valid_start),\n        \"valid_end\": int(valid_end),\n        \"gap\": int(GAP),\n        \"valid_window\": int(valid_end - valid_start + 1),\n    })\n    valid_end = train_end  # next fold ends where this train ended\n\n# sort by fold id ascending\nfold_boundaries = sorted(fold_boundaries, key=lambda d: d[\"fold\"])\n\nFOLD_CFG = {\n    \"N_FOLDS\": N_FOLDS,\n    \"VALID_WINDOW\": VALID_WINDOW,\n    \"GAP\": GAP,\n    \"TAIL_FRACTION\": TAIL_FRACTION,\n    \"MIN_VALID_ROWS\": MIN_VALID_ROWS,\n    \"TIME_COL\": TIME_COL,\n    \"ID_COL\": ID_COL,\n}\n\nprint(\"==================== STAGE 4: TIME SPLITS ====================\")\nprint(\"Train ts_index:\", ts_min, \"->\", ts_max, \"| span:\", span)\nprint(\"Tail fraction:\", TAIL_FRACTION, \"| tail_start_ts:\", tail_start_ts)\nprint(\"N_FOLDS:\", N_FOLDS, \"| VALID_WINDOW:\", VALID_WINDOW, \"| GAP:\", GAP)\nprint(\"\\nFold boundaries:\")\nfor b in fold_boundaries:\n    print(f\"  fold {b['fold']}: train <= {b['train_end']} | valid ({b['valid_start']}, {b['valid_end']}] | window={b['valid_window']}\")\n\n# ----------------------------\n# 3) Assign folds\n# ----------------------------\n# Default fold = -1 (train-only, never used for validation)\nfold_arr = np.full(len(df_train), -1, dtype=np.int16)\n\nts_series = df_train[TIME_COL].to_numpy(dtype=np.int64)\n\nfor b in fold_boundaries:\n    k = b[\"fold\"]\n    vs, ve = b[\"valid_start\"], b[\"valid_end\"]\n    mask = (ts_series >= vs) & (ts_series <= ve)\n    fold_arr[mask] = k\n\ndf_train[\"fold\"] = fold_arr\n\n# df_folds mapping (id -> fold)\ndf_folds = df_train[[ID_COL, \"fold\"]].copy()\n\n# ----------------------------\n# 4) Diagnostics\n# ----------------------------\nvc = df_train[\"fold\"].value_counts(dropna=False).sort_index()\nprint(\"\\nFold row counts (fold=-1 means never validated):\")\nprint(vc)\n\n# Ensure each fold has enough validation rows\nok = True\nfor b in fold_boundaries:\n    k = b[\"fold\"]\n    n_valid = int((df_train[\"fold\"] == k).sum())\n    if n_valid < MIN_VALID_ROWS:\n        print(f\"[WARN] fold {k} valid rows too small: {n_valid} < {MIN_VALID_ROWS}\")\n        ok = False\nif ok:\n    print(\"Validation sizes: OK\")\n\n# Quick check: validation is strictly in the future of its training end\nviol = []\nfor b in fold_boundaries:\n    if not (b[\"train_end\"] < b[\"valid_start\"]):\n        viol.append(b[\"fold\"])\nif viol:\n    raise RuntimeError(f\"Invalid split: folds where train_end >= valid_start: {viol}\")\n\nprint(\"\\nGlobals exported: df_train['fold'], df_folds, FOLD_CFG, fold_boundaries\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Preparation & Weighting Strategy","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 5 — Feature Preparation & Weighting Strategy (UPGRADE v4: TS + LAG + CS) (ONE CELL, Kaggle)\n# - Adds leakage-safe time-series features (lags/diffs/gaps) and optional cross-sectional (same-ts) features\n# - Updates FEATURE_COLS_* so Stage 6/7 can use the engineered columns\n#\n# REQUIRE (from STAGE 1–4):\n#   df_train, df_test, TARGET_COL, ID_COL, TIME_COL, WEIGHT_COL\n#   df_train[\"fold\"]\n#\n# OUTPUT globals:\n#   df_train, df_test (with engineered features)\n#   SERIES_KEYS, FEATURE_COLS_CAT_ALL, FEATURE_COLS_NUM_ALL, FEATURE_COLS_ALL\n#   CAT_FEATURE_IDXS_ALL\n#   make_sample_weight(), fit_median_imputer(), apply_median_imputer()\n# ============================================================\n\nimport gc\nimport numpy as np\nimport pandas as pd\n\n# ----------------------------\n# 0) Config\n# ----------------------------\nUSE_TS_AS_FEATURE = True\nADD_AGE_FEATURE   = True\n\n# Feature engineering intensity (start moderate; scale up after you see CV lift)\nTOPK_NUM_FOR_FE   = 24          # how many numeric base features to expand\nLAGS              = (1, 2, 3)    # lag steps per series\nADD_DIFFS         = True\nADD_TIME_GAP      = True\n\n# Cross-sectional features at SAME ts_index (no future). Turn on after baseline FE works.\nADD_CS_STATS      = True        # z-score within (ts_index, horizon)\nADD_CS_RANK       = True        # rank(pct) within (ts_index, horizon)\nCS_BUCKET         = [TIME_COL, \"horizon\"]  # will auto-prune if column missing\n\n# Speed\nMAX_ROWS_FOR_CORR = 250_000\nRANDOM_STATE      = 42\n\n# ----------------------------\n# 1) Series keys + basic cols\n# ----------------------------\nbase_cats = [c for c in [\"code\", \"sub_code\", \"sub_category\", \"horizon\"] if c in df_train.columns]\nSERIES_KEYS = [c for c in [\"code\", \"sub_code\", \"sub_category\", \"horizon\"] if c in df_train.columns]\nTRAIN_MAX_TS = int(df_train[TIME_COL].max())\n\n# Cast categorical to category (RAM saver + CatBoost friendly)\nfor c in base_cats:\n    for df in (df_train, df_test):\n        if c in df.columns:\n            df[c] = df[c].astype(\"category\")\n\n# ----------------------------\n# 2) Pick numeric features to expand (TOPK) using weighted abs-corr (train-only)\n# ----------------------------\ndef _weighted_abs_corr(x: np.ndarray, y: np.ndarray, w: np.ndarray, eps: float = 1e-12) -> float:\n    m_w = np.sum(w) + eps\n    wx = np.sum(w * x) / m_w\n    wy = np.sum(w * y) / m_w\n    xc = x - wx\n    yc = y - wy\n    cov = np.sum(w * xc * yc) / m_w\n    vx = np.sum(w * xc * xc) / m_w\n    vy = np.sum(w * yc * yc) / m_w\n    denom = (np.sqrt(vx * vy) + eps)\n    return float(abs(cov / denom))\n\nHELPER_COLS = {\"fold\"}\nDROP_ALWAYS = {ID_COL, TARGET_COL, WEIGHT_COL} | HELPER_COLS\n\nnum_candidates = [c for c in df_train.columns\n                  if (c not in DROP_ALWAYS)\n                  and pd.api.types.is_numeric_dtype(df_train[c])]\n\n# Prefer anonymized features (feature_*)\nfeat_candidates = [c for c in num_candidates if str(c).startswith(\"feature_\")]\nif len(feat_candidates) >= 5:\n    num_candidates = feat_candidates\nnum_candidates = list(num_candidates)\n\ndf_corr = df_train[[*num_candidates, TARGET_COL, WEIGHT_COL, TIME_COL]].copy()\nif len(df_corr) > MAX_ROWS_FOR_CORR:\n    t = df_corr[TIME_COL].to_numpy(np.float64)\n    p = np.exp(-(TRAIN_MAX_TS - t) / 600.0)\n    p = p / (p.sum() + 1e-12)\n    take = np.random.RandomState(RANDOM_STATE).choice(len(df_corr), size=MAX_ROWS_FOR_CORR, replace=False, p=p)\n    df_corr = df_corr.iloc[take].copy()\n\ny = df_corr[TARGET_COL].to_numpy(np.float64)\nw_off = df_corr[WEIGHT_COL].to_numpy(np.float64)\nw_off = np.where(np.isfinite(w_off), w_off, 0.0)\nw_off = np.maximum(w_off, 0.0)\nif w_off.sum() <= 0:\n    w_off = np.ones_like(w_off)\n\ncorr_scores = []\nfor c in num_candidates:\n    x = df_corr[c].to_numpy(np.float64)\n    med = np.nanmedian(x)\n    x = np.where(np.isfinite(x), x, med)\n    corr_scores.append((_weighted_abs_corr(x, y, w_off), c))\n\ncorr_scores.sort(reverse=True, key=lambda kv: kv[0])\nTOPK = [c for _, c in corr_scores[:min(TOPK_NUM_FOR_FE, len(corr_scores))]]\n\nprint(\"Selected TOPK numeric features for FE:\", TOPK[:12], \"...\" if len(TOPK) > 12 else \"\")\ndel df_corr\ngc.collect()\n\n# ----------------------------\n# 3) Build engineered features on concatenated (train+test) in TIME order\n# ----------------------------\ndf_train[\"_is_train\"] = 1\ndf_test[\"_is_train\"] = 0\ndf_all = pd.concat([df_train, df_test], axis=0, ignore_index=True)\n\ndf_all[\"__row_id\"] = np.arange(len(df_all), dtype=np.int64)\nsort_cols = [c for c in SERIES_KEYS if c in df_all.columns] + [TIME_COL, \"__row_id\"]\ndf_all = df_all.sort_values(sort_cols, kind=\"mergesort\").reset_index(drop=True)\n\n# Time gap per series\nif ADD_TIME_GAP and len(SERIES_KEYS) > 0:\n    dt = df_all.groupby(SERIES_KEYS, sort=False)[TIME_COL].diff()\n    df_all[\"fe_dt\"] = dt.fillna(0).astype(np.float32)\n    df_all[\"fe_dt_clip\"] = np.clip(df_all[\"fe_dt\"].to_numpy(np.float32), 0.0, 50.0).astype(np.float32)\n\n# Age feature\nif USE_TS_AS_FEATURE and ADD_AGE_FEATURE:\n    df_all[\"fe_age\"] = (TRAIN_MAX_TS - df_all[TIME_COL].to_numpy(np.int32)).astype(np.int32)\n\n# Lags / diffs\nif len(SERIES_KEYS) > 0 and len(TOPK) > 0:\n    g = df_all.groupby(SERIES_KEYS, sort=False)\n    for f in TOPK:\n        for L in LAGS:\n            df_all[f\"fe_{f}_lag{L}\"] = g[f].shift(L).astype(np.float32)\n        if ADD_DIFFS:\n            lag1 = df_all[f\"fe_{f}_lag1\"].to_numpy(np.float32)\n            cur  = df_all[f].to_numpy(np.float32)\n            df_all[f\"fe_{f}_diff1\"] = (cur - lag1).astype(np.float32)\n\n# Cross-sectional (same ts_index) stats: z-score + rank pct within (ts_index, horizon)\nbucket = [c for c in CS_BUCKET if c in df_all.columns]\nif ADD_CS_STATS and len(bucket) > 0 and len(TOPK) > 0:\n    gb = df_all.groupby(bucket, sort=False)\n    for f in TOPK:\n        mu = gb[f].transform(\"mean\").astype(np.float32)\n        sd = gb[f].transform(\"std\").astype(np.float32)\n        df_all[f\"fe_{f}_z_{'_'.join(bucket)}\"] = ((df_all[f].astype(np.float32) - mu) / (sd + 1e-6)).astype(np.float32)\n\nif ADD_CS_RANK and len(bucket) > 0 and len(TOPK) > 0:\n    gb = df_all.groupby(bucket, sort=False)\n    for f in TOPK:\n        df_all[f\"fe_{f}_r_{'_'.join(bucket)}\"] = gb[f].rank(pct=True).astype(np.float32)\n\n# Restore original order\ndf_all = df_all.sort_values(\"__row_id\", kind=\"mergesort\").reset_index(drop=True)\n\n# Split back\ndf_train = df_all[df_all[\"_is_train\"] == 1].drop(columns=[\"_is_train\", \"__row_id\"]).reset_index(drop=True)\ndf_test  = df_all[df_all[\"_is_train\"] == 0].drop(columns=[\"_is_train\", \"__row_id\", TARGET_COL], errors=\"ignore\").reset_index(drop=True)\n\ngc.collect()\n\n# ----------------------------\n# 4) Finalize feature lists (include engineered columns)\n# ----------------------------\nFEATURE_COLS_CAT_ALL = [c for c in [\"code\", \"sub_code\", \"sub_category\", \"horizon\"] if c in df_train.columns]\n\nHELPER_COLS = {\"fold\"}\nDO_NOT_USE = {ID_COL, TARGET_COL, WEIGHT_COL} | HELPER_COLS\n\nFEATURE_COLS_NUM_ALL = [c for c in df_train.columns\n                        if (c not in DO_NOT_USE)\n                        and (c not in FEATURE_COLS_CAT_ALL)\n                        and pd.api.types.is_numeric_dtype(df_train[c])]\n\nFEATURE_COLS_ALL = FEATURE_COLS_CAT_ALL + FEATURE_COLS_NUM_ALL\nCAT_FEATURE_IDXS_ALL = list(range(len(FEATURE_COLS_CAT_ALL)))\n\n# ----------------------------\n# 5) Weight strategy (official weight * optional recency)\n# ----------------------------\ndef make_sample_weight(df: pd.DataFrame,\n                       use_recency: bool = True,\n                       tau: float = 600.0,\n                       clip_w_quantile: float | None = None,\n                       eps: float = 1e-12) -> np.ndarray:\n    w = df[WEIGHT_COL].to_numpy(dtype=np.float64)\n    if clip_w_quantile is not None:\n        q = float(np.nanquantile(w, clip_w_quantile))\n        if np.isfinite(q) and q > 0:\n            w = np.minimum(w, q)\n    if use_recency:\n        t = df[TIME_COL].to_numpy(dtype=np.float64)\n        rec = np.exp(-(TRAIN_MAX_TS - t) / float(tau))\n        w = w * rec\n    w = np.where(np.isfinite(w), w, 0.0)\n    w = np.maximum(w, 0.0)\n    if float(w.sum()) <= eps:\n        w = np.ones(len(df), dtype=np.float64)\n    return w\n\n# ----------------------------\n# 6) Median imputer (optional, kalau nanti tambah model linear)\n# ----------------------------\ndef fit_median_imputer(df_fit: pd.DataFrame, num_cols: list[str]) -> dict:\n    med = df_fit[num_cols].median(numeric_only=True)\n    return {c: float(med[c]) if c in med.index and np.isfinite(med[c]) else 0.0 for c in num_cols}\n\ndef apply_median_imputer(df_apply: pd.DataFrame, medians: dict, num_cols: list[str]) -> pd.DataFrame:\n    out = df_apply.copy()\n    for c in num_cols:\n        if c in out.columns and out[c].isna().any():\n            out[c] = out[c].fillna(medians.get(c, 0.0))\n    return out\n\nprint(\"\\n==================== STAGE 5 UPGRADE SUMMARY ====================\")\nprint(\"Train/Test shapes:\", df_train.shape, df_test.shape)\nprint(\"SERIES_KEYS:\", SERIES_KEYS)\nprint(\"FEATURE_COLS_CAT_ALL:\", FEATURE_COLS_CAT_ALL)\nprint(\"NUM features:\", len(FEATURE_COLS_NUM_ALL), \"| TOTAL features:\", len(FEATURE_COLS_ALL))\nprint(\"Example engineered cols:\", [c for c in df_train.columns if c.startswith('fe_')][:20])\n\nglobals()[\"df_train\"] = df_train\nglobals()[\"df_test\"] = df_test\nglobals()[\"SERIES_KEYS\"] = SERIES_KEYS\nglobals()[\"FEATURE_COLS_CAT_ALL\"] = FEATURE_COLS_CAT_ALL\nglobals()[\"FEATURE_COLS_NUM_ALL\"] = FEATURE_COLS_NUM_ALL\nglobals()[\"FEATURE_COLS_ALL\"] = FEATURE_COLS_ALL\nglobals()[\"CAT_FEATURE_IDXS_ALL\"] = CAT_FEATURE_IDXS_ALL\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Training, OOF Evaluation, and Model Selection","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 6 — Model Training, OOF Evaluation, and Model Selection (UPGRADE v4: Ensemble + Blend + Alpha)\n# ============================================================\n\nimport gc, json, time\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nneed = [\"df_train\",\"TARGET_COL\",\"TIME_COL\",\"ID_COL\",\"WEIGHT_COL\",\"FEATURE_COLS_ALL\",\"FEATURE_COLS_CAT_ALL\",\n        \"fold_boundaries\",\"weighted_rmse_score\",\"make_sample_weight\"]\nfor k in need:\n    if k not in globals():\n        raise RuntimeError(f\"Missing global: {k}. Jalankan stage sebelumnya.\")\n\nMODE = \"per_horizon\"\n\nif MODE == \"per_horizon\" and \"horizon\" in FEATURE_COLS_CAT_ALL:\n    CAT_COLS_MODEL = [c for c in FEATURE_COLS_CAT_ALL if c != \"horizon\"]\nelse:\n    CAT_COLS_MODEL = list(FEATURE_COLS_CAT_ALL)\n\nNUM_COLS_MODEL = [c for c in FEATURE_COLS_ALL if c not in FEATURE_COLS_CAT_ALL]\nFEATURE_COLS_MODEL = CAT_COLS_MODEL + NUM_COLS_MODEL\nCAT_FEATURE_IDXS = [i for i,c in enumerate(FEATURE_COLS_MODEL) if c in CAT_COLS_MODEL]\n\nprint(\"MODE:\", MODE)\nprint(\"Total features:\", len(FEATURE_COLS_MODEL), \"| cat idx count:\", len(CAT_FEATURE_IDXS))\n\n# weights\nUSE_RECENCY = True\nTAU = 600.0\nCLIP_W_Q = 0.9995\n\nTRAIN_SAMPLE_CAP = 450_000\nSAMPLE_WEIGHTED = True\n\nUSE_CATBOOST = True\nUSE_LGBM = True\n\nCB_SEEDS = [42, 52, 62]\nLGB_SEEDS = [41, 51]\n\nCB_PARAM_LIST = [\n    dict(iterations=2500, learning_rate=0.04, depth=8,  l2_leaf_reg=6.0,  random_strength=1.0, rsm=0.9, min_data_in_leaf=120, bootstrap_type=\"Bernoulli\", subsample=0.8),\n    dict(iterations=3500, learning_rate=0.03, depth=10, l2_leaf_reg=8.0,  random_strength=1.2, rsm=0.9, min_data_in_leaf=70,  bootstrap_type=\"Bernoulli\", subsample=0.8),\n]\nEARLY_STOPPING_ROUNDS = 200\n\nLGB_PARAMS = dict(\n    objective=\"regression\",\n    metric=\"rmse\",\n    learning_rate=0.03,\n    num_leaves=192,\n    min_data_in_leaf=200,\n    feature_fraction=0.8,\n    bagging_fraction=0.8,\n    bagging_freq=1,\n    lambda_l2=8.0,\n    max_bin=255,\n    verbose=-1,\n)\n\nOUT_DIR = Path(\"/kaggle/working/tsf_stage6_models_v4\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\ndef _maybe_sample(df: pd.DataFrame, cap: int, weighted: bool, seed: int) -> pd.DataFrame:\n    if cap is None or cap <= 0 or len(df) <= cap:\n        return df\n    rs = np.random.RandomState(seed)\n    if not weighted:\n        idx = rs.choice(len(df), size=cap, replace=False)\n        return df.iloc[idx]\n    w = df[WEIGHT_COL].to_numpy(np.float64)\n    w = np.where(np.isfinite(w), w, 0.0)\n    w = np.maximum(w, 0.0)\n    if w.sum() <= 0:\n        idx = rs.choice(len(df), size=cap, replace=False)\n        return df.iloc[idx]\n    p = w / (w.sum() + 1e-12)\n    idx = rs.choice(len(df), size=cap, replace=False, p=p)\n    return df.iloc[idx]\n\ndef fit_alpha(y: np.ndarray, pred: np.ndarray, w: np.ndarray, clip=(0.0, 3.0)) -> float:\n    num = float(np.sum(w * y * pred))\n    den = float(np.sum(w * pred * pred) + 1e-12)\n    a = num / den\n    return float(np.clip(a, clip[0], clip[1]))\n\ndef fit_blend_weights(pred_mat: np.ndarray, y: np.ndarray, w: np.ndarray, nonneg=True) -> np.ndarray:\n    sw = np.sqrt(np.maximum(w, 0.0)).astype(np.float64)\n    Pw = pred_mat * sw[:, None]\n    yw = y * sw\n    b, *_ = np.linalg.lstsq(Pw, yw, rcond=None)\n    b = b.astype(np.float64)\n    if nonneg:\n        b = np.clip(b, 0.0, None)\n    s = b.sum()\n    if not np.isfinite(s) or s <= 0:\n        b = np.ones(pred_mat.shape[1], dtype=np.float64) / pred_mat.shape[1]\n    else:\n        b = b / s\n    return b\n\nfrom catboost import CatBoostRegressor, Pool\ntry:\n    import lightgbm as lgb\n    _HAS_LGB = True\nexcept Exception:\n    _HAS_LGB = False\n    USE_LGBM = False\n    print(\"[WARN] lightgbm not available; skipping LGBM.\")\n\ndf_train = df_train.copy()\ndf_train[\"fold\"] = df_train[\"fold\"].astype(int)\n\nfold_ids = sorted(df_train[\"fold\"].unique().tolist())\nhorizons = sorted(df_train[\"horizon\"].unique().tolist()) if (MODE == \"per_horizon\" and \"horizon\" in df_train.columns) else [None]\n\noof_store = {}\ndef _new_oof():\n    return np.zeros(len(df_train), dtype=np.float32)\n\nmodel_registry = []\n\nt0 = time.time()\nfor h in horizons:\n    if h is None:\n        mask_h = np.ones(len(df_train), dtype=bool)\n        h_key = \"__all__\"\n    else:\n        mask_h = (df_train[\"horizon\"].astype(str) == str(h))\n        h_key = str(h)\n\n    if mask_h.sum() == 0:\n        continue\n\n    print(\"\\n\" + \"=\"*80)\n    print(\"HORIZON:\", h_key, \"| rows:\", int(mask_h.sum()), \"| folds:\", fold_ids)\n\n    for k in fold_ids:\n        va_mask = mask_h & (df_train[\"fold\"] == k)\n        tr_mask = mask_h & (df_train[\"fold\"] != k)\n\n        df_tr = df_train.loc[tr_mask]\n        df_va = df_train.loc[va_mask]\n        if len(df_va) == 0 or len(df_tr) == 0:\n            continue\n\n        df_tr_s = _maybe_sample(df_tr, TRAIN_SAMPLE_CAP, SAMPLE_WEIGHTED, seed=1234 + k + (0 if h is None else int(h)*7))\n\n        X_tr = df_tr_s[FEATURE_COLS_MODEL]\n        y_tr = df_tr_s[TARGET_COL].to_numpy(np.float32)\n        w_tr = make_sample_weight(df_tr_s, use_recency=USE_RECENCY, tau=TAU, clip_w_quantile=CLIP_W_Q)\n\n        X_va = df_va[FEATURE_COLS_MODEL]\n        y_va = df_va[TARGET_COL].to_numpy(np.float32)\n        w_va_eval = df_va[WEIGHT_COL].to_numpy(np.float64)\n\n        if USE_CATBOOST:\n            for pi, pbase in enumerate(CB_PARAM_LIST):\n                for sd in CB_SEEDS:\n                    name = f\"cb_p{pi}_s{sd}\"\n                    if name not in oof_store:\n                        oof_store[name] = _new_oof()\n\n                    params = dict(\n                        loss_function=\"RMSE\",\n                        eval_metric=\"RMSE\",\n                        task_type=\"CPU\",\n                        thread_count=-1,\n                        random_seed=int(sd + 1000*k),\n                        allow_writing_files=False,\n                        **pbase\n                    )\n                    train_pool = Pool(X_tr, label=y_tr, weight=w_tr, cat_features=CAT_FEATURE_IDXS)\n                    valid_pool = Pool(X_va, label=y_va, cat_features=CAT_FEATURE_IDXS)\n\n                    model = CatBoostRegressor(**params)\n                    model.fit(train_pool, eval_set=valid_pool, use_best_model=True,\n                              verbose=False, early_stopping_rounds=EARLY_STOPPING_ROUNDS)\n\n                    pred_va = model.predict(valid_pool).astype(np.float32)\n                    oof_store[name][va_mask] = pred_va\n\n                    sc = weighted_rmse_score(y_va.astype(np.float64), pred_va.astype(np.float64), w_va_eval.astype(np.float64))\n                    model_registry.append(dict(family=\"catboost\", name=name, horizon=h_key, fold=int(k), score=float(sc)))\n\n        if USE_LGBM and _HAS_LGB:\n            X_tr_l = X_tr.copy()\n            X_va_l = X_va.copy()\n            for c in CAT_COLS_MODEL:\n                if c in X_tr_l.columns:\n                    X_tr_l[c] = X_tr_l[c].astype(\"category\")\n                    X_va_l[c] = X_va_l[c].astype(\"category\")\n\n            dtrain = lgb.Dataset(X_tr_l, label=y_tr, weight=w_tr, categorical_feature=CAT_COLS_MODEL, free_raw_data=True)\n            dvalid = lgb.Dataset(X_va_l, label=y_va, weight=None, categorical_feature=CAT_COLS_MODEL, free_raw_data=True)\n\n            for sd in LGB_SEEDS:\n                name = f\"lgb_s{sd}\"\n                if name not in oof_store:\n                    oof_store[name] = _new_oof()\n\n                params = dict(LGB_PARAMS)\n                params[\"seed\"] = int(sd + 1000*k)\n\n                model = lgb.train(\n                    params, dtrain,\n                    num_boost_round=8000,\n                    valid_sets=[dvalid],\n                    valid_names=[\"valid\"],\n                    callbacks=[lgb.early_stopping(250, verbose=False), lgb.log_evaluation(0)],\n                )\n                pred_va = model.predict(X_va_l, num_iteration=model.best_iteration).astype(np.float32)\n                oof_store[name][va_mask] = pred_va\n\n                sc = weighted_rmse_score(y_va.astype(np.float64), pred_va.astype(np.float64), w_va_eval.astype(np.float64))\n                model_registry.append(dict(family=\"lgbm\", name=name, horizon=h_key, fold=int(k), score=float(sc)))\n\n        gc.collect()\n\nprint(\"\\nTraining done in\", round(time.time() - t0, 1), \"sec\")\nprint(\"OOF variants:\", len(oof_store))\n\ndef _avg_oof(names):\n    arr = np.stack([oof_store[n] for n in names], axis=0).astype(np.float64)\n    return arr.mean(axis=0).astype(np.float32)\n\ncb_names = [n for n in oof_store.keys() if n.startswith(\"cb_\")]\nlgb_names = [n for n in oof_store.keys() if n.startswith(\"lgb_\")]\n\ncomponents = {}\nif len(cb_names):  components[\"cb\"]  = _avg_oof(cb_names)\nif len(lgb_names): components[\"lgb\"] = _avg_oof(lgb_names)\nif len(components) == 0:\n    raise RuntimeError(\"No OOF predictions built.\")\n\nblend_weights_by_h = {}\nalpha_by_h = {}\noof_pred_blend = np.zeros(len(df_train), dtype=np.float32)\n\ny_all = df_train[TARGET_COL].to_numpy(np.float64)\nw_all = df_train[WEIGHT_COL].to_numpy(np.float64)\nw_all = np.where(np.isfinite(w_all), w_all, 0.0)\nw_all = np.maximum(w_all, 0.0)\n\nfor h in horizons:\n    if h is None:\n        idx = np.ones(len(df_train), dtype=bool)\n        h_key = \"__all__\"\n    else:\n        idx = (df_train[\"horizon\"].astype(str) == str(h))\n        h_key = str(h)\n\n    y = y_all[idx]\n    w = w_all[idx]\n    P = np.vstack([components[k][idx].astype(np.float64) for k in components.keys()]).T\n    names = list(components.keys())\n\n    b = fit_blend_weights(P, y, w, nonneg=True)\n    blend_weights_by_h[h_key] = {names[i]: float(b[i]) for i in range(len(names))}\n\n    pred_bl = (P @ b).astype(np.float64)\n    a = fit_alpha(y, pred_bl, w, clip=(0.0, 3.0))\n    alpha_by_h[h_key] = float(a)\n\n    oof_pred_blend[idx] = (pred_bl * a).astype(np.float32)\n\ncv_score = weighted_rmse_score(y_all, oof_pred_blend.astype(np.float64), w_all)\nprint(\"\\nCV score (OOF blend):\", float(cv_score))\nprint(\"blend_weights_by_h:\", blend_weights_by_h)\nprint(\"alpha_by_h:\", alpha_by_h)\n\nmodel_cfg_used = dict(\n    MODE=MODE,\n    USE_RECENCY=USE_RECENCY, TAU=float(TAU), CLIP_W_Q=CLIP_W_Q,\n    TRAIN_SAMPLE_CAP=int(TRAIN_SAMPLE_CAP), SAMPLE_WEIGHTED=bool(SAMPLE_WEIGHTED),\n    USE_CATBOOST=True, USE_LGBM=bool(USE_LGBM),\n    CB_SEEDS=CB_SEEDS, LGB_SEEDS=LGB_SEEDS,\n    CB_PARAM_LIST=CB_PARAM_LIST, LGB_PARAMS=LGB_PARAMS,\n    FEATURE_COLS_MODEL=FEATURE_COLS_MODEL,\n    CAT_COLS_MODEL=CAT_COLS_MODEL,\n    CAT_FEATURE_IDXS=CAT_FEATURE_IDXS,\n    blend_weights_by_h=blend_weights_by_h,\n    alpha_by_h=alpha_by_h,\n    cv_score=float(cv_score),\n)\n\n(OUT_DIR / \"stage6_cfg.json\").write_text(json.dumps(model_cfg_used, indent=2))\n(OUT_DIR / \"stage6_model_registry.json\").write_text(json.dumps(model_registry, indent=2))\nprint(\"Saved:\", str(OUT_DIR / \"stage6_cfg.json\"))\n\nglobals()[\"oof_pred_blend\"] = oof_pred_blend\nglobals()[\"blend_weights_by_h\"] = blend_weights_by_h\nglobals()[\"alpha_by_h\"] = alpha_by_h\nglobals()[\"model_cfg_used\"] = model_cfg_used\nglobals()[\"FEATURE_COLS_MODEL\"] = FEATURE_COLS_MODEL\nglobals()[\"CAT_FEATURE_IDXS\"] = CAT_FEATURE_IDXS\nglobals()[\"CAT_COLS_MODEL\"] = CAT_COLS_MODEL\n\ngc.collect()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Final Fit, Test Inference, and Submission Packaging","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 7 — Final Fit, Test Inference, and Submission Packaging (UPGRADE v4: Ensemble + Blend)\n# ============================================================\n\nimport gc, json, time\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\n\nneed = [\"df_train\",\"df_test\",\"TARGET_COL\",\"ID_COL\",\"TIME_COL\",\"WEIGHT_COL\",\n        \"FEATURE_COLS_MODEL\",\"CAT_FEATURE_IDXS\",\"CAT_COLS_MODEL\",\"make_sample_weight\",\"model_cfg_used\"]\nfor k in need:\n    if k not in globals():\n        raise RuntimeError(f\"Missing global: {k}. Jalankan stage sebelumnya.\")\n\nfrom catboost import CatBoostRegressor, Pool\ntry:\n    import lightgbm as lgb\n    _HAS_LGB = True\nexcept Exception:\n    _HAS_LGB = False\n\nCFG = model_cfg_used\nblend_weights_by_h = CFG[\"blend_weights_by_h\"]\nalpha_by_h = CFG[\"alpha_by_h\"]\n\nUSE_CATBOOST = bool(CFG.get(\"USE_CATBOOST\", True))\nUSE_LGBM = bool(CFG.get(\"USE_LGBM\", False)) and _HAS_LGB\n\nCB_SEEDS = CFG.get(\"CB_SEEDS\", [42, 52, 62])\nLGB_SEEDS = CFG.get(\"LGB_SEEDS\", [41, 51])\nCB_PARAM_LIST = CFG.get(\"CB_PARAM_LIST\", [])\nLGB_PARAMS = CFG.get(\"LGB_PARAMS\", {})\n\nUSE_RECENCY = bool(CFG.get(\"USE_RECENCY\", True))\nTAU = float(CFG.get(\"TAU\", 600.0))\nCLIP_W_Q = CFG.get(\"CLIP_W_Q\", 0.9995)\n\nMODE = CFG.get(\"MODE\", \"per_horizon\")\nhorizons = sorted(df_train[\"horizon\"].unique().tolist()) if (MODE == \"per_horizon\" and \"horizon\" in df_train.columns) else [None]\n\nOUT_DIR = Path(\"/kaggle/working/tsf_stage7_bundle_v4\")\nMODEL_DIR = OUT_DIR / \"final_models\"\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\n\ntest_pred = np.zeros(len(df_test), dtype=np.float64)\n\nt0 = time.time()\nfor h in horizons:\n    if h is None:\n        tr_idx = np.ones(len(df_train), dtype=bool)\n        te_idx = np.ones(len(df_test), dtype=bool)\n        h_key = \"__all__\"\n    else:\n        tr_idx = (df_train[\"horizon\"].astype(str) == str(h))\n        te_idx = (df_test[\"horizon\"].astype(str) == str(h)) if \"horizon\" in df_test.columns else np.ones(len(df_test), dtype=bool)\n        h_key = str(h)\n\n    if tr_idx.sum() == 0 or te_idx.sum() == 0:\n        continue\n\n    X_tr = df_train.loc[tr_idx, FEATURE_COLS_MODEL]\n    y_tr = df_train.loc[tr_idx, TARGET_COL].to_numpy(np.float32)\n    w_tr = make_sample_weight(df_train.loc[tr_idx], use_recency=USE_RECENCY, tau=TAU, clip_w_quantile=CLIP_W_Q)\n\n    X_te = df_test.loc[te_idx, FEATURE_COLS_MODEL]\n    comps = {}\n\n    if USE_CATBOOST and len(CB_PARAM_LIST):\n        preds = []\n        for pi, pbase in enumerate(CB_PARAM_LIST):\n            for sd in CB_SEEDS:\n                params = dict(\n                    loss_function=\"RMSE\",\n                    eval_metric=\"RMSE\",\n                    task_type=\"CPU\",\n                    thread_count=-1,\n                    random_seed=int(sd + 777),\n                    allow_writing_files=False,\n                    **pbase\n                )\n                model = CatBoostRegressor(**params)\n                pool_tr = Pool(X_tr, label=y_tr, weight=w_tr, cat_features=CAT_FEATURE_IDXS)\n                model.fit(pool_tr, verbose=False)\n\n                pred_te = model.predict(Pool(X_te, cat_features=CAT_FEATURE_IDXS)).astype(np.float64)\n                preds.append(pred_te)\n\n                model.save_model(str(MODEL_DIR / f\"cb_h{h_key}_p{pi}_s{sd}.cbm\"))\n        comps[\"cb\"] = np.mean(np.stack(preds, axis=0), axis=0)\n\n    if USE_LGBM:\n        X_tr_l = X_tr.copy()\n        X_te_l = X_te.copy()\n        for c in CAT_COLS_MODEL:\n            if c in X_tr_l.columns:\n                X_tr_l[c] = X_tr_l[c].astype(\"category\")\n                X_te_l[c] = X_te_l[c].astype(\"category\")\n\n        dtrain = lgb.Dataset(X_tr_l, label=y_tr, weight=w_tr, categorical_feature=CAT_COLS_MODEL, free_raw_data=True)\n\n        preds = []\n        for sd in LGB_SEEDS:\n            params = dict(LGB_PARAMS)\n            params[\"seed\"] = int(sd + 777)\n            model = lgb.train(params, dtrain, num_boost_round=CFG.get(\"LGB_NUM_BOOST\", 3500))\n            preds.append(model.predict(X_te_l).astype(np.float64))\n            model.save_model(str(MODEL_DIR / f\"lgb_h{h_key}_s{sd}.txt\"))\n        comps[\"lgb\"] = np.mean(np.stack(preds, axis=0), axis=0)\n\n    wts = blend_weights_by_h.get(h_key, None)\n    if wts is None:\n        keys = list(comps.keys())\n        wts = {k: 1.0/len(keys) for k in keys}\n\n    pred = np.zeros(len(X_te), dtype=np.float64)\n    for k, v in comps.items():\n        pred += float(wts.get(k, 0.0)) * v\n\n    pred *= float(alpha_by_h.get(h_key, 1.0))\n    test_pred[te_idx] = pred\n\n    print(f\"H={h_key} | n_tr={int(tr_idx.sum())} n_te={int(te_idx.sum())} | comps={list(comps.keys())} | wts={wts} | alpha={alpha_by_h.get(h_key,1.0)}\")\n\nprint(\"Final inference done in\", round(time.time()-t0, 1), \"sec\")\n\nSUB_PATH = Path(\"/kaggle/working/submission.csv\")\nsub = pd.DataFrame({ID_COL: df_test[ID_COL].astype(str).values, \"prediction\": test_pred.astype(np.float64)})\nsub.to_csv(SUB_PATH, index=False)\nprint(\"Saved submission:\", str(SUB_PATH), \"| shape:\", sub.shape)\n\nbundle = dict(\n    created_utc=time.time(),\n    cfg=model_cfg_used,\n    features=FEATURE_COLS_MODEL,\n    cat_cols=CAT_COLS_MODEL,\n    id_col=ID_COL, time_col=TIME_COL, weight_col=WEIGHT_COL, target_col=TARGET_COL,\n    train_shape=list(df_train.shape),\n    test_shape=list(df_test.shape),\n)\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n(OUT_DIR / \"bundle.json\").write_text(json.dumps(bundle, indent=2))\nprint(\"Saved bundle:\", str(OUT_DIR / \"bundle.json\"))\n\nglobals()[\"test_pred\"] = test_pred\nglobals()[\"SUB_PATH\"] = str(SUB_PATH)\nglobals()[\"BUNDLE_DIR\"] = str(OUT_DIR)\n\ngc.collect()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
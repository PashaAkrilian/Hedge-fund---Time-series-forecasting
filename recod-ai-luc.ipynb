{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":113558,"databundleVersionId":14878066,"sourceType":"competition"},{"sourceId":4534,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3326,"modelId":986}],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dataset Loading & Manifest Building","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 0 — Dataset Loading & Manifest Building (ONE CELL)\n# - English stage naming (compatible with next stages in our plan)\n# - Auto-detect Kaggle dataset root from folder structure shown\n# - Builds:\n#     df_train_all : uid, case_id, y, img_path, mask_path, is_supplemental, split\n#     df_test      : uid, case_id, img_path\n# - Saves:\n#     /kaggle/working/recodai_luc_prof/paths.json\n#     /kaggle/working/recodai_luc_prof/train_manifest.parquet\n#     /kaggle/working/recodai_luc_prof/test_manifest.parquet\n#     /kaggle/working/recodai_luc_prof/sample_submission.csv (copy)\n# - Paper-ready figures (Stage 0):\n#     /kaggle/working/recodai_luc_prof/figures/stage0/*.png\n# ============================================================\n\nimport os, json, math, random, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Repro\n# ----------------------------\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\n# ----------------------------\n# 1) Auto-detect dataset root\n# ----------------------------\ndef find_dataset_root(base=\"/kaggle/input\"):\n    base = Path(base)\n    need_dirs = [\"train_images\", \"train_masks\", \"test_images\"]\n    need_file = \"sample_submission.csv\"\n    cands = []\n    for d in base.iterdir():\n        if not d.is_dir():\n            continue\n        ok = True\n        for nd in need_dirs:\n            if not (d / nd).exists():\n                ok = False\n                break\n        if ok and (d / need_file).exists():\n            cands.append(d)\n    # prefer the largest (usually main competition dataset)\n    if not cands:\n        raise RuntimeError(\n            \"Dataset root not found under /kaggle/input. \"\n            \"Expected folders: train_images/, train_masks/, test_images/ and sample_submission.csv\"\n        )\n    cands = sorted(cands, key=lambda p: sum(1 for _ in p.rglob(\"*\")), reverse=True)\n    return cands[0]\n\nDATA_ROOT = find_dataset_root()\nprint(\"DATA_ROOT:\", DATA_ROOT)\n\nTRAIN_IMG_DIR = DATA_ROOT / \"train_images\"\nTRAIN_AUTH_DIR = TRAIN_IMG_DIR / \"authentic\"\nTRAIN_FORG_DIR = TRAIN_IMG_DIR / \"forged\"\nTRAIN_MASK_DIR = DATA_ROOT / \"train_masks\"\n\nTEST_IMG_DIR = DATA_ROOT / \"test_images\"\n\nSUP_IMG_DIR = DATA_ROOT / \"supplemental_images\"\nSUP_MASK_DIR = DATA_ROOT / \"supplemental_masks\"\n\nSAMPLE_SUB_PATH = DATA_ROOT / \"sample_submission.csv\"\n\nfor p in [TRAIN_AUTH_DIR, TRAIN_FORG_DIR, TRAIN_MASK_DIR, TEST_IMG_DIR, SAMPLE_SUB_PATH]:\n    if not p.exists():\n        raise RuntimeError(f\"Missing required path: {p}\")\n\n# ----------------------------\n# 2) Output dirs (keep consistent for next stages)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\nPROF_DIR.mkdir(parents=True, exist_ok=True)\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage0\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\n# Copy sample submission for reference\npd.read_csv(SAMPLE_SUB_PATH).to_csv(PROF_DIR / \"sample_submission.csv\", index=False)\n\n# ----------------------------\n# 3) Helpers\n# ----------------------------\ndef list_pngs(d: Path):\n    if (not d.exists()) or (not d.is_dir()):\n        return []\n    return sorted([p for p in d.glob(\"*.png\")])\n\ndef read_mask_npy(mask_path: Path):\n    m = np.load(mask_path)\n    if m.ndim == 3:\n        m = m.max(axis=0)\n    m = (m > 0).astype(np.uint8)\n    return m\n\ndef overlay_mask(img_rgb, mask01, alpha=0.45):\n    img = img_rgb.astype(np.float32) / 255.0\n    m = mask01.astype(bool)\n    out = img.copy()\n    out[m, 0] = (1 - alpha) * out[m, 0] + alpha * 1.0\n    out[m, 1] = (1 - alpha) * out[m, 1] + alpha * 0.0\n    out[m, 2] = (1 - alpha) * out[m, 2] + alpha * 0.0\n    return (out * 255).clip(0, 255).astype(np.uint8)\n\ndef safe_case_id_from_uid(uid: str):\n    # filenames look like \"10.png\" -> uid \"10\"\n    # Keep as string for exact match with sample_submission\n    return str(uid)\n\n# ----------------------------\n# 4) Build manifests\n# ----------------------------\nauth_files = list_pngs(TRAIN_AUTH_DIR)\nforg_files = list_pngs(TRAIN_FORG_DIR)\n\nrows = []\nfor p in auth_files:\n    uid = p.stem\n    rows.append(dict(\n        uid=uid,\n        case_id=safe_case_id_from_uid(uid),\n        y=0,\n        split=\"train\",\n        img_path=str(p),\n        mask_path=\"\",\n        is_supplemental=0,\n        source=\"train_authentic\",\n    ))\n\nfor p in forg_files:\n    uid = p.stem\n    mp = TRAIN_MASK_DIR / f\"{uid}.npy\"\n    rows.append(dict(\n        uid=uid,\n        case_id=safe_case_id_from_uid(uid),\n        y=1,\n        split=\"train\",\n        img_path=str(p),\n        mask_path=str(mp) if mp.exists() else \"\",\n        is_supplemental=0,\n        source=\"train_forged\",\n    ))\n\n# Supplemental (if exists)\nif SUP_IMG_DIR.exists() and SUP_MASK_DIR.exists():\n    sup_files = list_pngs(SUP_IMG_DIR)\n    for p in sup_files:\n        uid = p.stem\n        mp = SUP_MASK_DIR / f\"{uid}.npy\"\n        rows.append(dict(\n            uid=uid,\n            case_id=safe_case_id_from_uid(uid),\n            y=1,\n            split=\"train\",\n            img_path=str(p),\n            mask_path=str(mp) if mp.exists() else \"\",\n            is_supplemental=1,\n            source=\"supplemental_forged\",\n        ))\n\ndf_train_all = pd.DataFrame(rows)\n\n# Resolve duplicate uids safely:\n# If uid appears more than once (e.g., both authentic & forged), keep the row with an existing mask,\n# otherwise prefer forged, else keep the first.\ndup = df_train_all[\"uid\"].duplicated(keep=False)\nif dup.any():\n    ddf = df_train_all[dup].copy()\n    print(f\"[WARN] Duplicate uid detected: {ddf['uid'].nunique()} uids (show up to 10):\", ddf[\"uid\"].unique()[:10])\n\n    def pick_best(group: pd.DataFrame):\n        # prefer: has mask_path existing file\n        g = group.copy()\n        g[\"mask_exists\"] = g[\"mask_path\"].apply(lambda x: Path(x).exists() if str(x) else False)\n        # ranking: mask_exists desc, y desc (prefer forged), is_supplemental desc, keep stable by source\n        g = g.sort_values([\"mask_exists\", \"y\", \"is_supplemental\"], ascending=[False, False, False])\n        return g.iloc[0]\n\n    df_train_all = (\n        df_train_all.groupby(\"uid\", as_index=False, sort=False)\n        .apply(pick_best)\n        .reset_index(drop=True)\n    )\n\n# Basic checks\ndf_train_all[\"mask_path\"] = df_train_all[\"mask_path\"].fillna(\"\").astype(str)\nmissing_mask_forged = df_train_all[(df_train_all[\"y\"] == 1) & (df_train_all[\"mask_path\"] == \"\")]\nif len(missing_mask_forged) > 0:\n    print(f\"[WARN] Forged samples missing mask_path: {len(missing_mask_forged)} (first 5 uids):\",\n          missing_mask_forged[\"uid\"].head(5).tolist())\n\n# Test manifest\ntest_files = list_pngs(TEST_IMG_DIR)\ndf_test = pd.DataFrame([dict(\n    uid=p.stem,\n    case_id=safe_case_id_from_uid(p.stem),\n    split=\"test\",\n    img_path=str(p),\n) for p in test_files])\n\n# Sort by numeric id if possible (nice & stable)\ndef to_int_or_nan(x):\n    try:\n        return int(str(x))\n    except:\n        return np.nan\n\ndf_train_all[\"_cid_int\"] = df_train_all[\"case_id\"].map(to_int_or_nan)\ndf_test[\"_cid_int\"] = df_test[\"case_id\"].map(to_int_or_nan)\ndf_train_all = df_train_all.sort_values([\"_cid_int\", \"case_id\"]).drop(columns=[\"_cid_int\"]).reset_index(drop=True)\ndf_test = df_test.sort_values([\"_cid_int\", \"case_id\"]).drop(columns=[\"_cid_int\"]).reset_index(drop=True)\n\nprint(\"train_manifest:\", df_train_all.shape, \"| forged% =\", round(df_train_all[\"y\"].mean() * 100, 3))\nprint(\"test_manifest :\", df_test.shape)\n\n# ----------------------------\n# 5) Save artifacts (parquet preferred)\n# ----------------------------\ntrain_out = PROF_DIR / \"train_manifest.parquet\"\ntest_out  = PROF_DIR / \"test_manifest.parquet\"\ndf_train_all.to_parquet(train_out, index=False)\ndf_test.to_parquet(test_out, index=False)\n\n# Save paths.json for downstream stages\n# (We keep these names stable so next stages can read them without errors.)\npaths = dict(\n    DATA_ROOT=str(DATA_ROOT),\n    TRAIN_AUTH_DIR=str(TRAIN_AUTH_DIR),\n    TRAIN_FORG_DIR=str(TRAIN_FORG_DIR),\n    TRAIN_MASK_DIR=str(TRAIN_MASK_DIR),\n    TEST_IMG_DIR=str(TEST_IMG_DIR),\n    SUP_IMG_DIR=str(SUP_IMG_DIR) if SUP_IMG_DIR.exists() else \"\",\n    SUP_MASK_DIR=str(SUP_MASK_DIR) if SUP_MASK_DIR.exists() else \"\",\n    SAMPLE_SUBMISSION=str(SAMPLE_SUB_PATH),\n    PROF_DIR=str(PROF_DIR),\n    TRAIN_MANIFEST=str(train_out),\n    TEST_MANIFEST=str(test_out),\n)\n(Path(PROF_DIR) / \"paths.json\").write_text(json.dumps(paths, indent=2))\n\n# ----------------------------\n# 6) Stage-0 paper figures (safe + lightweight)\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\n# Fig0-2: class distribution\nvc = df_train_all[\"y\"].value_counts().sort_index()\nplt.figure(figsize=(5,4))\nplt.bar([str(k) for k in vc.index], vc.values)\nplt.xlabel(\"Class (0=authentic, 1=forged)\")\nplt.ylabel(\"Count\")\nplt.title(\"Class distribution\")\nsavefig(FIG_DIR / \"Fig0-2_class_distribution.png\")\n\n# Fig0-3: image size scatter (sample to keep fast)\nsample_n = min(800, len(df_train_all))\nrows_s = df_train_all.sample(sample_n, random_state=SEED)\nws, hs = [], []\nfor p in rows_s[\"img_path\"].tolist():\n    im = Image.open(p)\n    w, h = im.size\n    ws.append(w); hs.append(h)\n\nplt.figure(figsize=(6,4))\nplt.scatter(ws, hs, s=8)\nplt.xlabel(\"Width\"); plt.ylabel(\"Height\")\nplt.title(\"Image size scatter (sample)\")\nsavefig(FIG_DIR / \"Fig0-3_image_size_scatter.png\")\n\n# Fig0-4: GT mask area histogram (forged with mask exists)\nforged_with_mask = df_train_all[(df_train_all[\"y\"]==1) & (df_train_all[\"mask_path\"]!=\"\")].copy()\nareas = []\nif len(forged_with_mask) > 0:\n    rows_m = forged_with_mask.sample(min(1200, len(forged_with_mask)), random_state=SEED)\n    for mp in rows_m[\"mask_path\"].tolist():\n        m = read_mask_npy(Path(mp))\n        areas.append(float(m.mean()))\nplt.figure(figsize=(6,4))\nplt.hist(areas, bins=40)\nplt.xlabel(\"Mask area (fraction of pixels)\")\nplt.ylabel(\"Count\")\nplt.title(\"GT mask area distribution (forged)\")\nsavefig(FIG_DIR / \"Fig0-4_gt_mask_area_hist.png\")\n\n# Fig0-1: sample grid (authentic + forged overlay)\ndef make_sample_grid(n_auth=6, n_forg=6):\n    items, titles = [], []\n    a = df_train_all[df_train_all[\"y\"]==0].sample(min(n_auth, (df_train_all[\"y\"]==0).sum()), random_state=SEED)\n    f = df_train_all[(df_train_all[\"y\"]==1) & (df_train_all[\"mask_path\"]!=\"\")].sample(\n        min(n_forg, len(forged_with_mask)), random_state=SEED\n    ) if len(forged_with_mask) else pd.DataFrame()\n\n    # authentic\n    for _, r in a.iterrows():\n        img = np.array(Image.open(r[\"img_path\"]).convert(\"RGB\"))\n        items.append(img); titles.append(f'{r[\"case_id\"]} | authentic')\n\n    # forged with overlay\n    for _, r in f.iterrows():\n        img = np.array(Image.open(r[\"img_path\"]).convert(\"RGB\"))\n        m = read_mask_npy(Path(r[\"mask_path\"]))\n        ov = overlay_mask(img, m, alpha=0.45)\n        items.append(ov); titles.append(f'{r[\"case_id\"]} | forged (GT overlay)')\n\n    # plot\n    n = len(items)\n    if n == 0:\n        return\n    ncols = 4\n    nrows = int(math.ceil(n / ncols))\n    plt.figure(figsize=(14, 10))\n    for i in range(n):\n        plt.subplot(nrows, ncols, i+1)\n        plt.imshow(items[i])\n        plt.axis(\"off\")\n        plt.title(titles[i], fontsize=9)\n    savefig(FIG_DIR / \"Fig0-1_samples_grid.png\")\n\nmake_sample_grid()\n\nprint(\"\\n[OK] Saved manifests & figures:\")\nprint(\" -\", train_out)\nprint(\" -\", test_out)\nprint(\" -\", PROF_DIR / \"paths.json\")\nprint(\" - figures:\", FIG_DIR)\n\n# Keep globals for next stages\nglobals().update(dict(\n    DATA_ROOT=DATA_ROOT,\n    TRAIN_AUTH_DIR=TRAIN_AUTH_DIR,\n    TRAIN_FORG_DIR=TRAIN_FORG_DIR,\n    TRAIN_MASK_DIR=TRAIN_MASK_DIR,\n    TEST_IMG_DIR=TEST_IMG_DIR,\n    SUP_IMG_DIR=SUP_IMG_DIR if SUP_IMG_DIR.exists() else None,\n    SUP_MASK_DIR=SUP_MASK_DIR if SUP_MASK_DIR.exists() else None,\n    SAMPLE_SUB_PATH=SAMPLE_SUB_PATH,\n    PROF_DIR=PROF_DIR,\n    FIG_DIR=FIG_DIR,\n    df_train_all=df_train_all,\n    df_test=df_test,\n))\n# ============================================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T13:02:17.490887Z","iopub.execute_input":"2026-01-15T13:02:17.491261Z","iopub.status.idle":"2026-01-15T13:02:58.880888Z","shell.execute_reply.started":"2026-01-15T13:02:17.491218Z","shell.execute_reply":"2026-01-15T13:02:58.879457Z"}},"outputs":[{"name":"stdout","text":"DATA_ROOT: /kaggle/input/recodai-luc-scientific-image-forgery-detection\n[WARN] Duplicate uid detected: 2377 uids (show up to 10): ['10' '10015' '10017' '10030' '10070' '1008' '10138' '10139' '10147'\n '10152']\ntrain_manifest: (2795, 9) | forged% = 100.0\ntest_manifest : (1, 4)\n\n[OK] Saved manifests & figures:\n - /kaggle/working/recodai_luc_prof/train_manifest.parquet\n - /kaggle/working/recodai_luc_prof/test_manifest.parquet\n - /kaggle/working/recodai_luc_prof/paths.json\n - figures: /kaggle/working/recodai_luc_prof/figures/stage0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Data Profiling & Sanity Checks","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 1 — Data Profiling & Sanity Checks (ONE CELL)\n# - Continues from STAGE 0 (uses df_train_all, df_test, PROF_DIR, paths.json)\n# - Outputs:\n#   * /kaggle/working/recodai_luc_prof/artifacts/profiles/stage1_profile.json\n#   * /kaggle/working/recodai_luc_prof/artifacts/profiles/bad_cases.csv\n#   * /kaggle/working/recodai_luc_prof/artifacts/profiles/mask_stats.parquet\n#   * Paper figures: /kaggle/working/recodai_luc_prof/figures/stage1/*.png\n# - Sanity checks:\n#   * image readable, size, mode\n#   * mask loadable, ndim (2D/3D), shape match vs image (incl transpose match)\n#   * forged missing masks\n#   * tiny masks & ambiguous masks sampling for article figures\n# ============================================================\n\nimport os, json, math, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require Stage 0 outputs (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\nif \"df_train_all\" not in globals() or \"df_test\" not in globals():\n    paths_path = PROF_DIR / \"paths.json\"\n    if not paths_path.exists():\n        raise RuntimeError(\"Missing Stage 0 artifacts. Run STAGE 0 first.\")\n    paths = json.loads(paths_path.read_text())\n    df_train_all = pd.read_parquet(paths[\"TRAIN_MANIFEST\"])\n    df_test = pd.read_parquet(paths[\"TEST_MANIFEST\"])\nelse:\n    paths_path = PROF_DIR / \"paths.json\"\n    paths = json.loads(paths_path.read_text()) if paths_path.exists() else {}\n\nART_DIR = PROF_DIR / \"artifacts\" / \"profiles\"\nART_DIR.mkdir(parents=True, exist_ok=True)\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage1\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Loaded:\", \"train\", df_train_all.shape, \"| test\", df_test.shape)\nprint(\"PROF_DIR:\", PROF_DIR)\nprint(\"FIG_DIR :\", FIG_DIR)\nprint(\"ART_DIR :\", ART_DIR)\n\n# ----------------------------\n# 1) Helpers\n# ----------------------------\ndef safe_open_image(path):\n    try:\n        im = Image.open(path)\n        im.load()\n        return im, None\n    except Exception as e:\n        return None, str(e)\n\ndef safe_load_mask(path):\n    try:\n        m = np.load(path)\n        return m, None\n    except Exception as e:\n        return None, str(e)\n\ndef binarize_mask(m):\n    if m.ndim == 3:\n        m2 = m.max(axis=0)\n    else:\n        m2 = m\n    m2 = (m2 > 0).astype(np.uint8)\n    return m2\n\ndef overlay_mask(img_rgb, mask01, alpha=0.45):\n    img = img_rgb.astype(np.float32) / 255.0\n    m = mask01.astype(bool)\n    out = img.copy()\n    out[m, 0] = (1 - alpha) * out[m, 0] + alpha * 1.0\n    out[m, 1] = (1 - alpha) * out[m, 1] + alpha * 0.0\n    out[m, 2] = (1 - alpha) * out[m, 2] + alpha * 0.0\n    return (out * 255).clip(0, 255).astype(np.uint8)\n\ndef savefig(path, dpi=300):\n    import matplotlib.pyplot as plt\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\ndef show_grid(items, titles=None, ncols=4, figsize=(14,10)):\n    import matplotlib.pyplot as plt\n    n = len(items)\n    if n == 0:\n        return\n    ncols = min(ncols, n)\n    nrows = int(math.ceil(n / ncols))\n    plt.figure(figsize=figsize)\n    for i, x in enumerate(items):\n        plt.subplot(nrows, ncols, i+1)\n        if x.ndim == 2:\n            plt.imshow(x, cmap=\"gray\")\n        else:\n            plt.imshow(x)\n        plt.axis(\"off\")\n        if titles is not None:\n            plt.title(str(titles[i]), fontsize=9)\n    plt.tight_layout()\n\n# ----------------------------\n# 2) Fast global checks\n# ----------------------------\nprofile = {}\nprofile[\"n_train\"] = int(len(df_train_all))\nprofile[\"n_test\"] = int(len(df_test))\nprofile[\"train_forged_pct\"] = float(df_train_all[\"y\"].mean() * 100.0) if \"y\" in df_train_all else None\nprofile[\"n_supplemental\"] = int(df_train_all.get(\"is_supplemental\", pd.Series([0]*len(df_train_all))).sum())\n\n# duplicates by uid / case_id\nprofile[\"dup_uid_count\"] = int(df_train_all[\"uid\"].duplicated().sum())\nprofile[\"dup_case_id_count\"] = int(df_train_all[\"case_id\"].duplicated().sum())\n\n# forged missing masks\nforged = df_train_all[df_train_all[\"y\"] == 1].copy()\nmissing_mask = forged[forged[\"mask_path\"].fillna(\"\").astype(str) == \"\"]\nprofile[\"forged_missing_mask_count\"] = int(len(missing_mask))\nprofile[\"forged_missing_mask_examples\"] = missing_mask[\"uid\"].head(10).tolist()\n\nprint(\"forged_missing_mask_count:\", profile[\"forged_missing_mask_count\"])\n\n# ----------------------------\n# 3) Sample-based integrity scan (images + masks)\n# ----------------------------\nSCAN_MAX = 2500  # keep it safe for Kaggle CPU\ndf_scan = df_train_all.sample(min(SCAN_MAX, len(df_train_all)), random_state=42).reset_index(drop=True)\n\nbad_rows = []\nmask_stats_rows = []\n\nimg_size_records = []\n\nfor i, r in df_scan.iterrows():\n    uid = r[\"uid\"]\n    ip = Path(r[\"img_path\"])\n    mp = Path(r[\"mask_path\"]) if str(r.get(\"mask_path\",\"\")) else None\n\n    im, err_img = safe_open_image(ip)\n    if err_img is not None:\n        bad_rows.append(dict(uid=uid, case_id=r[\"case_id\"], kind=\"image_open_fail\", path=str(ip), error=err_img))\n        continue\n\n    w, h = im.size\n    mode = im.mode\n    img_size_records.append((w, h, mode, int(r[\"y\"]), int(r.get(\"is_supplemental\", 0))))\n\n    # mask checks for forged with mask\n    if int(r[\"y\"]) == 1 and mp is not None and mp.exists():\n        m_raw, err_m = safe_load_mask(mp)\n        if err_m is not None:\n            bad_rows.append(dict(uid=uid, case_id=r[\"case_id\"], kind=\"mask_load_fail\", path=str(mp), error=err_m))\n            continue\n\n        m_ndim = int(m_raw.ndim)\n        m_shape = tuple(map(int, m_raw.shape))\n        m_bin = binarize_mask(m_raw)\n        mh, mw = m_bin.shape[:2]\n\n        match = \"match\" if (mh == h and mw == w) else (\"transpose_match\" if (mh == w and mw == h) else \"mismatch\")\n        area_px = int(m_bin.sum())\n        area_frac = float(area_px / (mh * mw + 1e-9))\n\n        # light intensity stats inside mask (for \"ambiguous\" examples)\n        # (works even without original)\n        gray = np.array(im.convert(\"L\"), dtype=np.float32)\n        if match == \"transpose_match\":\n            mb = m_bin.T\n        else:\n            mb = m_bin\n\n        if mb.shape != gray.shape:\n            inside_mean = np.nan\n            inside_std  = np.nan\n        else:\n            if mb.sum() == 0:\n                inside_mean = 0.0\n                inside_std  = 0.0\n            else:\n                vals = gray[mb.astype(bool)]\n                inside_mean = float(vals.mean())\n                inside_std  = float(vals.std())\n\n        mask_stats_rows.append(dict(\n            uid=uid,\n            case_id=r[\"case_id\"],\n            is_supplemental=int(r.get(\"is_supplemental\", 0)),\n            img_w=int(w), img_h=int(h), img_mode=str(mode),\n            mask_path=str(mp),\n            mask_ndim=m_ndim,\n            mask_shape=str(m_shape),\n            grid_match=match,\n            mask_w=int(mw), mask_h=int(mh),\n            area_px=area_px,\n            area_frac=area_frac,\n            inside_mean=inside_mean,\n            inside_std=inside_std,\n        ))\n\n        if match == \"mismatch\":\n            bad_rows.append(dict(uid=uid, case_id=r[\"case_id\"], kind=\"mask_image_shape_mismatch\",\n                                 path=str(mp), error=f\"img(h,w)=({h},{w}) mask(h,w)=({mh},{mw}) raw_shape={m_shape}\"))\n\n# summarize image size\nimg_sizes = pd.DataFrame(img_size_records, columns=[\"w\",\"h\",\"mode\",\"y\",\"is_supplemental\"])\nprofile[\"scan_n\"] = int(len(df_scan))\nprofile[\"scan_image_fail_count\"] = int(sum(1 for b in bad_rows if b[\"kind\"]==\"image_open_fail\"))\nprofile[\"scan_mask_fail_count\"] = int(sum(1 for b in bad_rows if b[\"kind\"]==\"mask_load_fail\"))\nprofile[\"scan_shape_mismatch_count\"] = int(sum(1 for b in bad_rows if b[\"kind\"]==\"mask_image_shape_mismatch\"))\n\n# save bad cases\nbad_df = pd.DataFrame(bad_rows)\nbad_path = ART_DIR / \"bad_cases.csv\"\nbad_df.to_csv(bad_path, index=False)\nprint(\"Saved:\", bad_path, \"| rows:\", len(bad_df))\n\n# save mask stats\nmask_stats_df = pd.DataFrame(mask_stats_rows)\nmask_stats_path = ART_DIR / \"mask_stats.parquet\"\nmask_stats_df.to_parquet(mask_stats_path, index=False)\nprint(\"Saved:\", mask_stats_path, \"| rows:\", len(mask_stats_df))\n\n# add more profile stats\nif len(img_sizes) > 0:\n    profile[\"img_mode_counts\"] = img_sizes[\"mode\"].value_counts().to_dict()\n    profile[\"img_w_minmax\"] = [int(img_sizes[\"w\"].min()), int(img_sizes[\"w\"].max())]\n    profile[\"img_h_minmax\"] = [int(img_sizes[\"h\"].min()), int(img_sizes[\"h\"].max())]\n\nif len(mask_stats_df) > 0:\n    profile[\"mask_ndim_counts\"] = mask_stats_df[\"mask_ndim\"].value_counts().to_dict()\n    profile[\"mask_match_counts\"] = mask_stats_df[\"grid_match\"].value_counts().to_dict()\n    profile[\"mask_area_frac_minmax\"] = [float(mask_stats_df[\"area_frac\"].min()), float(mask_stats_df[\"area_frac\"].max())]\n\n# save profile json\nprofile_path = ART_DIR / \"stage1_profile.json\"\nprofile_path.write_text(json.dumps(profile, indent=2))\nprint(\"Saved:\", profile_path)\n\n# ----------------------------\n# 4) Paper figures (Stage 1)\n# ----------------------------\nimport matplotlib.pyplot as plt\n\n# Fig1-A: Image size histogram (w and h)\nif len(img_sizes) > 0:\n    plt.figure(figsize=(6,4))\n    plt.hist(img_sizes[\"w\"].values, bins=40, alpha=0.7, label=\"width\")\n    plt.hist(img_sizes[\"h\"].values, bins=40, alpha=0.7, label=\"height\")\n    plt.xlabel(\"Pixels\")\n    plt.ylabel(\"Count\")\n    plt.title(\"Image size distribution (sample)\")\n    plt.legend()\n    savefig(FIG_DIR / \"Fig1-A_image_size_hist.png\")\n\n# Fig1-B: Mask area fraction histogram (log-friendly view)\nif len(mask_stats_df) > 0:\n    vals = mask_stats_df[\"area_frac\"].values\n    plt.figure(figsize=(6,4))\n    plt.hist(vals, bins=50)\n    plt.xlabel(\"Mask area (fraction of pixels)\")\n    plt.ylabel(\"Count\")\n    plt.title(\"GT mask area distribution (forged, sample)\")\n    savefig(FIG_DIR / \"Fig1-B_mask_area_frac_hist.png\")\n\n# Fig1-1: Tiny masks examples (overlay) — good for paper\n# define tiny = bottom 1% by area_px or area_frac\nif len(mask_stats_df) > 0:\n    ms = mask_stats_df.sort_values(\"area_px\").reset_index(drop=True)\n    take = min(12, len(ms))\n    tiny = ms.head(take)\n\n    items, titles = [], []\n    for _, rr in tiny.iterrows():\n        ip = df_train_all.loc[df_train_all[\"uid\"]==rr[\"uid\"], \"img_path\"].iloc[0]\n        img = np.array(Image.open(ip).convert(\"RGB\"))\n        mp = Path(rr[\"mask_path\"])\n        m = binarize_mask(np.load(mp))\n        # fix transpose match\n        if rr[\"grid_match\"] == \"transpose_match\":\n            m = m.T\n        ov = overlay_mask(img, m, alpha=0.45)\n        items.append(ov)\n        titles.append(f'{rr[\"case_id\"]} | area_px={int(rr[\"area_px\"])}')\n    show_grid(items, titles=titles, ncols=4, figsize=(14,10))\n    savefig(FIG_DIR / \"Fig1-1_tiny_mask_examples.png\")\n\n# Fig1-2: Coverage examples (small/medium/large)\nif len(mask_stats_df) > 0:\n    ms = mask_stats_df.sort_values(\"area_frac\").reset_index(drop=True)\n    idxs = []\n    for q in [0.05, 0.50, 0.95]:\n        idxs.append(int(q * (len(ms)-1)))\n    pick = ms.iloc[idxs].drop_duplicates(\"uid\")\n\n    items, titles = [], []\n    for _, rr in pick.iterrows():\n        ip = df_train_all.loc[df_train_all[\"uid\"]==rr[\"uid\"], \"img_path\"].iloc[0]\n        img = np.array(Image.open(ip).convert(\"RGB\"))\n        mp = Path(rr[\"mask_path\"])\n        m = binarize_mask(np.load(mp))\n        if rr[\"grid_match\"] == \"transpose_match\":\n            m = m.T\n        ov = overlay_mask(img, m, alpha=0.45)\n        items.append(ov)\n        titles.append(f'{rr[\"case_id\"]} | area_frac={rr[\"area_frac\"]:.4f}')\n    show_grid(items, titles=titles, ncols=3, figsize=(12,6))\n    savefig(FIG_DIR / \"Fig1-2_mask_coverage_examples.png\")\n\nprint(\"\\n[OK] Stage 1 complete.\")\nprint(\"Profile  :\", profile_path)\nprint(\"Bad cases:\", bad_path)\nprint(\"Mask stats:\", mask_stats_path)\nprint(\"Figures  :\", FIG_DIR)\n\n# Keep globals for next stages\nglobals().update(dict(\n    STAGE1_PROFILE=profile,\n    mask_stats_df=mask_stats_df,\n    bad_cases_df=bad_df,\n    STAGE1_ART_DIR=ART_DIR,\n    STAGE1_FIG_DIR=FIG_DIR,\n))\n# ============================================================\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T13:02:58.883216Z","iopub.execute_input":"2026-01-15T13:02:58.883537Z","iopub.status.idle":"2026-01-15T13:05:50.239881Z","shell.execute_reply.started":"2026-01-15T13:02:58.883509Z","shell.execute_reply":"2026-01-15T13:05:50.238710Z"}},"outputs":[{"name":"stdout","text":"Loaded: train (2795, 9) | test (1, 4)\nPROF_DIR: /kaggle/working/recodai_luc_prof\nFIG_DIR : /kaggle/working/recodai_luc_prof/figures/stage1\nART_DIR : /kaggle/working/recodai_luc_prof/artifacts/profiles\nforged_missing_mask_count: 0\nSaved: /kaggle/working/recodai_luc_prof/artifacts/profiles/bad_cases.csv | rows: 0\nSaved: /kaggle/working/recodai_luc_prof/artifacts/profiles/mask_stats.parquet | rows: 2500\nSaved: /kaggle/working/recodai_luc_prof/artifacts/profiles/stage1_profile.json\n\n[OK] Stage 1 complete.\nProfile  : /kaggle/working/recodai_luc_prof/artifacts/profiles/stage1_profile.json\nBad cases: /kaggle/working/recodai_luc_prof/artifacts/profiles/bad_cases.csv\nMask stats: /kaggle/working/recodai_luc_prof/artifacts/profiles/mask_stats.parquet\nFigures  : /kaggle/working/recodai_luc_prof/figures/stage1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# DINOv2 Feature Extraction","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 2 — DINOv2 Feature Extraction (Token-Grid Embedding) (ONE CELL)\n# - Embedding backbone: DINOv2-Base from /kaggle/input/dinov2/pytorch/base/1\n# - Produces per-image token-grid cache (.npz) for TRAIN + TEST\n# - Keeps artifacts consistent for next stages (mask training & inference)\n#\n# Outputs:\n#   /kaggle/working/recodai_luc/cache/dinov2_base_518_cfg_<hash>/\n#       cfg.json\n#       train/{uid}.npz   (tokens: float16 [Htok,Wtok,D])\n#       test/{uid}.npz\n#       tokens_manifest_train.parquet\n#       tokens_manifest_test.parquet\n#\n# Paper figures:\n#   /kaggle/working/recodai_luc_prof/figures/stage2/Fig2-2_patch_grid_overlay.png\n#   /kaggle/working/recodai_luc_prof/figures/stage2/Fig2-3_token_norm_heatmap.png\n# ============================================================\n\nimport os, gc, json, math, time, hashlib, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require STAGE 0 artifacts (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\n\npaths = json.loads(paths_path.read_text())\ndf_train_all = globals().get(\"df_train_all\", None)\ndf_test = globals().get(\"df_test\", None)\nif df_train_all is None:\n    df_train_all = pd.read_parquet(paths[\"TRAIN_MANIFEST\"])\nif df_test is None:\n    df_test = pd.read_parquet(paths[\"TEST_MANIFEST\"])\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage2\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Loaded manifests:\", df_train_all.shape, df_test.shape)\nprint(\"FIG_DIR:\", FIG_DIR)\n\n# ----------------------------\n# 1) Locate DINOv2 local model directory (prefer user path)\n# ----------------------------\nPREFERRED_MODEL_DIR = Path(\"/kaggle/input/dinov2/pytorch/base/1\")\n\ndef find_local_dinov2_dir():\n    # fallback: search /kaggle/input for a HF-style directory containing pytorch_model.bin + config.json\n    base = Path(\"/kaggle/input\")\n    cands = []\n    for d in base.rglob(\"pytorch_model.bin\"):\n        parent = d.parent\n        if (parent / \"config.json\").exists():\n            # heuristic: name contains \"dino\" somewhere\n            if \"dino\" in str(parent).lower():\n                cands.append(parent)\n    # prefer shortest path / most direct\n    cands = sorted(cands, key=lambda p: (len(str(p)), str(p)))\n    return cands[0] if cands else None\n\nMODEL_DIR = PREFERRED_MODEL_DIR if PREFERRED_MODEL_DIR.exists() else find_local_dinov2_dir()\nif MODEL_DIR is None or (not MODEL_DIR.exists()):\n    raise RuntimeError(\n        \"Could not find local DINOv2 model directory.\\n\"\n        \"Expected: /kaggle/input/dinov2/pytorch/base/1\\n\"\n        \"Or a directory containing pytorch_model.bin + config.json under /kaggle/input.\"\n    )\n\nprint(\"MODEL_DIR:\", MODEL_DIR)\n\n# ----------------------------\n# 2) Load model + processor\n# ----------------------------\nimport torch\n\ntry:\n    from transformers import AutoImageProcessor, AutoModel\nexcept Exception as e:\n    raise RuntimeError(\n        \"transformers is not available in this environment. \"\n        \"Please ensure 'transformers' is installed in Kaggle.\"\n    ) from e\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nprocessor = AutoImageProcessor.from_pretrained(str(MODEL_DIR))\nmodel = AutoModel.from_pretrained(str(MODEL_DIR))\nmodel.eval().to(device)\n\n# enforce fixed input size (important for stable token grid)\nINPUT_SIZE = 518  # recommended for patch=14 => 37x37 grid\n# Many processors support these attributes; set defensively.\nfor attr, val in [\n    (\"do_resize\", True),\n    (\"do_center_crop\", True),\n]:\n    if hasattr(processor, attr):\n        setattr(processor, attr, val)\n\n# set resize/crop size if supported\n# processor.size may be int or dict; we enforce dict\nif hasattr(processor, \"size\"):\n    try:\n        processor.size = {\"height\": INPUT_SIZE, \"width\": INPUT_SIZE}\n    except Exception:\n        pass\nif hasattr(processor, \"crop_size\"):\n    try:\n        processor.crop_size = {\"height\": INPUT_SIZE, \"width\": INPUT_SIZE}\n    except Exception:\n        pass\n\n# Patch size (best effort)\npatch_size = None\nif hasattr(model, \"config\") and hasattr(model.config, \"patch_size\"):\n    patch_size = int(model.config.patch_size)\nelif hasattr(model, \"config\") and hasattr(model.config, \"vit_patch_size\"):\n    patch_size = int(model.config.vit_patch_size)\nelse:\n    patch_size = 14  # dinov2-base default\n\n# ----------------------------\n# 3) Cache directory (hash config for reproducibility)\n# ----------------------------\nCFG = {\n    \"model_dir\": str(MODEL_DIR),\n    \"input_size\": int(INPUT_SIZE),\n    \"patch_size\": int(patch_size),\n    \"dtype\": \"float16\",\n    \"tokens\": \"patch_tokens_only (exclude CLS)\",\n    \"processor_class\": processor.__class__.__name__,\n    \"model_class\": model.__class__.__name__,\n}\ncfg_id = hashlib.md5(json.dumps(CFG, sort_keys=True).encode()).hexdigest()[:12]\n\nCACHE_ROOT = Path(\"/kaggle/working/recodai_luc/cache\") / f\"dinov2_base_518_cfg_{cfg_id}\"\nTRAIN_OUT = CACHE_ROOT / \"train\"\nTEST_OUT  = CACHE_ROOT / \"test\"\nTRAIN_OUT.mkdir(parents=True, exist_ok=True)\nTEST_OUT.mkdir(parents=True, exist_ok=True)\n(CACHE_ROOT / \"cfg.json\").write_text(json.dumps(CFG, indent=2))\n\nprint(\"CACHE_ROOT:\", CACHE_ROOT)\n\n# ----------------------------\n# 4) Dataset + DataLoader\n# ----------------------------\nfrom torch.utils.data import Dataset, DataLoader\n\nclass ImgDataset(Dataset):\n    def __init__(self, df):\n        self.df = df.reset_index(drop=True)\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        uid = str(r[\"uid\"])\n        ip = str(r[\"img_path\"])\n        return uid, r.get(\"case_id\", uid), ip\n\ndef collate_fn(batch):\n    uids, case_ids, img_paths = zip(*batch)\n    images = [Image.open(p).convert(\"RGB\") for p in img_paths]\n    inputs = processor(images=images, return_tensors=\"pt\")\n    return list(uids), list(case_ids), list(img_paths), inputs\n\nBATCH_SIZE = 8 if device.type == \"cuda\" else 4\nNUM_WORKERS = 2  # safe default on Kaggle\nPIN_MEMORY = (device.type == \"cuda\")\n\n# ----------------------------\n# 5) Extract + Save tokens (resume-safe)\n# ----------------------------\n@torch.no_grad()\ndef extract_split(df, out_dir: Path, split_name: str):\n    ds = ImgDataset(df)\n    dl = DataLoader(\n        ds,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=PIN_MEMORY,\n        collate_fn=collate_fn,\n        drop_last=False,\n    )\n\n    rows = []\n    n_total = len(df)\n    n_done = 0\n    t0 = time.time()\n\n    for uids, case_ids, img_paths, inputs in dl:\n        # skip existing\n        to_run = []\n        run_idx = []\n        for i, uid in enumerate(uids):\n            op = out_dir / f\"{uid}.npz\"\n            if op.exists():\n                # still record manifest row\n                rows.append(dict(\n                    uid=uid, case_id=str(case_ids[i]), split=split_name,\n                    img_path=str(img_paths[i]), tokens_path=str(op),\n                ))\n            else:\n                to_run.append(i)\n                run_idx.append(i)\n\n        if len(to_run) > 0:\n            # subset inputs\n            pix = inputs[\"pixel_values\"][to_run].to(device, non_blocking=True)\n\n            out = model(pixel_values=pix)\n            # transformers ViT-style: last_hidden_state [B, 1+N, D]\n            hs = out.last_hidden_state\n            patch = hs[:, 1:, :]  # exclude CLS\n            B, N, D = patch.shape\n            g = int(round(math.sqrt(N)))\n            if g * g != N:\n                # fallback: derive from input size / patch size\n                g2 = INPUT_SIZE // patch_size\n                if g2 * g2 == N:\n                    g = g2\n                else:\n                    raise RuntimeError(\n                        f\"Token count N={N} is not a perfect square and cannot be resolved. \"\n                        f\"Check preprocessing/INPUT_SIZE. (g~{g}, g2={g2}, patch={patch_size})\"\n                    )\n            Htok = Wtok = g\n\n            tok = patch.reshape(B, Htok, Wtok, D).detach().float().cpu().numpy().astype(np.float16)\n\n            for j, bi in enumerate(to_run):\n                uid = uids[bi]\n                op = out_dir / f\"{uid}.npz\"\n                np.savez_compressed(op, tokens=tok[j], Htok=Htok, Wtok=Wtok, D=D)\n                rows.append(dict(\n                    uid=str(uid), case_id=str(case_ids[bi]), split=split_name,\n                    img_path=str(img_paths[bi]), tokens_path=str(op),\n                ))\n\n        n_done += len(uids)\n        if n_done % max(64, BATCH_SIZE * 8) == 0:\n            dt = time.time() - t0\n            print(f\"[{split_name}] {n_done}/{n_total} done | {dt/60:.1f} min\")\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n        gc.collect()\n\n    dfm = pd.DataFrame(rows).drop_duplicates(subset=[\"uid\"], keep=\"last\").reset_index(drop=True)\n    # attach token meta from one sample\n    if len(dfm) > 0:\n        # read one file\n        s = np.load(dfm[\"tokens_path\"].iloc[0])\n        dfm[\"tok_h\"] = int(s[\"Htok\"])\n        dfm[\"tok_w\"] = int(s[\"Wtok\"])\n        dfm[\"tok_d\"] = int(s[\"D\"])\n    return dfm\n\nprint(\"Extracting TRAIN tokens...\")\nman_train = extract_split(df_train_all, TRAIN_OUT, \"train\")\n\nprint(\"Extracting TEST tokens...\")\nman_test = extract_split(df_test, TEST_OUT, \"test\")\n\n# Save manifests\nman_train_path = CACHE_ROOT / \"tokens_manifest_train.parquet\"\nman_test_path  = CACHE_ROOT / \"tokens_manifest_test.parquet\"\nman_train.to_parquet(man_train_path, index=False)\nman_test.to_parquet(man_test_path, index=False)\n\nprint(\"\\n[OK] Saved token manifests:\")\nprint(\" -\", man_train_path, \"| rows:\", len(man_train))\nprint(\" -\", man_test_path,  \"| rows:\", len(man_test))\n\n# ----------------------------\n# 6) Stage 2 paper figures (grid overlay + token norm heatmap)\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\n# pick one sample (prefer forged with mask, else any)\npick_uid = None\nif \"y\" in df_train_all.columns and (df_train_all[\"y\"]==1).any():\n    pick_uid = df_train_all[df_train_all[\"y\"]==1][\"uid\"].iloc[0]\nelse:\n    pick_uid = df_train_all[\"uid\"].iloc[0]\n\npick_row = df_train_all[df_train_all[\"uid\"]==pick_uid].iloc[0]\nimg = Image.open(pick_row[\"img_path\"]).convert(\"RGB\")\n\n# Create a resized copy to INPUT_SIZE for visualization\nimg_resized = img.resize((INPUT_SIZE, INPUT_SIZE), Image.BICUBIC)\nimg_np = np.array(img_resized)\n\n# Determine grid size from cached token\ntok_npz = np.load(TRAIN_OUT / f\"{pick_uid}.npz\")\nHtok = int(tok_npz[\"Htok\"])\nWtok = int(tok_npz[\"Wtok\"])\ntokens = tok_npz[\"tokens\"].astype(np.float32)  # [H,W,D]\n\n# Fig2-2: patch grid overlay\nplt.figure(figsize=(7,7))\nplt.imshow(img_np)\nfor i in range(1, Wtok):\n    x = i * (INPUT_SIZE / Wtok)\n    plt.plot([x, x], [0, INPUT_SIZE], linewidth=0.7)\nfor j in range(1, Htok):\n    y = j * (INPUT_SIZE / Htok)\n    plt.plot([0, INPUT_SIZE], [y, y], linewidth=0.7)\nplt.axis(\"off\")\nplt.title(f\"Patch-token grid overlay ({Htok}×{Wtok}) | uid={pick_uid}\")\nsavefig(FIG_DIR / \"Fig2-2_patch_grid_overlay.png\")\n\n# Fig2-3: token norm heatmap\nnorm_map = np.linalg.norm(tokens, axis=-1)  # [H,W]\nplt.figure(figsize=(7,6))\nplt.imshow(norm_map, cmap=\"magma\")\nplt.colorbar(fraction=0.046, pad=0.04)\nplt.title(f\"Token L2-norm heatmap | uid={pick_uid}\")\nplt.axis(\"off\")\nsavefig(FIG_DIR / \"Fig2-3_token_norm_heatmap.png\")\n\nprint(\"\\n[OK] Stage 2 figures saved to:\", FIG_DIR)\n\n# ----------------------------\n# 7) Keep globals for next stages\n# ----------------------------\nglobals().update(dict(\n    DINO_MODEL_DIR=MODEL_DIR,\n    DINO_PROCESSOR=processor,\n    DINO_MODEL=model,\n    DINO_CFG=CFG,\n    CFG_ID=cfg_id,\n    CACHE_ROOT=CACHE_ROOT,\n    TOKENS_MANIFEST_TRAIN=man_train_path,\n    TOKENS_MANIFEST_TEST=man_test_path,\n    man_train=man_train,\n    man_test=man_test,\n    TOK_H=int(man_train[\"tok_h\"].iloc[0]) if len(man_train) else None,\n    TOK_W=int(man_train[\"tok_w\"].iloc[0]) if len(man_train) else None,\n    TOK_D=int(man_train[\"tok_d\"].iloc[0]) if len(man_train) else None,\n))\n# ============================================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T13:05:50.241341Z","iopub.execute_input":"2026-01-15T13:05:50.241681Z","execution_failed":"2026-01-15T13:25:43.799Z"}},"outputs":[{"name":"stdout","text":"Loaded manifests: (2795, 9) (1, 4)\nFIG_DIR: /kaggle/working/recodai_luc_prof/figures/stage2\nMODEL_DIR: /kaggle/input/dinov2/pytorch/base/1\n","output_type":"stream"},{"name":"stderr","text":"2026-01-15 13:06:10.383285: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768482370.659493      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768482370.741634      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768482371.350164      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768482371.350253      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768482371.350257      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768482371.350260      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"name":"stdout","text":"Device: cpu\nCACHE_ROOT: /kaggle/working/recodai_luc/cache/dinov2_base_518_cfg_3be27f67a798\nExtracting TRAIN tokens...\n[train] 64/2795 done | 3.7 min\n[train] 128/2795 done | 7.4 min\n[train] 192/2795 done | 11.1 min\n[train] 256/2795 done | 14.8 min\n[train] 320/2795 done | 18.5 min\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Ground Truth Preparation on Token Grid","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 3 — Ground Truth Preparation on Token Grid (ONE CELL)\n# - Continues from STAGE 0 + STAGE 2 (uses train_manifest + tokens cache)\n# - Creates token-grid GT masks (Htok x Wtok) aligned to each image/mask\n#\n# Outputs:\n#   /kaggle/working/recodai_luc/cache/dinov2_base_518_cfg_<hash>/grid_masks_train/{uid}.npy\n#   /kaggle/working/recodai_luc/cache/dinov2_base_518_cfg_<hash>/gridmask_manifest_train.parquet\n#   /kaggle/working/recodai_luc_prof/train_manifest_with_gridmask.parquet\n#   /kaggle/working/recodai_luc_prof/artifacts/profiles/stage3_gridmask_profile.json\n#\n# Paper figures:\n#   /kaggle/working/recodai_luc_prof/figures/stage3/Fig3-1_full_vs_grid_examples.png\n#   /kaggle/working/recodai_luc_prof/figures/stage3/Fig3-2_grid_area_hist.png\n# ============================================================\n\nimport os, json, math, warnings, hashlib\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require STAGE 0 artifacts (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\npaths = json.loads(paths_path.read_text())\n\ndf_train_all = globals().get(\"df_train_all\", None)\nif df_train_all is None:\n    df_train_all = pd.read_parquet(paths[\"TRAIN_MANIFEST\"])\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage3\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nART_PROF_DIR = PROF_DIR / \"artifacts\" / \"profiles\"\nART_PROF_DIR.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# 1) Locate token cache root from STAGE 2 (robust auto-pick)\n# ----------------------------\ndef pick_token_cache_root():\n    # Prefer globals from Stage2 if present\n    if \"CACHE_ROOT\" in globals():\n        cr = Path(globals()[\"CACHE_ROOT\"])\n        if (cr / \"tokens_manifest_train.parquet\").exists():\n            return cr\n    # Else search /kaggle/working/recodai_luc/cache\n    base = Path(\"/kaggle/working/recodai_luc/cache\")\n    if not base.exists():\n        raise RuntimeError(\"Token cache base not found. Run STAGE 2 first.\")\n    cands = []\n    for d in base.glob(\"dinov2_base_518_cfg_*\"):\n        if (d / \"tokens_manifest_train.parquet\").exists():\n            # score by number of token files in train/\n            nfiles = len(list((d / \"train\").glob(\"*.npz\")))\n            cands.append((nfiles, d))\n    if not cands:\n        raise RuntimeError(\"No valid token cache found. Run STAGE 2 first.\")\n    cands.sort(reverse=True, key=lambda x: x[0])\n    return cands[0][1]\n\nCACHE_ROOT = pick_token_cache_root()\nTOK_MAN_TRAIN = CACHE_ROOT / \"tokens_manifest_train.parquet\"\nman_train = pd.read_parquet(TOK_MAN_TRAIN)\n\nprint(\"CACHE_ROOT:\", CACHE_ROOT)\nprint(\"Token manifest train:\", man_train.shape)\n\n# Read token grid shape from one sample\nsample_npz = np.load(man_train[\"tokens_path\"].iloc[0])\nHtok = int(sample_npz[\"Htok\"])\nWtok = int(sample_npz[\"Wtok\"])\nDtok = int(sample_npz[\"D\"])\nprint(f\"Token grid: Htok={Htok}, Wtok={Wtok}, D={Dtok}\")\n\n# ----------------------------\n# 2) Grid-mask output dir (resume-safe)\n# ----------------------------\nGRID_DIR = CACHE_ROOT / \"grid_masks_train\"\nGRID_DIR.mkdir(parents=True, exist_ok=True)\n\nGRID_CFG = dict(\n    cache_root=str(CACHE_ROOT),\n    grid_dir=str(GRID_DIR),\n    Htok=Htok, Wtok=Wtok,\n    method=\"full_mask -> align (transpose if needed) -> resize to (Wtok,Htok) with NEAREST -> binarize\",\n)\n(CACHE_ROOT / \"gridmask_cfg.json\").write_text(json.dumps(GRID_CFG, indent=2))\n\n# ----------------------------\n# 3) Helpers\n# ----------------------------\ndef load_mask_as_bin(mask_path: Path):\n    m = np.load(mask_path)\n    if m.ndim == 3:\n        m = m.max(axis=0)\n    return (m > 0).astype(np.uint8)\n\ndef align_mask_to_image(mask01: np.ndarray, img_w: int, img_h: int):\n    \"\"\"\n    Returns aligned mask (H,W) to match image orientation as best as possible.\n    \"\"\"\n    mh, mw = mask01.shape[:2]\n    if (mh == img_h) and (mw == img_w):\n        return mask01, \"match\"\n    if (mh == img_w) and (mw == img_h):\n        return mask01.T, \"transpose_match\"\n    # fallback: resize mask to image size (nearest)\n    m_img = Image.fromarray((mask01 * 255).astype(np.uint8), mode=\"L\")\n    m_res = m_img.resize((img_w, img_h), resample=Image.NEAREST)\n    return (np.array(m_res) > 0).astype(np.uint8), \"resized_to_match\"\n\ndef downsample_to_grid(mask01_hw: np.ndarray, Wtok: int, Htok: int):\n    m_img = Image.fromarray((mask01_hw * 255).astype(np.uint8), mode=\"L\")\n    m_small = m_img.resize((Wtok, Htok), resample=Image.NEAREST)\n    return (np.array(m_small) > 0).astype(np.uint8)\n\ndef overlay_mask(img_rgb, mask01, alpha=0.45):\n    img = img_rgb.astype(np.float32) / 255.0\n    m = mask01.astype(bool)\n    out = img.copy()\n    out[m, 0] = (1 - alpha) * out[m, 0] + alpha * 1.0\n    out[m, 1] = (1 - alpha) * out[m, 1] + alpha * 0.0\n    out[m, 2] = (1 - alpha) * out[m, 2] + alpha * 0.0\n    return (out * 255).clip(0, 255).astype(np.uint8)\n\n# ----------------------------\n# 4) Build grid masks for all train rows (resume-safe)\n# ----------------------------\ndf = df_train_all.copy().reset_index(drop=True)\ndf[\"mask_path\"] = df.get(\"mask_path\", \"\").fillna(\"\").astype(str)\n\nrows = []\nstats = {\n    \"n_train\": int(len(df)),\n    \"n_forged\": int((df[\"y\"] == 1).sum()),\n    \"n_authentic\": int((df[\"y\"] == 0).sum()),\n    \"n_forged_missing_mask\": int(((df[\"y\"]==1) & (df[\"mask_path\"]==\"\")).sum()),\n    \"align_counts\": {\"match\":0, \"transpose_match\":0, \"resized_to_match\":0, \"no_mask\":0},\n    \"written\": 0,\n    \"skipped_existing\": 0,\n}\n\nt0 = time.time() if \"time\" in globals() else None\n\nfor i, r in df.iterrows():\n    uid = str(r[\"uid\"])\n    case_id = str(r[\"case_id\"])\n    y = int(r[\"y\"])\n    ip = Path(r[\"img_path\"])\n    mp = Path(r[\"mask_path\"]) if (y == 1 and str(r[\"mask_path\"])) else None\n\n    out_p = GRID_DIR / f\"{uid}.npy\"\n    if out_p.exists():\n        stats[\"skipped_existing\"] += 1\n        # still record\n        m_grid = np.load(out_p)\n        rows.append(dict(\n            uid=uid, case_id=case_id, y=y,\n            gridmask_path=str(out_p),\n            grid_area_px=int(m_grid.sum()),\n            grid_area_frac=float(m_grid.mean()),\n            align=\"cached\",\n        ))\n        continue\n\n    # open image size (needed for alignment)\n    try:\n        im = Image.open(ip)\n        w, h = im.size\n    except Exception:\n        # if image unreadable, fallback to zero mask\n        m_grid = np.zeros((Htok, Wtok), dtype=np.uint8)\n        np.save(out_p, m_grid)\n        stats[\"written\"] += 1\n        rows.append(dict(\n            uid=uid, case_id=case_id, y=y,\n            gridmask_path=str(out_p),\n            grid_area_px=0, grid_area_frac=0.0,\n            align=\"image_open_fail->zero\",\n        ))\n        continue\n\n    if y == 0 or mp is None or (not mp.exists()):\n        # authentic or missing mask => all-zero\n        m_grid = np.zeros((Htok, Wtok), dtype=np.uint8)\n        np.save(out_p, m_grid)\n        stats[\"align_counts\"][\"no_mask\"] += 1\n        stats[\"written\"] += 1\n        rows.append(dict(\n            uid=uid, case_id=case_id, y=y,\n            gridmask_path=str(out_p),\n            grid_area_px=0, grid_area_frac=0.0,\n            align=\"no_mask\",\n        ))\n        continue\n\n    # forged with mask\n    try:\n        m = load_mask_as_bin(mp)\n    except Exception:\n        m_grid = np.zeros((Htok, Wtok), dtype=np.uint8)\n        np.save(out_p, m_grid)\n        stats[\"written\"] += 1\n        rows.append(dict(\n            uid=uid, case_id=case_id, y=y,\n            gridmask_path=str(out_p),\n            grid_area_px=0, grid_area_frac=0.0,\n            align=\"mask_load_fail->zero\",\n        ))\n        continue\n\n    m_aligned, how = align_mask_to_image(m, w, h)\n    stats[\"align_counts\"][how] = stats[\"align_counts\"].get(how, 0) + 1\n\n    m_grid = downsample_to_grid(m_aligned, Wtok=Wtok, Htok=Htok)\n\n    np.save(out_p, m_grid.astype(np.uint8))\n    stats[\"written\"] += 1\n\n    rows.append(dict(\n        uid=uid, case_id=case_id, y=y,\n        gridmask_path=str(out_p),\n        grid_area_px=int(m_grid.sum()),\n        grid_area_frac=float(m_grid.mean()),\n        align=how,\n    ))\n\n    if (i+1) % 500 == 0:\n        print(f\"[gridmask] {i+1}/{len(df)}\")\n\ngridman = pd.DataFrame(rows)\ngridman_path = CACHE_ROOT / \"gridmask_manifest_train.parquet\"\ngridman.to_parquet(gridman_path, index=False)\n\n# Merge into train manifest for downstream stages\ndf_train_with_grid = df.merge(gridman[[\"uid\",\"gridmask_path\",\"grid_area_px\",\"grid_area_frac\",\"align\"]],\n                              on=\"uid\", how=\"left\")\n\ntrain_with_grid_path = PROF_DIR / \"train_manifest_with_gridmask.parquet\"\ndf_train_with_grid.to_parquet(train_with_grid_path, index=False)\n\n# Save profile\nstats[\"grid_area_frac_minmax\"] = [float(gridman[\"grid_area_frac\"].min()), float(gridman[\"grid_area_frac\"].max())]\nstats[\"grid_area_px_minmax\"] = [int(gridman[\"grid_area_px\"].min()), int(gridman[\"grid_area_px\"].max())]\nprofile_path = ART_PROF_DIR / \"stage3_gridmask_profile.json\"\nprofile_path.write_text(json.dumps(stats, indent=2))\n\nprint(\"\\n[OK] Saved:\")\nprint(\" -\", gridman_path)\nprint(\" -\", train_with_grid_path)\nprint(\" -\", profile_path)\n\n# ----------------------------\n# 5) Paper figures (Stage 3)\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\ndef show_grid(items, titles=None, ncols=3, figsize=(14,10)):\n    n = len(items)\n    if n == 0:\n        return\n    ncols = min(ncols, n)\n    nrows = int(math.ceil(n / ncols))\n    plt.figure(figsize=figsize)\n    for i, x in enumerate(items):\n        plt.subplot(nrows, ncols, i+1)\n        if x.ndim == 2:\n            plt.imshow(x, cmap=\"gray\")\n        else:\n            plt.imshow(x)\n        plt.axis(\"off\")\n        if titles is not None:\n            plt.title(str(titles[i]), fontsize=9)\n    plt.tight_layout()\n\n# Fig3-2: grid area histogram (for forged)\ng_f = gridman[gridman[\"y\"]==1].copy()\nplt.figure(figsize=(6,4))\nplt.hist(g_f[\"grid_area_frac\"].values, bins=40)\nplt.xlabel(\"Grid-mask area (fraction of cells)\")\nplt.ylabel(\"Count\")\nplt.title(\"Grid GT mask area distribution (forged)\")\nsavefig(FIG_DIR / \"Fig3-2_grid_area_hist.png\")\n\n# Fig3-1: full-res vs grid-res qualitative examples (pick tiny/medium/large by FULL area proxy)\n# We use grid_area_frac for selection (fast & consistent)\ncand = df_train_with_grid[(df_train_with_grid[\"y\"]==1) & (df_train_with_grid[\"mask_path\"]!=\"\")].copy()\nif len(cand) > 0:\n    cand = cand.sort_values(\"grid_area_frac\").reset_index(drop=True)\n    picks = []\n    for q in [0.02, 0.08, 0.25, 0.50, 0.75, 0.95]:\n        picks.append(int(q * (len(cand)-1)))\n    picks = sorted(set(picks))\n    sel = cand.iloc[picks].copy()\n\n    items, titles = [], []\n    for _, r in sel.iterrows():\n        uid = str(r[\"uid\"])\n        ip = Path(r[\"img_path\"])\n        mp = Path(r[\"mask_path\"])\n        img = np.array(Image.open(ip).convert(\"RGB\"))\n        w, h = Image.open(ip).size\n\n        # full-res mask aligned\n        m = load_mask_as_bin(mp)\n        m_aligned, how = align_mask_to_image(m, w, h)\n\n        # grid mask + upsample back to image size for visualization\n        mg = np.load(Path(r[\"gridmask_path\"]))\n        mg_img = Image.fromarray((mg*255).astype(np.uint8), mode=\"L\").resize((w, h), resample=Image.NEAREST)\n        mg_up = (np.array(mg_img) > 0).astype(np.uint8)\n\n        items.append(img)\n        titles.append(f\"{uid} | image\")\n\n        items.append(overlay_mask(img, m_aligned, alpha=0.45))\n        titles.append(f\"{uid} | full GT ({how})\")\n\n        items.append(overlay_mask(img, mg_up, alpha=0.45))\n        titles.append(f\"{uid} | grid GT upsampled\")\n\n    show_grid(items, titles=titles, ncols=3, figsize=(14, 18))\n    savefig(FIG_DIR / \"Fig3-1_full_vs_grid_examples.png\")\n\nprint(\"[OK] Stage 3 figures saved to:\", FIG_DIR)\n\n# ----------------------------\n# 6) Keep globals for next stages\n# ----------------------------\nglobals().update(dict(\n    CACHE_ROOT=CACHE_ROOT,\n    GRID_DIR=GRID_DIR,\n    GRIDMAN_TRAIN=gridman_path,\n    TRAIN_MANIFEST_WITH_GRID=train_with_grid_path,\n    Htok=Htok, Wtok=Wtok, Dtok=Dtok,\n    df_train_with_grid=df_train_with_grid,\n))\n# ============================================================\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-15T13:25:43.802Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Leakage-Safe Cross-Validation Split","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 4 — Leakage-Safe Cross-Validation Split (ONE CELL)\n# - GroupKFold by case_id (leakage-safe)\n# - Writes fold assignment back into train manifest (with gridmask paths)\n#\n# Outputs:\n#   /kaggle/working/recodai_luc_prof/folds.parquet\n#   /kaggle/working/recodai_luc_prof/train_manifest_with_gridmask_folds.parquet\n#   /kaggle/working/recodai_luc_prof/artifacts/folds/fold_summary.json\n#\n# Paper figure:\n#   /kaggle/working/recodai_luc_prof/figures/stage4/Fig4-1_fold_distribution.png\n# ============================================================\n\nimport os, json, math, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require STAGE 3 outputs (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\npaths = json.loads(paths_path.read_text())\n\ntrain_with_grid_path = Path(globals().get(\"TRAIN_MANIFEST_WITH_GRID\", PROF_DIR / \"train_manifest_with_gridmask.parquet\"))\nif not train_with_grid_path.exists():\n    raise RuntimeError(\"Missing train_manifest_with_gridmask.parquet. Run STAGE 3 first.\")\ndf_train = pd.read_parquet(train_with_grid_path)\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage4\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nART_DIR = PROF_DIR / \"artifacts\" / \"folds\"\nART_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Loaded:\", df_train.shape, \"from\", train_with_grid_path)\n\n# ----------------------------\n# 1) Ensure group key exists\n# ----------------------------\nif \"case_id\" not in df_train.columns:\n    raise RuntimeError(\"case_id missing in train manifest. Ensure STAGE 0 created case_id.\")\n\ndf_train[\"case_id\"] = df_train[\"case_id\"].astype(str)\ndf_train[\"uid\"] = df_train[\"uid\"].astype(str)\n\n# If you want a stronger grouping rule, you can transform case_id here.\n# Current dataset shown uses numeric filenames => case_id == uid => still safe.\n\n# ----------------------------\n# 2) Create GroupKFold split\n# ----------------------------\nN_FOLDS = 5  # adjust if needed\n\n# If there are fewer groups than folds, reduce folds\nn_groups = df_train[\"case_id\"].nunique()\nif n_groups < N_FOLDS:\n    N_FOLDS = max(2, n_groups)\n    print(f\"[WARN] Reduced N_FOLDS to {N_FOLDS} because n_groups={n_groups}\")\n\ntry:\n    from sklearn.model_selection import GroupKFold\nexcept Exception as e:\n    raise RuntimeError(\"scikit-learn not available. Please add it to your Kaggle environment.\") from e\n\ngkf = GroupKFold(n_splits=N_FOLDS)\n\nfold = np.full(len(df_train), -1, dtype=int)\nX_dummy = np.zeros((len(df_train), 1), dtype=np.float32)\ny_dummy = df_train[\"y\"].values if \"y\" in df_train.columns else np.zeros(len(df_train))\n\nfor k, (_, va_idx) in enumerate(gkf.split(X_dummy, y_dummy, groups=df_train[\"case_id\"].values)):\n    fold[va_idx] = k\n\ndf_train[\"fold\"] = fold\nif (df_train[\"fold\"] < 0).any():\n    raise RuntimeError(\"Internal error: some rows did not receive a fold assignment.\")\n\n# ----------------------------\n# 3) Fold summary + leakage checks\n# ----------------------------\nsummary = []\nfor k in range(N_FOLDS):\n    d = df_train[df_train[\"fold\"] == k]\n    summary.append(dict(\n        fold=int(k),\n        n=int(len(d)),\n        forged_pct=float(d[\"y\"].mean() * 100.0) if \"y\" in d.columns and len(d) else 0.0,\n        n_groups=int(d[\"case_id\"].nunique()),\n    ))\n\n# leakage check: no group appears in more than one fold\ngrp_to_fold = df_train.groupby(\"case_id\")[\"fold\"].nunique()\nleak_groups = grp_to_fold[grp_to_fold > 1]\nif len(leak_groups) > 0:\n    # should never happen with GroupKFold\n    raise RuntimeError(f\"Leakage detected: {len(leak_groups)} groups appear in multiple folds!\")\n\nfold_summary = dict(\n    n_folds=int(N_FOLDS),\n    n_train=int(len(df_train)),\n    n_groups=int(n_groups),\n    folds=summary,\n    forged_pct_overall=float(df_train[\"y\"].mean() * 100.0) if \"y\" in df_train.columns else None,\n)\n\n(ART_DIR / \"fold_summary.json\").write_text(json.dumps(fold_summary, indent=2))\n\n# Save folds file\ndf_folds = df_train[[\"uid\", \"case_id\", \"fold\"]].copy()\nfolds_path = PROF_DIR / \"folds.parquet\"\ndf_folds.to_parquet(folds_path, index=False)\n\n# Save updated train manifest\ntrain_with_folds_path = PROF_DIR / \"train_manifest_with_gridmask_folds.parquet\"\ndf_train.to_parquet(train_with_folds_path, index=False)\n\nprint(\"\\n[OK] Saved:\")\nprint(\" -\", folds_path)\nprint(\" -\", train_with_folds_path)\nprint(\" -\", ART_DIR / \"fold_summary.json\")\n\n# ----------------------------\n# 4) Paper figure: fold distribution\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\nfold_df = pd.DataFrame(summary)\n\nplt.figure(figsize=(7,4))\nplt.bar(fold_df[\"fold\"].astype(str), fold_df[\"n\"].values)\nplt.xlabel(\"Fold\")\nplt.ylabel(\"Samples\")\nplt.title(\"Fold distribution (samples per fold)\")\nsavefig(FIG_DIR / \"Fig4-1_fold_counts.png\")\n\nplt.figure(figsize=(7,4))\nplt.plot(fold_df[\"fold\"].values, fold_df[\"forged_pct\"].values, marker=\"o\")\nplt.xlabel(\"Fold\")\nplt.ylabel(\"Forged %\")\nplt.title(\"Fold distribution (forged ratio per fold)\")\nsavefig(FIG_DIR / \"Fig4-1_forged_ratio.png\")\n\nprint(\"[OK] Figures saved to:\", FIG_DIR)\n\n# Keep globals for next stages\nglobals().update(dict(\n    N_FOLDS=N_FOLDS,\n    df_train_folds=df_train,\n    FOLDS_PATH=folds_path,\n    TRAIN_MANIFEST_WITH_FOLDS=train_with_folds_path,\n    FOLD_SUMMARY=fold_summary,\n))\n# ============================================================\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-15T13:25:43.803Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Segmentation Decoder","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 5 — Train Segmentation Decoder (Model A) (ONE CELL)\n# - Uses cached DINOv2 token-grid embeddings from STAGE 2\n# - Uses token-grid GT masks from STAGE 3\n# - Uses leakage-safe folds from STAGE 4 (GroupKFold by case_id)\n#\n# Model A:\n#   tokens [Htok,Wtok,D] -> (permute to [D,H,W]) -> small CNN decoder -> logits [Htok,Wtok]\n# Loss:\n#   BCEWithLogits + Dice (imbalance-friendly)\n#\n# Outputs:\n#   /kaggle/working/recodai_luc_prof/artifacts/mask_model/\n#       cfg.json\n#       fold_{k}.pt\n#       history_fold_{k}.csv\n#       valid_preds_fold_{k}.npz   (uids + prob grid)\n#\n# Paper figures:\n#   /kaggle/working/recodai_luc_prof/figures/stage5/\n#       Fig5-1_curves_fold_{k}.png\n#       Fig5-2_qualitative_fold_{k}.png\n# ============================================================\n\nimport os, gc, json, math, time, warnings, hashlib\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require prior stages (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\npaths = json.loads(paths_path.read_text())\n\ntrain_with_folds_path = Path(globals().get(\"TRAIN_MANIFEST_WITH_FOLDS\", PROF_DIR / \"train_manifest_with_gridmask_folds.parquet\"))\nif not train_with_folds_path.exists():\n    raise RuntimeError(\"Missing train_manifest_with_gridmask_folds.parquet. Run STAGE 4 first.\")\ndf_train = pd.read_parquet(train_with_folds_path)\n\n# pick token cache root (same helper logic as Stage 3)\ndef pick_token_cache_root():\n    if \"CACHE_ROOT\" in globals():\n        cr = Path(globals()[\"CACHE_ROOT\"])\n        if (cr / \"tokens_manifest_train.parquet\").exists():\n            return cr\n    base = Path(\"/kaggle/working/recodai_luc/cache\")\n    cands = []\n    for d in base.glob(\"dinov2_base_518_cfg_*\"):\n        if (d / \"tokens_manifest_train.parquet\").exists():\n            nfiles = len(list((d / \"train\").glob(\"*.npz\")))\n            cands.append((nfiles, d))\n    if not cands:\n        raise RuntimeError(\"No valid token cache found. Run STAGE 2 first.\")\n    cands.sort(reverse=True, key=lambda x: x[0])\n    return cands[0][1]\n\nCACHE_ROOT = pick_token_cache_root()\nman_train = pd.read_parquet(CACHE_ROOT / \"tokens_manifest_train.parquet\")\n\n# token grid meta\ns = np.load(man_train[\"tokens_path\"].iloc[0])\nHtok = int(s[\"Htok\"]); Wtok = int(s[\"Wtok\"]); Dtok = int(s[\"D\"])\nprint(f\"CACHE_ROOT: {CACHE_ROOT}\")\nprint(f\"Token grid: {Htok}x{Wtok}x{Dtok}\")\nprint(\"Train rows:\", df_train.shape, \" | folds:\", sorted(df_train[\"fold\"].unique().tolist()))\n\n# output dirs\nART_DIR = PROF_DIR / \"artifacts\" / \"mask_model\"\nART_DIR.mkdir(parents=True, exist_ok=True)\nFIG_DIR = PROF_DIR / \"figures\" / \"stage5\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\n# ----------------------------\n# 1) Join paths (tokens + gridmask) robustly\n# ----------------------------\ndf = df_train.copy()\ndf[\"uid\"] = df[\"uid\"].astype(str)\n\n# tokens path from man_train\nman_train2 = man_train[[\"uid\",\"tokens_path\"]].copy()\nman_train2[\"uid\"] = man_train2[\"uid\"].astype(str)\ndf = df.merge(man_train2, on=\"uid\", how=\"left\")\n\n# gridmask path should already exist in df from Stage 3\nif \"gridmask_path\" not in df.columns:\n    raise RuntimeError(\"gridmask_path missing. Run STAGE 3 first.\")\n\n# filter missing paths (fail-fast but keep report)\nmiss_tok = df[\"tokens_path\"].isna() | (df[\"tokens_path\"].astype(str)==\"\")\nmiss_gm  = df[\"gridmask_path\"].isna() | (df[\"gridmask_path\"].astype(str)==\"\")\nif miss_tok.any():\n    bad = df.loc[miss_tok, \"uid\"].head(10).tolist()\n    raise RuntimeError(f\"Missing tokens_path for {miss_tok.sum()} rows. Examples: {bad}\")\nif miss_gm.any():\n    bad = df.loc[miss_gm, \"uid\"].head(10).tolist()\n    raise RuntimeError(f\"Missing gridmask_path for {miss_gm.sum()} rows. Examples: {bad}\")\n\n# Ensure files exist\ndef exists_all(series):\n    return series.map(lambda p: Path(str(p)).exists()).values\n\ntok_exist = exists_all(df[\"tokens_path\"])\ngm_exist  = exists_all(df[\"gridmask_path\"])\nif (~tok_exist).any():\n    bad = df.loc[~tok_exist, [\"uid\",\"tokens_path\"]].head(10).values.tolist()\n    raise RuntimeError(f\"Some token files not found. Examples: {bad}\")\nif (~gm_exist).any():\n    bad = df.loc[~gm_exist, [\"uid\",\"gridmask_path\"]].head(10).values.tolist()\n    raise RuntimeError(f\"Some gridmask files not found. Examples: {bad}\")\n\n# ----------------------------\n# 2) Torch setup\n# ----------------------------\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nUSE_AMP = (device.type == \"cuda\")\nprint(\"Device:\", device, \"| AMP:\", USE_AMP)\n\n# ----------------------------\n# 3) Dataset\n# ----------------------------\nclass TokenGridMaskDataset(Dataset):\n    def __init__(self, df):\n        self.df = df.reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        r = self.df.iloc[idx]\n        uid = str(r[\"uid\"])\n        tok_path = str(r[\"tokens_path\"])\n        gm_path  = str(r[\"gridmask_path\"])\n\n        npz = np.load(tok_path)\n        tok = npz[\"tokens\"].astype(np.float32)  # [H,W,D]\n        gm  = np.load(gm_path).astype(np.float32)  # [H,W] 0/1\n\n        # safety: enforce shapes\n        if tok.shape[0] != Htok or tok.shape[1] != Wtok or tok.shape[2] != Dtok:\n            raise RuntimeError(f\"Token shape mismatch uid={uid}: {tok.shape} expected {(Htok,Wtok,Dtok)}\")\n        if gm.shape[0] != Htok or gm.shape[1] != Wtok:\n            raise RuntimeError(f\"Gridmask shape mismatch uid={uid}: {gm.shape} expected {(Htok,Wtok)}\")\n\n        # torch: tokens -> [D,H,W], mask -> [1,H,W]\n        x = torch.from_numpy(tok).permute(2,0,1).contiguous()\n        y = torch.from_numpy(gm)[None, ...].contiguous()\n        return uid, x, y\n\n# ----------------------------\n# 4) Model A — small CNN decoder\n# ----------------------------\nclass SmallSegDecoder(nn.Module):\n    def __init__(self, in_ch, mid1=256, mid2=128, mid3=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, mid1, 3, padding=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid1, mid2, 3, padding=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid2, mid3, 3, padding=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid3, 1, 1, padding=0, bias=True),\n        )\n\n    def forward(self, x):\n        return self.net(x)  # [B,1,H,W]\n\n# ----------------------------\n# 5) Losses + metrics\n# ----------------------------\ndef dice_loss_with_logits(logits, targets, eps=1e-6):\n    # logits/targets: [B,1,H,W]\n    probs = torch.sigmoid(logits)\n    num = 2.0 * (probs * targets).sum(dim=(1,2,3)) + eps\n    den = (probs + targets).sum(dim=(1,2,3)) + eps\n    dice = num / den\n    return 1.0 - dice.mean()\n\n@torch.no_grad()\ndef dice_score_from_logits(logits, targets, thr=0.5, eps=1e-6):\n    probs = torch.sigmoid(logits)\n    pred = (probs > thr).float()\n    num = 2.0 * (pred * targets).sum(dim=(1,2,3)) + eps\n    den = (pred + targets).sum(dim=(1,2,3)) + eps\n    return (num / den).mean().item()\n\n# ----------------------------\n# 6) Training config (safe defaults)\n# ----------------------------\nN_FOLDS = int(df[\"fold\"].nunique())\nEPOCHS = 25 if device.type == \"cpu\" else 35\nPATIENCE = 6\nLR = 3e-4\nWEIGHT_DECAY = 1e-4\n\nBATCH_SIZE = 8 if device.type == \"cpu\" else 16\nNUM_WORKERS = 2\nPIN_MEMORY = (device.type == \"cuda\")\n\nCFG = dict(\n    stage=\"stage5_train_seg_decoder\",\n    cache_root=str(CACHE_ROOT),\n    Htok=Htok, Wtok=Wtok, Dtok=Dtok,\n    epochs=int(EPOCHS),\n    patience=int(PATIENCE),\n    lr=float(LR),\n    weight_decay=float(WEIGHT_DECAY),\n    batch_size=int(BATCH_SIZE),\n    loss=\"BCEWithLogits(pos_weight fold-wise) + Dice\",\n    model=\"SmallSegDecoder(in=Dtok, 256-128-64-1)\",\n)\n(ART_DIR / \"cfg.json\").write_text(json.dumps(CFG, indent=2))\n\n# ----------------------------\n# 7) Utilities for figures\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\ndef overlay_mask(img_rgb, mask01, alpha=0.45):\n    img = img_rgb.astype(np.float32) / 255.0\n    m = mask01.astype(bool)\n    out = img.copy()\n    out[m, 0] = (1 - alpha) * out[m, 0] + alpha * 1.0\n    out[m, 1] = (1 - alpha) * out[m, 1] + alpha * 0.0\n    out[m, 2] = (1 - alpha) * out[m, 2] + alpha * 0.0\n    return (out * 255).clip(0, 255).astype(np.uint8)\n\ndef plot_curves(hist_df, out_path):\n    plt.figure(figsize=(7,4))\n    plt.plot(hist_df[\"epoch\"], hist_df[\"train_loss\"], label=\"train_loss\")\n    plt.plot(hist_df[\"epoch\"], hist_df[\"valid_loss\"], label=\"valid_loss\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Training curves (loss)\")\n    plt.legend()\n    savefig(out_path)\n\n    plt.figure(figsize=(7,4))\n    plt.plot(hist_df[\"epoch\"], hist_df[\"valid_dice\"], label=\"valid_dice\")\n    plt.xlabel(\"Epoch\"); plt.ylabel(\"Dice\"); plt.title(\"Validation Dice\")\n    plt.legend()\n    out2 = Path(out_path).with_name(Path(out_path).stem.replace(\"curves\",\"dice\") + \".png\")\n    savefig(out2)\n\n# ----------------------------\n# 8) Train per fold\n# ----------------------------\nall_fold_metrics = []\n\nscaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n\nfor fold_id in range(N_FOLDS):\n    print(\"\\n\" + \"=\"*60)\n    print(f\"Fold {fold_id}/{N_FOLDS-1}\")\n\n    trn = df[df[\"fold\"] != fold_id].reset_index(drop=True)\n    val = df[df[\"fold\"] == fold_id].reset_index(drop=True)\n\n    # fold-wise pos_weight from mean grid area fraction (already stored per sample)\n    # pos_frac ~ E[mask cell==1]; clamp to avoid extreme\n    if \"grid_area_frac\" in trn.columns:\n        pos_frac = float(np.clip(trn[\"grid_area_frac\"].mean(), 1e-6, 0.2))  # cap 0.2\n    else:\n        pos_frac = 1e-3\n    pos_weight = float(np.clip((1.0 - pos_frac) / max(pos_frac, 1e-6), 1.0, 30.0))\n    bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n\n    print(f\"Train size={len(trn)} | Valid size={len(val)} | pos_frac≈{pos_frac:.6f} | pos_weight={pos_weight:.2f}\")\n\n    ds_tr = TokenGridMaskDataset(trn)\n    ds_va = TokenGridMaskDataset(val)\n\n    dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True,\n                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n    dl_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False,\n                       num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, drop_last=False)\n\n    model = SmallSegDecoder(in_ch=Dtok).to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n\n    best_dice = -1.0\n    best_epoch = -1\n    best_path = ART_DIR / f\"fold_{fold_id}.pt\"\n    patience_ctr = 0\n\n    history = []\n\n    for epoch in range(1, EPOCHS + 1):\n        # ---- train\n        model.train()\n        tr_losses = []\n\n        for _, x, y in dl_tr:\n            x = x.to(device, non_blocking=True)\n            y = y.to(device, non_blocking=True)\n\n            opt.zero_grad(set_to_none=True)\n            with torch.cuda.amp.autocast(enabled=USE_AMP):\n                logits = model(x)\n                loss_bce = bce(logits, y)\n                loss_dice = dice_loss_with_logits(logits, y)\n                loss = loss_bce + loss_dice\n\n            scaler.scale(loss).backward()\n            scaler.step(opt)\n            scaler.update()\n\n            tr_losses.append(loss.item())\n\n        # ---- valid\n        model.eval()\n        va_losses = []\n        va_dices = []\n\n        with torch.no_grad():\n            for _, x, y in dl_va:\n                x = x.to(device, non_blocking=True)\n                y = y.to(device, non_blocking=True)\n                with torch.cuda.amp.autocast(enabled=USE_AMP):\n                    logits = model(x)\n                    loss_bce = bce(logits, y)\n                    loss_dice = dice_loss_with_logits(logits, y)\n                    loss = loss_bce + loss_dice\n                va_losses.append(loss.item())\n                va_dices.append(dice_score_from_logits(logits, y, thr=0.5))\n\n        train_loss = float(np.mean(tr_losses)) if tr_losses else float(\"nan\")\n        valid_loss = float(np.mean(va_losses)) if va_losses else float(\"nan\")\n        valid_dice = float(np.mean(va_dices)) if va_dices else 0.0\n\n        history.append(dict(epoch=epoch, train_loss=train_loss, valid_loss=valid_loss, valid_dice=valid_dice))\n\n        print(f\"Epoch {epoch:03d} | train_loss={train_loss:.5f} | valid_loss={valid_loss:.5f} | valid_dice@0.5={valid_dice:.4f}\")\n\n        # early stop / best save\n        if valid_dice > best_dice + 1e-5:\n            best_dice = valid_dice\n            best_epoch = epoch\n            torch.save({\n                \"state_dict\": model.state_dict(),\n                \"fold\": fold_id,\n                \"Htok\": Htok, \"Wtok\": Wtok, \"Dtok\": Dtok,\n                \"pos_weight\": pos_weight,\n                \"cfg\": CFG,\n            }, best_path)\n            patience_ctr = 0\n        else:\n            patience_ctr += 1\n            if patience_ctr >= PATIENCE:\n                print(f\"Early stopping at epoch {epoch} (best_epoch={best_epoch}, best_dice={best_dice:.4f})\")\n                break\n\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n        gc.collect()\n\n    # save history\n    hist_df = pd.DataFrame(history)\n    hist_path = ART_DIR / f\"history_fold_{fold_id}.csv\"\n    hist_df.to_csv(hist_path, index=False)\n    print(\"Saved:\", hist_path)\n    print(\"Saved best:\", best_path, f\"(best_dice={best_dice:.4f} @ epoch {best_epoch})\")\n\n    # ---- save valid predictions (for postprocess tuning later)\n    # predict probs for all valid rows and store grid probs\n    ckpt = torch.load(best_path, map_location=device)\n    model.load_state_dict(ckpt[\"state_dict\"], strict=True)\n    model.eval()\n\n    uids_va = []\n    probs_va = []\n\n    with torch.no_grad():\n        for uids, x, y in dl_va:\n            x = x.to(device, non_blocking=True)\n            with torch.cuda.amp.autocast(enabled=USE_AMP):\n                logits = model(x)\n                probs = torch.sigmoid(logits).detach().float().cpu().numpy()  # [B,1,H,W]\n            uids_va.extend([str(u) for u in uids])\n            probs_va.append(probs)\n\n    probs_va = np.concatenate(probs_va, axis=0) if len(probs_va) else np.zeros((0,1,Htok,Wtok), np.float32)\n    pred_path = ART_DIR / f\"valid_preds_fold_{fold_id}.npz\"\n    np.savez_compressed(pred_path, uids=np.array(uids_va, dtype=object), probs=probs_va.astype(np.float16))\n    print(\"Saved:\", pred_path)\n\n    # ---- paper figures (curves + qualitative)\n    try:\n        plot_curves(hist_df, FIG_DIR / f\"Fig5-1_curves_fold_{fold_id}.png\")\n    except Exception as e:\n        print(\"[WARN] Could not save curve figure:\", e)\n\n    # qualitative examples: image (resized 518), GT overlay (resized), Pred overlay (upsampled)\n    try:\n        # pick 4 forged + 4 authentic from valid (if available)\n        val_df = val.copy()\n        v_f = val_df[val_df[\"y\"]==1].head(4)\n        v_a = val_df[val_df[\"y\"]==0].head(4)\n        sel = pd.concat([v_f, v_a], axis=0).head(8)\n\n        # map uid->prob\n        uid2prob = {uids_va[i]: probs_va[i,0] for i in range(len(uids_va))}\n\n        items = []\n        titles = []\n        for _, rr in sel.iterrows():\n            uid = str(rr[\"uid\"])\n            ip = Path(rr[\"img_path\"])\n            img = np.array(Image.open(ip).convert(\"RGB\"))\n            # For visualization we show the same 518x518 resolution used for tokens\n            img_518 = np.array(Image.fromarray(img).resize((518,518), Image.BICUBIC))\n\n            # GT full mask if exists -> resize to 518\n            gt_overlay = img_518\n            if int(rr[\"y\"]) == 1 and str(rr.get(\"mask_path\",\"\")):\n                mp = Path(rr[\"mask_path\"])\n                if mp.exists():\n                    m = np.load(mp)\n                    if m.ndim == 3:\n                        m = m.max(axis=0)\n                    m = (m > 0).astype(np.uint8)\n                    # align to image orientation if possible\n                    w0, h0 = Image.open(ip).size\n                    mh, mw = m.shape\n                    if (mh == h0 and mw == w0):\n                        m_al = m\n                    elif (mh == w0 and mw == h0):\n                        m_al = m.T\n                    else:\n                        m_al = np.array(Image.fromarray((m*255).astype(np.uint8)).resize((w0,h0), Image.NEAREST)) > 0\n                        m_al = m_al.astype(np.uint8)\n                    m_518 = np.array(Image.fromarray((m_al*255).astype(np.uint8)).resize((518,518), Image.NEAREST)) > 0\n                    gt_overlay = overlay_mask(img_518, m_518.astype(np.uint8), alpha=0.45)\n\n            # Pred grid prob -> upsample to 518\n            prob = uid2prob.get(uid, np.zeros((Htok,Wtok), np.float32))\n            prob_518 = np.array(Image.fromarray((prob*255).astype(np.uint8)).resize((518,518), Image.BILINEAR)).astype(np.float32)/255.0\n            pred_bin = (prob_518 > 0.5).astype(np.uint8)\n            pred_overlay = overlay_mask(img_518, pred_bin, alpha=0.45)\n\n            items.extend([img_518, gt_overlay, pred_overlay])\n            titles.extend([f\"{uid} | image\",\n                           f\"{uid} | GT (resized)\",\n                           f\"{uid} | Pred@0.5\"])\n\n        # plot grid 3 columns\n        n = len(items)\n        ncols = 3\n        nrows = int(math.ceil(n / ncols))\n        plt.figure(figsize=(12, 3.8*nrows))\n        for i in range(n):\n            plt.subplot(nrows, ncols, i+1)\n            plt.imshow(items[i])\n            plt.axis(\"off\")\n            plt.title(titles[i], fontsize=9)\n        savefig(FIG_DIR / f\"Fig5-2_qualitative_fold_{fold_id}.png\")\n    except Exception as e:\n        print(\"[WARN] Could not save qualitative figure:\", e)\n\n    all_fold_metrics.append(dict(fold=fold_id, best_epoch=int(best_epoch), best_dice=float(best_dice)))\n    del model\n    gc.collect()\n    if device.type == \"cuda\":\n        torch.cuda.empty_cache()\n\n# Save fold metrics summary\nmetrics_df = pd.DataFrame(all_fold_metrics)\nmetrics_path = ART_DIR / \"fold_metrics.csv\"\nmetrics_df.to_csv(metrics_path, index=False)\nprint(\"\\n[OK] Training complete.\")\nprint(\"Saved:\", metrics_path)\nprint(\"Models in:\", ART_DIR)\nprint(\"Figures in:\", FIG_DIR)\n\n# Keep globals for next stages\nglobals().update(dict(\n    MASK_MODEL_DIR=ART_DIR,\n    MASK_MODELS=[str(ART_DIR / f\"fold_{k}.pt\") for k in range(N_FOLDS)],\n    MASK_FOLD_METRICS=all_fold_metrics,\n))\n# ============================================================\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-15T13:25:43.803Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Full-Resolution Reconstruction & Post-Processing","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 6 — Full-Resolution Reconstruction & Post-Processing (ONE CELL)\n# - Uses STAGE 5 saved VALID grid probabilities (valid_preds_fold_k.npz)\n# - Reconstructs full-res probability maps, applies post-processing, tunes params on CV-valid\n#\n# Outputs:\n#   /kaggle/working/recodai_luc_prof/artifacts/postprocess/postprocess_cfg.json\n#   /kaggle/working/recodai_luc_prof/artifacts/postprocess/threshold_sweep.csv\n#   /kaggle/working/recodai_luc_prof/artifacts/postprocess/valid_postproc_summary.json\n#   /kaggle/working/recodai_luc_prof/figures/stage6/Fig6-1_before_after_examples.png\n#   /kaggle/working/recodai_luc_prof/figures/stage6/Fig6-2_fp_suppression_examples.png\n#\n# Keeps context for next stage:\n#   POSTPROCESS_CFG, POSTPROCESS_CFG_PATH\n# ============================================================\n\nimport os, gc, json, math, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile, ImageFilter\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require prior stages (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\npaths = json.loads(paths_path.read_text())\n\ntrain_with_folds_path = Path(globals().get(\"TRAIN_MANIFEST_WITH_FOLDS\", PROF_DIR / \"train_manifest_with_gridmask_folds.parquet\"))\nif not train_with_folds_path.exists():\n    raise RuntimeError(\"Missing train_manifest_with_gridmask_folds.parquet. Run STAGE 4 first.\")\ndf_train = pd.read_parquet(train_with_folds_path).copy()\n\nMASK_MODEL_DIR = Path(globals().get(\"MASK_MODEL_DIR\", PROF_DIR / \"artifacts\" / \"mask_model\"))\nif not MASK_MODEL_DIR.exists():\n    raise RuntimeError(\"Missing mask_model dir. Run STAGE 5 first.\")\n\nART_DIR = PROF_DIR / \"artifacts\" / \"postprocess\"\nART_DIR.mkdir(parents=True, exist_ok=True)\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage6\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Loaded train:\", df_train.shape, \"| folds:\", sorted(df_train[\"fold\"].unique().tolist()))\nprint(\"MASK_MODEL_DIR:\", MASK_MODEL_DIR)\nprint(\"ART_DIR:\", ART_DIR)\nprint(\"FIG_DIR:\", FIG_DIR)\n\n# ----------------------------\n# 1) Load all fold valid predictions (grid probs)\n# ----------------------------\npred_files = sorted(MASK_MODEL_DIR.glob(\"valid_preds_fold_*.npz\"))\nif not pred_files:\n    raise RuntimeError(\"No valid_preds_fold_*.npz found. Ensure STAGE 5 saved validation predictions.\")\n\npred_rows = []\nfor pf in pred_files:\n    z = np.load(pf, allow_pickle=True)\n    uids = z[\"uids\"].astype(object)\n    probs = z[\"probs\"]  # [N,1,H,W] float16\n    # infer fold id from filename\n    fold_id = int(pf.stem.split(\"_\")[-1])\n    if probs.ndim != 4 or probs.shape[1] != 1:\n        raise RuntimeError(f\"Bad probs shape in {pf}: {probs.shape}\")\n    for i, uid in enumerate(uids):\n        pred_rows.append(dict(\n            uid=str(uid),\n            fold=int(fold_id),\n            prob_grid=probs[i,0].astype(np.float32),  # store as float32 in-memory\n        ))\n\ndf_pred = pd.DataFrame(pred_rows)\nprint(\"Loaded valid grid preds:\", df_pred.shape)\n\n# Join to train rows (must match each uid exactly once on its fold)\ndf_train[\"uid\"] = df_train[\"uid\"].astype(str)\ndf_pred[\"uid\"] = df_pred[\"uid\"].astype(str)\n\ndfv = df_train.merge(df_pred, on=[\"uid\", \"fold\"], how=\"left\")\nif dfv[\"prob_grid\"].isna().any():\n    miss = dfv[dfv[\"prob_grid\"].isna()][[\"uid\",\"fold\"]].head(20).values.tolist()\n    raise RuntimeError(f\"Missing validation predictions after merge. Examples: {miss}\")\nprint(\"Validation merged:\", dfv.shape)\n\n# infer grid shape\ng0 = dfv[\"prob_grid\"].iloc[0]\nHtok, Wtok = int(g0.shape[0]), int(g0.shape[1])\nprint(f\"Grid size: {Htok}x{Wtok}\")\n\n# ----------------------------\n# 2) Optional SciPy for better morphology/filters (fallback to PIL-only)\n# ----------------------------\ntry:\n    import scipy.ndimage as ndi\n    _HAS_SCIPY = True\nexcept Exception:\n    _HAS_SCIPY = False\n\nprint(\"SciPy available:\", _HAS_SCIPY)\n\n# ----------------------------\n# 3) Helpers (alignment, reconstruction, postprocess, metrics, figures)\n# ----------------------------\ndef load_mask_as_bin(mask_path: Path):\n    m = np.load(mask_path)\n    if m.ndim == 3:\n        m = m.max(axis=0)\n    return (m > 0).astype(np.uint8)\n\ndef align_mask_to_image(mask01: np.ndarray, img_w: int, img_h: int):\n    mh, mw = mask01.shape[:2]\n    if (mh == img_h) and (mw == img_w):\n        return mask01, \"match\"\n    if (mh == img_w) and (mw == img_h):\n        return mask01.T, \"transpose_match\"\n    # fallback: resize to image size\n    m_img = Image.fromarray((mask01*255).astype(np.uint8), mode=\"L\")\n    m_res = m_img.resize((img_w, img_h), resample=Image.NEAREST)\n    return (np.array(m_res) > 0).astype(np.uint8), \"resized_to_match\"\n\ndef upsample_grid_prob(prob_grid: np.ndarray, w: int, h: int):\n    # prob_grid: [Htok,Wtok] float [0..1]\n    img = Image.fromarray(np.clip(prob_grid*255.0, 0, 255).astype(np.uint8), mode=\"L\")\n    up = img.resize((w, h), resample=Image.BILINEAR)\n    return (np.array(up).astype(np.float32) / 255.0).clip(0, 1)\n\ndef sobel_grad(x: np.ndarray):\n    # x: float32 HxW\n    if _HAS_SCIPY:\n        gx = ndi.sobel(x, axis=1)\n        gy = ndi.sobel(x, axis=0)\n        g = np.sqrt(gx*gx + gy*gy)\n        g = g / (g.max() + 1e-8)\n        return g.astype(np.float32)\n    # fallback: simple finite diff\n    gx = np.zeros_like(x)\n    gy = np.zeros_like(x)\n    gx[:,1:] = np.abs(x[:,1:] - x[:,:-1])\n    gy[1:,:] = np.abs(x[1:,:] - x[:-1,:])\n    g = (gx + gy)\n    g = g / (g.max() + 1e-8)\n    return g.astype(np.float32)\n\ndef gaussian_blur(x: np.ndarray, sigma: float):\n    if sigma <= 0:\n        return x\n    if _HAS_SCIPY:\n        return ndi.gaussian_filter(x, sigma=sigma).astype(np.float32)\n    # PIL fallback: radius approx sigma\n    img = Image.fromarray(np.clip(x*255,0,255).astype(np.uint8), mode=\"L\")\n    img = img.filter(ImageFilter.GaussianBlur(radius=float(sigma)))\n    return (np.array(img).astype(np.float32)/255.0).clip(0,1)\n\ndef morph_close_open(mask01: np.ndarray, k_close=5, k_open=3):\n    if not _HAS_SCIPY:\n        return mask01  # safe fallback (no morphology)\n    st_close = np.ones((k_close, k_close), dtype=bool)\n    st_open  = np.ones((k_open,  k_open),  dtype=bool)\n    m = ndi.binary_closing(mask01.astype(bool), structure=st_close)\n    m = ndi.binary_opening(m, structure=st_open)\n    return m.astype(np.uint8)\n\ndef postprocess_prob_to_mask(prob_up: np.ndarray, img_gray: np.ndarray, *,\n                             alpha_grad=0.35, blur_sigma=1.0, k_std=0.30,\n                             thr_min=0.20, thr_max=0.90,\n                             do_morph=True, k_close=5, k_open=3,\n                             min_area=400, min_mean_inside=0.30):\n    \"\"\"\n    Returns: mask01, info dict (thr, area, mean_inside)\n    \"\"\"\n    grad = sobel_grad(prob_up)\n    enh = (1.0 - alpha_grad) * prob_up + alpha_grad * grad\n    enh = enh.clip(0, 1)\n    enh = gaussian_blur(enh, sigma=blur_sigma)\n\n    mu = float(enh.mean())\n    sd = float(enh.std())\n    thr = float(np.clip(mu + k_std * sd, thr_min, thr_max))\n\n    mask = (enh > thr).astype(np.uint8)\n\n    if do_morph:\n        mask = morph_close_open(mask, k_close=k_close, k_open=k_open)\n\n    area = int(mask.sum())\n    if area == 0:\n        return mask, {\"thr\": thr, \"area\": 0, \"mean_inside\": 0.0}\n\n    # mean intensity inside mask (grayscale)\n    if area > 0:\n        vals = img_gray[mask.astype(bool)]\n        mean_inside = float(vals.mean()) / 255.0\n    else:\n        mean_inside = 0.0\n\n    # anti-FP filtering\n    if (area < int(min_area)) or (mean_inside < float(min_mean_inside)):\n        mask[:] = 0\n        return mask, {\"thr\": thr, \"area\": 0, \"mean_inside\": mean_inside, \"filtered\": True}\n\n    return mask, {\"thr\": thr, \"area\": area, \"mean_inside\": mean_inside, \"filtered\": False}\n\ndef f1_binary(pred01: np.ndarray, gt01: np.ndarray, eps=1e-9):\n    # pixel-level F1\n    pred = pred01.astype(bool)\n    gt = gt01.astype(bool)\n    tp = (pred & gt).sum()\n    fp = (pred & (~gt)).sum()\n    fn = ((~pred) & gt).sum()\n    return float((2*tp + eps) / (2*tp + fp + fn + eps))\n\ndef overlay_mask(img_rgb, mask01, alpha=0.45):\n    img = img_rgb.astype(np.float32)/255.0\n    m = mask01.astype(bool)\n    out = img.copy()\n    out[m,0] = (1-alpha)*out[m,0] + alpha*1.0\n    out[m,1] = (1-alpha)*out[m,1] + alpha*0.0\n    out[m,2] = (1-alpha)*out[m,2] + alpha*0.0\n    return (out*255).clip(0,255).astype(np.uint8)\n\nimport matplotlib.pyplot as plt\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\ndef show_grid(items, titles=None, ncols=3, figsize=(14,10)):\n    n = len(items)\n    if n == 0:\n        return\n    ncols = min(ncols, n)\n    nrows = int(math.ceil(n / ncols))\n    plt.figure(figsize=figsize)\n    for i, x in enumerate(items):\n        plt.subplot(nrows, ncols, i+1)\n        if x.ndim == 2:\n            plt.imshow(x, cmap=\"gray\")\n        else:\n            plt.imshow(x)\n        plt.axis(\"off\")\n        if titles is not None:\n            plt.title(str(titles[i]), fontsize=9)\n    plt.tight_layout()\n\n# ----------------------------\n# 4) Prepare GT loader (full-res)\n# ----------------------------\ndfv[\"mask_path\"] = dfv.get(\"mask_path\",\"\").fillna(\"\").astype(str)\ndfv[\"img_path\"]  = dfv[\"img_path\"].astype(str)\n\ndef get_gt_mask(uid, img_path, y, mask_path):\n    im = Image.open(img_path).convert(\"RGB\")\n    w, h = im.size\n    if int(y) == 1 and mask_path and Path(mask_path).exists():\n        m = load_mask_as_bin(Path(mask_path))\n        m_al, _ = align_mask_to_image(m, w, h)\n        return np.array(im), w, h, m_al\n    # authentic or missing mask -> empty GT\n    return np.array(im), w, h, np.zeros((h, w), dtype=np.uint8)\n\n# ----------------------------\n# 5) Tune postprocess parameters on a subset of validation\n#     (pixel-level F1 proxy; stable & fast; prevents crashes)\n# ----------------------------\nTUNE_MAX = 600  # safe compute\n# balanced sampling: forged first then authentic\nforged_idx = dfv[dfv[\"y\"]==1].index.tolist()\nauth_idx   = dfv[dfv[\"y\"]==0].index.tolist()\nnp.random.RandomState(42).shuffle(forged_idx)\nnp.random.RandomState(42).shuffle(auth_idx)\n\ntake_f = min(len(forged_idx), TUNE_MAX//2)\ntake_a = min(len(auth_idx),   TUNE_MAX - take_f)\ntune_idx = forged_idx[:take_f] + auth_idx[:take_a]\ndf_tune = dfv.loc[tune_idx].reset_index(drop=True)\nprint(\"Tuning subset:\", df_tune.shape, \"| forged:\", int((df_tune[\"y\"]==1).sum()), \"| authentic:\", int((df_tune[\"y\"]==0).sum()))\n\n# small grid (safe runtime)\nGRID = []\nfor alpha_grad in [0.0, 0.35]:\n    for k_std in [0.20, 0.30]:\n        for blur_sigma in [0.0, 1.0]:\n            for min_area in [0, 400]:\n                for min_mean in [0.0, 0.30]:\n                    GRID.append((alpha_grad, k_std, blur_sigma, min_area, min_mean))\n\ndef eval_params(params):\n    alpha_grad, k_std, blur_sigma, min_area, min_mean = params\n    scores = []\n    n_filtered = 0\n    n_pred_pos = 0\n    for _, r in df_tune.iterrows():\n        img_rgb, w, h, gt = get_gt_mask(r[\"uid\"], r[\"img_path\"], r[\"y\"], r[\"mask_path\"])\n        gray = np.array(Image.fromarray(img_rgb).convert(\"L\"), dtype=np.float32)\n        prob_up = upsample_grid_prob(r[\"prob_grid\"], w=w, h=h)\n        mask, info = postprocess_prob_to_mask(\n            prob_up, gray,\n            alpha_grad=alpha_grad,\n            blur_sigma=blur_sigma,\n            k_std=k_std,\n            do_morph=True,\n            min_area=min_area,\n            min_mean_inside=min_mean\n        )\n        if info.get(\"filtered\", False):\n            n_filtered += 1\n        if mask.sum() > 0:\n            n_pred_pos += 1\n        scores.append(f1_binary(mask, gt))\n    return float(np.mean(scores)), int(n_pred_pos), int(n_filtered)\n\nresults = []\nbest = None\n\nprint(\"Grid search candidates:\", len(GRID))\nfor i, p in enumerate(GRID, 1):\n    mean_f1, n_pos, n_filt = eval_params(p)\n    results.append(dict(\n        alpha_grad=p[0], k_std=p[1], blur_sigma=p[2], min_area=p[3], min_mean_inside=p[4],\n        mean_f1=mean_f1, n_pred_pos=n_pos, n_filtered=n_filt\n    ))\n    if best is None or mean_f1 > best[\"mean_f1\"]:\n        best = results[-1]\n    if i % 8 == 0:\n        print(f\"[tune] {i}/{len(GRID)} best_mean_f1={best['mean_f1']:.4f}\")\n\nsweep_df = pd.DataFrame(results).sort_values(\"mean_f1\", ascending=False).reset_index(drop=True)\nsweep_path = ART_DIR / \"threshold_sweep.csv\"\nsweep_df.to_csv(sweep_path, index=False)\nprint(\"Saved sweep:\", sweep_path)\nprint(\"Best params:\", best)\n\n# final postprocess config for next stages\nPOSTPROCESS_CFG = dict(\n    stage=\"stage6_postprocess_tuned\",\n    grid_size=[int(Htok), int(Wtok)],\n    # tuned params\n    alpha_grad=float(best[\"alpha_grad\"]),\n    k_std=float(best[\"k_std\"]),\n    blur_sigma=float(best[\"blur_sigma\"]),\n    do_morph=True,\n    k_close=5,\n    k_open=3,\n    thr_min=0.20,\n    thr_max=0.90,\n    min_area=int(best[\"min_area\"]),\n    min_mean_inside=float(best[\"min_mean_inside\"]),\n    # notes\n    tuned_metric=\"pixel_F1_proxy_on_CV_valid\",\n    tuned_subset_size=int(len(df_tune)),\n    mask_empty_label=\"authentic\",\n)\n\nPOSTPROCESS_CFG_PATH = ART_DIR / \"postprocess_cfg.json\"\nPOSTPROCESS_CFG_PATH.write_text(json.dumps(POSTPROCESS_CFG, indent=2))\nprint(\"Saved:\", POSTPROCESS_CFG_PATH)\n\n# ----------------------------\n# 6) Apply tuned postprocess to ALL validation rows (for summary + figures)\n# ----------------------------\nall_scores = []\nall_info = []\nfor _, r in dfv.iterrows():\n    img_rgb, w, h, gt = get_gt_mask(r[\"uid\"], r[\"img_path\"], r[\"y\"], r[\"mask_path\"])\n    gray = np.array(Image.fromarray(img_rgb).convert(\"L\"), dtype=np.float32)\n    prob_up = upsample_grid_prob(r[\"prob_grid\"], w=w, h=h)\n    mask, info = postprocess_prob_to_mask(\n        prob_up, gray,\n        alpha_grad=POSTPROCESS_CFG[\"alpha_grad\"],\n        blur_sigma=POSTPROCESS_CFG[\"blur_sigma\"],\n        k_std=POSTPROCESS_CFG[\"k_std\"],\n        thr_min=POSTPROCESS_CFG[\"thr_min\"],\n        thr_max=POSTPROCESS_CFG[\"thr_max\"],\n        do_morph=POSTPROCESS_CFG[\"do_morph\"],\n        k_close=POSTPROCESS_CFG[\"k_close\"],\n        k_open=POSTPROCESS_CFG[\"k_open\"],\n        min_area=POSTPROCESS_CFG[\"min_area\"],\n        min_mean_inside=POSTPROCESS_CFG[\"min_mean_inside\"],\n    )\n    score = f1_binary(mask, gt)\n    all_scores.append(score)\n    all_info.append(dict(uid=r[\"uid\"], fold=int(r[\"fold\"]), y=int(r[\"y\"]),\n                         f1=score, area=int(mask.sum()), thr=float(info[\"thr\"]),\n                         filtered=bool(info.get(\"filtered\", False))))\n\nsummary = {\n    \"n_valid_total\": int(len(dfv)),\n    \"mean_pixel_f1_proxy\": float(np.mean(all_scores)),\n    \"forged_mean_pixel_f1_proxy\": float(np.mean([a[\"f1\"] for a in all_info if a[\"y\"]==1])) if any(a[\"y\"]==1 for a in all_info) else 0.0,\n    \"auth_mean_pixel_f1_proxy\": float(np.mean([a[\"f1\"] for a in all_info if a[\"y\"]==0])) if any(a[\"y\"]==0 for a in all_info) else 0.0,\n    \"pred_positive_frac\": float(np.mean([1.0 if a[\"area\"]>0 else 0.0 for a in all_info])),\n    \"filtered_count\": int(sum(1 for a in all_info if a[\"filtered\"])),\n}\nsummary_path = ART_DIR / \"valid_postproc_summary.json\"\nsummary_path.write_text(json.dumps(summary, indent=2))\nprint(\"Saved:\", summary_path)\nprint(\"Summary:\", summary)\n\n# ----------------------------\n# 7) Paper figures (before/after + FP suppression examples)\n# ----------------------------\n# pick examples\ndf_info = pd.DataFrame(all_info)\n# \"hard FP\": authentic predicted positive before filtering would require raw; we approximate by selecting authentic with area=0 (filtered away)\n# We'll generate 2 panels:\n#  - mixed forged examples before/after\n#  - authentic examples where final is empty (show how postprocess outputs empty)\n\n# Helper to build before/after visuals for a uid\ndef build_before_after(uid):\n    r = dfv[dfv[\"uid\"]==uid].iloc[0]\n    img_rgb, w, h, gt = get_gt_mask(r[\"uid\"], r[\"img_path\"], r[\"y\"], r[\"mask_path\"])\n    gray = np.array(Image.fromarray(img_rgb).convert(\"L\"), dtype=np.float32)\n    prob_up = upsample_grid_prob(r[\"prob_grid\"], w=w, h=h)\n\n    # raw bin at fixed 0.5 (baseline)\n    raw_bin = (prob_up > 0.5).astype(np.uint8)\n\n    # tuned postprocess\n    mask, info = postprocess_prob_to_mask(\n        prob_up, gray,\n        alpha_grad=POSTPROCESS_CFG[\"alpha_grad\"],\n        blur_sigma=POSTPROCESS_CFG[\"blur_sigma\"],\n        k_std=POSTPROCESS_CFG[\"k_std\"],\n        thr_min=POSTPROCESS_CFG[\"thr_min\"],\n        thr_max=POSTPROCESS_CFG[\"thr_max\"],\n        do_morph=POSTPROCESS_CFG[\"do_morph\"],\n        k_close=POSTPROCESS_CFG[\"k_close\"],\n        k_open=POSTPROCESS_CFG[\"k_open\"],\n        min_area=POSTPROCESS_CFG[\"min_area\"],\n        min_mean_inside=POSTPROCESS_CFG[\"min_mean_inside\"],\n    )\n\n    # visuals (resize to max 640 for figure speed)\n    max_side = 640\n    scale = min(1.0, max_side / max(w, h))\n    ww, hh = int(w*scale), int(h*scale)\n\n    img_v = np.array(Image.fromarray(img_rgb).resize((ww, hh), Image.BICUBIC))\n    prob_v = np.array(Image.fromarray((prob_up*255).astype(np.uint8)).resize((ww, hh), Image.BILINEAR))\n    raw_v  = np.array(Image.fromarray((raw_bin*255).astype(np.uint8)).resize((ww, hh), Image.NEAREST)) > 0\n    post_v = np.array(Image.fromarray((mask*255).astype(np.uint8)).resize((ww, hh), Image.NEAREST)) > 0\n    gt_v   = np.array(Image.fromarray((gt*255).astype(np.uint8)).resize((ww, hh), Image.NEAREST)) > 0\n\n    return {\n        \"img\": img_v,\n        \"prob\": prob_v,\n        \"raw_ov\": overlay_mask(img_v, raw_v.astype(np.uint8), alpha=0.45),\n        \"post_ov\": overlay_mask(img_v, post_v.astype(np.uint8), alpha=0.45),\n        \"gt_ov\": overlay_mask(img_v, gt_v.astype(np.uint8), alpha=0.45),\n        \"title\": f\"{uid} | y={int(r['y'])} | thr≈{info['thr']:.3f} | area={int(mask.sum())}\"\n    }\n\n# Fig6-1: mixed forged examples\nforged_uids = df_info[df_info[\"y\"]==1].sort_values(\"f1\").head(4)[\"uid\"].tolist()\n# if too few forged\nif len(forged_uids) < 4:\n    forged_uids = df_info[df_info[\"y\"]==1][\"uid\"].head(4).tolist()\n\nitems, titles = [], []\nfor uid in forged_uids[:4]:\n    ex = build_before_after(uid)\n    items += [ex[\"img\"], ex[\"gt_ov\"], ex[\"raw_ov\"], ex[\"post_ov\"]]\n    titles += [f\"{uid} image\", f\"{uid} GT overlay\", f\"{uid} raw@0.5\", ex[\"title\"] + \" post\"]\n\nshow_grid(items, titles=titles, ncols=4, figsize=(16, 10))\nsavefig(FIG_DIR / \"Fig6-1_before_after_examples.png\")\n\n# Fig6-2: authentic examples (should end empty after filtering)\nauth_uids = df_info[(df_info[\"y\"]==0)].sample(min(4, int((df_info[\"y\"]==0).sum())), random_state=42)[\"uid\"].tolist()\nitems, titles = [], []\nfor uid in auth_uids[:4]:\n    ex = build_before_after(uid)\n    items += [ex[\"img\"], ex[\"raw_ov\"], ex[\"post_ov\"]]\n    titles += [f\"{uid} image\", f\"{uid} raw@0.5\", ex[\"title\"] + \" post\"]\nshow_grid(items, titles=titles, ncols=3, figsize=(15, 8))\nsavefig(FIG_DIR / \"Fig6-2_fp_suppression_examples.png\")\n\nprint(\"[OK] Stage 6 figures saved to:\", FIG_DIR)\n\n# ----------------------------\n# 8) Keep globals for next stage\n# ----------------------------\nglobals().update(dict(\n    POSTPROCESS_CFG=POSTPROCESS_CFG,\n    POSTPROCESS_CFG_PATH=str(POSTPROCESS_CFG_PATH),\n    POSTPROCESS_SUMMARY=summary,\n))\n# ============================================================\n","metadata":{"trusted":true,"execution":{"execution_failed":"2026-01-15T13:25:43.803Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Inference (Fold Ensemble) & Submission Generation","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 7 — Test Inference (Fold Ensemble) & Submission Generation (ONE CELL)\n# - Uses:\n#   * STAGE 0: df_test + sample_submission\n#   * STAGE 2: token caches for TEST (tokens_manifest_test.parquet)\n#   * STAGE 5: fold_{k}.pt models\n#   * STAGE 6: postprocess_cfg.json (tuned)\n#\n# Produces:\n#   /kaggle/working/submission.csv\n#   /kaggle/working/recodai_luc_prof/artifacts/submission/submission.csv\n#   /kaggle/working/recodai_luc_prof/artifacts/submission/test_pred_stats.json\n#   /kaggle/working/recodai_luc_prof/figures/stage7/Fig7-1_test_overlays.png\n#   /kaggle/working/recodai_luc_prof/figures/stage7/Fig7-2_output_distributions.png\n#\n# Notes:\n# - Ensemble: average probs across folds on token-grid\n# - Reconstruction: upsample to original size\n# - Postprocess: tuned Stage 6 (morphology uses SciPy if available)\n# - Output format:\n#     \"authentic\" OR JSON list string \"[start, length, ...]\"\n# ============================================================\n\nimport os, gc, json, math, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFile, ImageFilter\n\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Require prior stages (fallback load)\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\npaths = json.loads(paths_path.read_text())\n\n# test manifest\ndf_test = globals().get(\"df_test\", None)\nif df_test is None:\n    df_test = pd.read_parquet(paths[\"TEST_MANIFEST\"]).copy()\ndf_test[\"uid\"] = df_test[\"uid\"].astype(str)\ndf_test[\"case_id\"] = df_test[\"case_id\"].astype(str)\ndf_test[\"img_path\"] = df_test[\"img_path\"].astype(str)\n\n# sample submission (for order)\nsample_sub_path = Path(paths.get(\"SAMPLE_SUBMISSION\", PROF_DIR / \"sample_submission.csv\"))\nif not sample_sub_path.exists():\n    # fallback to copied one\n    sample_sub_path = PROF_DIR / \"sample_submission.csv\"\nsample_sub = pd.read_csv(sample_sub_path)\nif \"case_id\" not in sample_sub.columns:\n    # try common Kaggle naming\n    if \"id\" in sample_sub.columns:\n        sample_sub = sample_sub.rename(columns={\"id\":\"case_id\"})\n    else:\n        raise RuntimeError(\"sample_submission.csv does not contain 'case_id' or 'id' column.\")\n\nsample_sub[\"case_id\"] = sample_sub[\"case_id\"].astype(str)\n\n# token cache root + manifest test\ndef pick_token_cache_root():\n    if \"CACHE_ROOT\" in globals():\n        cr = Path(globals()[\"CACHE_ROOT\"])\n        if (cr / \"tokens_manifest_test.parquet\").exists():\n            return cr\n    base = Path(\"/kaggle/working/recodai_luc/cache\")\n    cands = []\n    for d in base.glob(\"dinov2_base_518_cfg_*\"):\n        if (d / \"tokens_manifest_test.parquet\").exists():\n            nfiles = len(list((d / \"test\").glob(\"*.npz\")))\n            cands.append((nfiles, d))\n    if not cands:\n        raise RuntimeError(\"No valid token cache found. Run STAGE 2 first.\")\n    cands.sort(reverse=True, key=lambda x: x[0])\n    return cands[0][1]\n\nCACHE_ROOT = pick_token_cache_root()\nman_test = pd.read_parquet(CACHE_ROOT / \"tokens_manifest_test.parquet\")\nman_test[\"uid\"] = man_test[\"uid\"].astype(str)\n\n# models\nMASK_MODEL_DIR = Path(globals().get(\"MASK_MODEL_DIR\", PROF_DIR / \"artifacts\" / \"mask_model\"))\nif not MASK_MODEL_DIR.exists():\n    raise RuntimeError(\"Missing mask_model dir. Run STAGE 5 first.\")\nmodel_paths = sorted(MASK_MODEL_DIR.glob(\"fold_*.pt\"))\nif not model_paths:\n    raise RuntimeError(\"No fold_*.pt models found. Run STAGE 5 first.\")\n\n# postprocess cfg\npp_path = Path(globals().get(\"POSTPROCESS_CFG_PATH\", PROF_DIR / \"artifacts\" / \"postprocess\" / \"postprocess_cfg.json\"))\nif not pp_path.exists():\n    raise RuntimeError(\"Missing postprocess_cfg.json. Run STAGE 6 first.\")\nPOSTPROCESS_CFG = json.loads(pp_path.read_text())\n\n# output dirs\nART_DIR = PROF_DIR / \"artifacts\" / \"submission\"\nART_DIR.mkdir(parents=True, exist_ok=True)\nFIG_DIR = PROF_DIR / \"figures\" / \"stage7\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"CACHE_ROOT:\", CACHE_ROOT)\nprint(\"Models:\", len(model_paths), \"->\", [p.name for p in model_paths])\nprint(\"Postprocess cfg:\", pp_path)\nprint(\"Test rows:\", df_test.shape, \"| Tokens test rows:\", man_test.shape)\n\n# ----------------------------\n# 1) Torch + Model definition (must match STAGE 5)\n# ----------------------------\nimport torch\nimport torch.nn as nn\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nUSE_AMP = (device.type == \"cuda\")\nprint(\"Device:\", device, \"| AMP:\", USE_AMP)\n\nclass SmallSegDecoder(nn.Module):\n    def __init__(self, in_ch, mid1=256, mid2=128, mid3=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(in_ch, mid1, 3, padding=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid1, mid2, 3, padding=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid2, mid3, 3, padding=1, bias=True),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid3, 1, 1, padding=0, bias=True),\n        )\n    def forward(self, x):\n        return self.net(x)\n\n# read grid meta from first model ckpt\nck0 = torch.load(model_paths[0], map_location=\"cpu\")\nHtok = int(ck0.get(\"Htok\", POSTPROCESS_CFG[\"grid_size\"][0]))\nWtok = int(ck0.get(\"Wtok\", POSTPROCESS_CFG[\"grid_size\"][1]))\nDtok = int(ck0.get(\"Dtok\", 768))\nprint(f\"Model grid: {Htok}x{Wtok} | Dtok={Dtok}\")\n\n# load all fold models\nmodels = []\nfor mp in model_paths:\n    ck = torch.load(mp, map_location=\"cpu\")\n    m = SmallSegDecoder(in_ch=Dtok)\n    m.load_state_dict(ck[\"state_dict\"], strict=True)\n    m.eval().to(device)\n    models.append(m)\n\n# ----------------------------\n# 2) SciPy optional for morphology/filters (same as Stage 6)\n# ----------------------------\ntry:\n    import scipy.ndimage as ndi\n    _HAS_SCIPY = True\nexcept Exception:\n    _HAS_SCIPY = False\nprint(\"SciPy available:\", _HAS_SCIPY)\n\n# ----------------------------\n# 3) Helpers: load tokens, reconstruct, postprocess, RLE\n# ----------------------------\ndef load_tokens(uid: str):\n    # map uid -> tokens_path\n    # build dict once for speed\n    return None\n\nuid2tok = dict(zip(man_test[\"uid\"].tolist(), man_test[\"tokens_path\"].tolist()))\nmissing_u = [u for u in df_test[\"uid\"].head(50).tolist() if u not in uid2tok]\nif missing_u:\n    raise RuntimeError(f\"Some test uids missing in token manifest. Example: {missing_u[:5]}\")\n\ndef load_token_grid(uid: str):\n    p = Path(uid2tok[uid])\n    npz = np.load(p)\n    tok = npz[\"tokens\"].astype(np.float32)  # [H,W,D]\n    if tok.shape[0] != Htok or tok.shape[1] != Wtok or tok.shape[2] != Dtok:\n        raise RuntimeError(f\"Token shape mismatch uid={uid}: {tok.shape} expected {(Htok,Wtok,Dtok)}\")\n    # torch [D,H,W]\n    x = torch.from_numpy(tok).permute(2,0,1).contiguous()\n    return x\n\ndef sobel_grad(x: np.ndarray):\n    if _HAS_SCIPY:\n        gx = ndi.sobel(x, axis=1)\n        gy = ndi.sobel(x, axis=0)\n        g = np.sqrt(gx*gx + gy*gy)\n        g = g / (g.max() + 1e-8)\n        return g.astype(np.float32)\n    gx = np.zeros_like(x)\n    gy = np.zeros_like(x)\n    gx[:,1:] = np.abs(x[:,1:] - x[:,:-1])\n    gy[1:,:] = np.abs(x[1:,:] - x[:-1,:])\n    g = gx + gy\n    g = g / (g.max() + 1e-8)\n    return g.astype(np.float32)\n\ndef gaussian_blur(x: np.ndarray, sigma: float):\n    if sigma <= 0:\n        return x\n    if _HAS_SCIPY:\n        return ndi.gaussian_filter(x, sigma=sigma).astype(np.float32)\n    img = Image.fromarray(np.clip(x*255,0,255).astype(np.uint8), mode=\"L\")\n    img = img.filter(ImageFilter.GaussianBlur(radius=float(sigma)))\n    return (np.array(img).astype(np.float32)/255.0).clip(0,1)\n\ndef morph_close_open(mask01: np.ndarray, k_close=5, k_open=3):\n    if not _HAS_SCIPY:\n        return mask01\n    st_close = np.ones((k_close, k_close), dtype=bool)\n    st_open  = np.ones((k_open,  k_open),  dtype=bool)\n    m = ndi.binary_closing(mask01.astype(bool), structure=st_close)\n    m = ndi.binary_opening(m, structure=st_open)\n    return m.astype(np.uint8)\n\ndef upsample_grid_prob(prob_grid: np.ndarray, w: int, h: int):\n    img = Image.fromarray(np.clip(prob_grid*255.0, 0, 255).astype(np.uint8), mode=\"L\")\n    up = img.resize((w, h), resample=Image.BILINEAR)\n    return (np.array(up).astype(np.float32) / 255.0).clip(0, 1)\n\ndef postprocess_prob_to_mask(prob_up: np.ndarray, img_gray: np.ndarray, cfg: dict):\n    grad = sobel_grad(prob_up)\n    enh = (1.0 - float(cfg[\"alpha_grad\"])) * prob_up + float(cfg[\"alpha_grad\"]) * grad\n    enh = enh.clip(0,1)\n    enh = gaussian_blur(enh, sigma=float(cfg[\"blur_sigma\"]))\n\n    mu = float(enh.mean())\n    sd = float(enh.std())\n    thr = float(np.clip(mu + float(cfg[\"k_std\"]) * sd, float(cfg[\"thr_min\"]), float(cfg[\"thr_max\"])))\n\n    mask = (enh > thr).astype(np.uint8)\n\n    if bool(cfg.get(\"do_morph\", True)):\n        mask = morph_close_open(mask, k_close=int(cfg.get(\"k_close\",5)), k_open=int(cfg.get(\"k_open\",3)))\n\n    area = int(mask.sum())\n    if area == 0:\n        return mask, {\"thr\": thr, \"area\": 0, \"mean_inside\": 0.0, \"filtered\": False}\n\n    vals = img_gray[mask.astype(bool)]\n    mean_inside = float(vals.mean()) / 255.0 if vals.size else 0.0\n\n    if (area < int(cfg.get(\"min_area\",0))) or (mean_inside < float(cfg.get(\"min_mean_inside\",0.0))):\n        mask[:] = 0\n        return mask, {\"thr\": thr, \"area\": 0, \"mean_inside\": mean_inside, \"filtered\": True}\n\n    return mask, {\"thr\": thr, \"area\": area, \"mean_inside\": mean_inside, \"filtered\": False}\n\ndef rle_json_list(mask01: np.ndarray):\n    \"\"\"\n    Encode binary mask to JSON list [start, length, ...]\n    Uses Fortran-order flatten (transpose then C-flatten) which is common for Kaggle RLE.\n    \"\"\"\n    m = mask01.astype(np.uint8)\n    flat = m.T.flatten()  # column-major\n    # pad\n    padded = np.concatenate([[0], flat, [0]])\n    changes = np.where(padded[1:] != padded[:-1])[0] + 1\n    runs = []\n    for i in range(0, len(changes), 2):\n        start = int(changes[i])\n        length = int(changes[i+1] - changes[i])\n        runs.extend([start, length])\n    return json.dumps(runs)\n\n# ----------------------------\n# 4) Batched inference on token grid + fold ensemble\n# ----------------------------\n@torch.no_grad()\ndef predict_prob_grid_batch(x_batch: torch.Tensor):\n    # x_batch: [B, D, H, W]\n    probs = None\n    with torch.cuda.amp.autocast(enabled=USE_AMP):\n        for m in models:\n            logit = m(x_batch)  # [B,1,H,W]\n            p = torch.sigmoid(logit)\n            probs = p if probs is None else (probs + p)\n    probs = probs / float(len(models))\n    return probs  # torch [B,1,H,W]\n\nBATCH_SIZE = 16 if device.type == \"cuda\" else 8\n\n# ----------------------------\n# 5) Run inference + build submission rows\n# ----------------------------\nsub_rows = []\nstats = {\n    \"n_test\": int(len(df_test)),\n    \"n_pred_mask\": 0,\n    \"n_pred_authentic\": 0,\n    \"mean_area_if_mask\": None,\n    \"filtered_count\": 0,\n}\n\nareas = []\n\n# iterate in stable order matching df_test\nuids = df_test[\"uid\"].tolist()\ncase_ids = df_test[\"case_id\"].tolist()\nimg_paths = df_test[\"img_path\"].tolist()\n\nfor i0 in range(0, len(uids), BATCH_SIZE):\n    batch_uids = uids[i0:i0+BATCH_SIZE]\n    batch_case = case_ids[i0:i0+BATCH_SIZE]\n    batch_imgs = img_paths[i0:i0+BATCH_SIZE]\n\n    # load tokens\n    xb = torch.stack([load_token_grid(u) for u in batch_uids], dim=0).to(device, non_blocking=True)  # [B,D,H,W]\n\n    # predict grid probs (ensemble)\n    pb = predict_prob_grid_batch(xb).detach().float().cpu().numpy()  # [B,1,H,W]\n\n    # per sample: reconstruct + postprocess + encode\n    for j in range(len(batch_uids)):\n        uid = batch_uids[j]\n        cid = batch_case[j]\n        ip = batch_imgs[j]\n\n        im = Image.open(ip).convert(\"RGB\")\n        w, h = im.size\n        img_rgb = np.array(im)\n        gray = np.array(im.convert(\"L\"), dtype=np.float32)\n\n        prob_grid = pb[j,0]  # [Htok,Wtok]\n        prob_up = upsample_grid_prob(prob_grid, w=w, h=h)\n        mask, info = postprocess_prob_to_mask(prob_up, gray, POSTPROCESS_CFG)\n\n        if info.get(\"filtered\", False):\n            stats[\"filtered_count\"] += 1\n\n        area = int(mask.sum())\n        if area == 0:\n            ann = \"authentic\"\n            stats[\"n_pred_authentic\"] += 1\n        else:\n            ann = rle_json_list(mask)\n            stats[\"n_pred_mask\"] += 1\n            areas.append(area)\n\n        sub_rows.append(dict(case_id=str(cid), annotation=ann))\n\n    if (i0 + BATCH_SIZE) % max(256, BATCH_SIZE*8) == 0:\n        print(f\"[test] {min(i0+BATCH_SIZE, len(uids))}/{len(uids)}\")\n\n    if device.type == \"cuda\":\n        torch.cuda.empty_cache()\n    gc.collect()\n\n# finalize stats\nif len(areas) > 0:\n    stats[\"mean_area_if_mask\"] = float(np.mean(areas))\n    stats[\"median_area_if_mask\"] = float(np.median(areas))\nelse:\n    stats[\"mean_area_if_mask\"] = 0.0\n    stats[\"median_area_if_mask\"] = 0.0\n\n# ----------------------------\n# 6) Build submission.csv aligned to sample_submission order\n# ----------------------------\nsub_df = pd.DataFrame(sub_rows)\nsub_df[\"case_id\"] = sub_df[\"case_id\"].astype(str)\n\n# ensure uniqueness\ndup = sub_df[\"case_id\"].duplicated()\nif dup.any():\n    # keep last (should not happen)\n    sub_df = sub_df.drop_duplicates(\"case_id\", keep=\"last\")\n\n# align to sample submission order\nsub_df = sample_sub[[\"case_id\"]].merge(sub_df, on=\"case_id\", how=\"left\")\n\nif sub_df[\"annotation\"].isna().any():\n    miss = sub_df[sub_df[\"annotation\"].isna()][\"case_id\"].head(20).tolist()\n    raise RuntimeError(f\"Submission missing annotations for {sub_df['annotation'].isna().sum()} case_id. Examples: {miss}\")\n\n# Save\nOUT_SUB = Path(\"/kaggle/working/submission.csv\")\nsub_df.to_csv(OUT_SUB, index=False)\n\nOUT_SUB2 = ART_DIR / \"submission.csv\"\nsub_df.to_csv(OUT_SUB2, index=False)\n\nstats_path = ART_DIR / \"test_pred_stats.json\"\nstats_path.write_text(json.dumps(stats, indent=2))\n\nprint(\"\\n[OK] Saved submission:\")\nprint(\" -\", OUT_SUB)\nprint(\" -\", OUT_SUB2)\nprint(\"Stats:\", stats)\n\n# ----------------------------\n# 7) Paper figures (Stage 7): overlays + output distributions\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\ndef overlay_mask(img_rgb, mask01, alpha=0.45):\n    img = img_rgb.astype(np.float32)/255.0\n    m = mask01.astype(bool)\n    out = img.copy()\n    out[m,0] = (1-alpha)*out[m,0] + alpha*1.0\n    out[m,1] = (1-alpha)*out[m,1] + alpha*0.0\n    out[m,2] = (1-alpha)*out[m,2] + alpha*0.0\n    return (out*255).clip(0,255).astype(np.uint8)\n\ndef show_grid(items, titles=None, ncols=4, figsize=(14,10)):\n    n = len(items)\n    if n == 0:\n        return\n    ncols = min(ncols, n)\n    nrows = int(math.ceil(n / ncols))\n    plt.figure(figsize=figsize)\n    for i, x in enumerate(items):\n        plt.subplot(nrows, ncols, i+1)\n        plt.imshow(x)\n        plt.axis(\"off\")\n        if titles is not None:\n            plt.title(str(titles[i]), fontsize=9)\n    plt.tight_layout()\n\n# Recompute a few overlays for figures (cheap sample)\n# choose 8 samples: some predicted mask, some authentic\npred_mask_ids = sub_df[sub_df[\"annotation\"]!=\"authentic\"][\"case_id\"].head(4).tolist()\npred_auth_ids = sub_df[sub_df[\"annotation\"]==\"authentic\"][\"case_id\"].head(4).tolist()\npick_ids = pred_mask_ids + pred_auth_ids\npick_df = df_test[df_test[\"case_id\"].isin(pick_ids)].head(8)\n\n# Need to regenerate masks for picked ones (safe)\nitems, titles = [], []\nfor _, r in pick_df.iterrows():\n    uid = str(r[\"uid\"])\n    cid = str(r[\"case_id\"])\n    ip = str(r[\"img_path\"])\n\n    im = Image.open(ip).convert(\"RGB\")\n    w, h = im.size\n    img_rgb = np.array(im)\n    gray = np.array(im.convert(\"L\"), dtype=np.float32)\n\n    x = load_token_grid(uid)[None, ...].to(device)\n    with torch.no_grad():\n        p = predict_prob_grid_batch(x).detach().float().cpu().numpy()[0,0]\n    prob_up = upsample_grid_prob(p, w=w, h=h)\n    mask, info = postprocess_prob_to_mask(prob_up, gray, POSTPROCESS_CFG)\n\n    max_side = 640\n    scale = min(1.0, max_side / max(w, h))\n    ww, hh = int(w*scale), int(h*scale)\n    img_v = np.array(Image.fromarray(img_rgb).resize((ww, hh), Image.BICUBIC))\n    mask_v = np.array(Image.fromarray((mask*255).astype(np.uint8)).resize((ww, hh), Image.NEAREST)) > 0\n    ov = overlay_mask(img_v, mask_v.astype(np.uint8), alpha=0.45)\n\n    items.append(ov)\n    titles.append(f\"{cid} | area={int(mask.sum())}\")\n\nshow_grid(items, titles=titles, ncols=4, figsize=(14,8))\nsavefig(FIG_DIR / \"Fig7-1_test_overlays.png\")\n\n# Output distribution plots\nplt.figure(figsize=(6,4))\nplt.bar([\"authentic\", \"mask\"], [stats[\"n_pred_authentic\"], stats[\"n_pred_mask\"]])\nplt.ylabel(\"Count\")\nplt.title(\"Test output distribution\")\nsavefig(FIG_DIR / \"Fig7-2_output_distribution.png\")\n\nif len(areas) > 0:\n    plt.figure(figsize=(6,4))\n    plt.hist(areas, bins=40)\n    plt.xlabel(\"Pred mask area (pixels)\")\n    plt.ylabel(\"Count\")\n    plt.title(\"Pred mask area histogram (non-empty)\")\n    savefig(FIG_DIR / \"Fig7-2_mask_area_hist.png\")\n\nprint(\"[OK] Figures saved to:\", FIG_DIR)\n\n# ----------------------------\n# 8) Keep globals\n# ----------------------------\nglobals().update(dict(\n    submission_df=sub_df,\n    SUBMISSION_PATH=str(OUT_SUB),\n    SUB_STATS=stats,\n))\n# ============================================================\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission Quality Assurance (QA)","metadata":{}},{"cell_type":"code","source":"# ============================================================\n# STAGE 8 — Submission Quality Assurance (QA) (ONE CELL)\n# - Validates submission.csv format + coverage\n# - Checks:\n#   * all case_id present and unique\n#   * annotation is either \"authentic\" OR valid JSON list [start,length,...]\n#   * RLE runs valid (even length, positive lengths, monotonic starts)\n#   * Optional: decode a small sample to ensure dimensions match image sizes\n#\n# Outputs:\n#   /kaggle/working/recodai_luc_prof/artifacts/submission/qa_report.json\n#   /kaggle/working/recodai_luc_prof/artifacts/submission/qa_bad_rows.csv\n#   /kaggle/working/recodai_luc_prof/figures/stage8/Fig8-1_QA_summary.png\n# ============================================================\n\nimport os, json, math, warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------------------\n# 0) Load required artifacts\n# ----------------------------\nPROF_DIR = Path(\"/kaggle/working/recodai_luc_prof\")\npaths_path = PROF_DIR / \"paths.json\"\nif not paths_path.exists():\n    raise RuntimeError(\"Missing paths.json. Run STAGE 0 first.\")\npaths = json.loads(paths_path.read_text())\n\nART_DIR = PROF_DIR / \"artifacts\" / \"submission\"\nART_DIR.mkdir(parents=True, exist_ok=True)\n\nFIG_DIR = PROF_DIR / \"figures\" / \"stage8\"\nFIG_DIR.mkdir(parents=True, exist_ok=True)\n\n# submission\nsub_path = Path(globals().get(\"SUBMISSION_PATH\", \"/kaggle/working/submission.csv\"))\nif not sub_path.exists():\n    sub_path = ART_DIR / \"submission.csv\"\nif not sub_path.exists():\n    raise RuntimeError(\"submission.csv not found. Run STAGE 7 first.\")\nsub_df = pd.read_csv(sub_path)\n\n# sample submission (truth for ordering/coverage)\nsample_sub_path = Path(paths.get(\"SAMPLE_SUBMISSION\", PROF_DIR / \"sample_submission.csv\"))\nif not sample_sub_path.exists():\n    sample_sub_path = PROF_DIR / \"sample_submission.csv\"\nsample_sub = pd.read_csv(sample_sub_path)\nif \"case_id\" not in sample_sub.columns:\n    if \"id\" in sample_sub.columns:\n        sample_sub = sample_sub.rename(columns={\"id\":\"case_id\"})\n    else:\n        raise RuntimeError(\"sample_submission.csv does not contain 'case_id' or 'id'.\")\n\nsample_sub[\"case_id\"] = sample_sub[\"case_id\"].astype(str)\nsub_df[\"case_id\"] = sub_df[\"case_id\"].astype(str)\n\n# test manifest (for optional decode checks)\ndf_test = globals().get(\"df_test\", None)\nif df_test is None:\n    df_test = pd.read_parquet(paths[\"TEST_MANIFEST\"]).copy()\ndf_test[\"case_id\"] = df_test[\"case_id\"].astype(str)\ndf_test[\"img_path\"] = df_test[\"img_path\"].astype(str)\n\nprint(\"Loaded submission:\", sub_path, \"| rows:\", len(sub_df))\nprint(\"Loaded sample_submission rows:\", len(sample_sub))\n\n# ----------------------------\n# 1) Basic schema checks\n# ----------------------------\nrequired_cols = [\"case_id\", \"annotation\"]\nmissing_cols = [c for c in required_cols if c not in sub_df.columns]\nif missing_cols:\n    raise RuntimeError(f\"submission missing columns: {missing_cols}\")\n\nreport = {\n    \"submission_path\": str(sub_path),\n    \"n_rows\": int(len(sub_df)),\n    \"n_expected\": int(len(sample_sub)),\n    \"columns\": list(sub_df.columns),\n    \"errors\": [],\n    \"warnings\": [],\n}\n\n# duplicates\ndup = sub_df[\"case_id\"].duplicated()\nreport[\"duplicate_case_id_count\"] = int(dup.sum())\n\n# coverage vs sample submission\nsub_set = set(sub_df[\"case_id\"].tolist())\nsam_set = set(sample_sub[\"case_id\"].tolist())\nmissing = sorted(list(sam_set - sub_set))\nextra   = sorted(list(sub_set - sam_set))\nreport[\"missing_case_id_count\"] = int(len(missing))\nreport[\"extra_case_id_count\"] = int(len(extra))\nreport[\"missing_case_id_examples\"] = missing[:20]\nreport[\"extra_case_id_examples\"] = extra[:20]\n\nif report[\"missing_case_id_count\"] > 0:\n    report[\"errors\"].append(\"Missing case_id(s) compared to sample_submission.\")\nif report[\"duplicate_case_id_count\"] > 0:\n    report[\"errors\"].append(\"Duplicate case_id(s) detected in submission.\")\nif report[\"extra_case_id_count\"] > 0:\n    report[\"warnings\"].append(\"Extra case_id(s) present beyond sample_submission (usually ignored but not ideal).\")\n\n# reorder check (not error, just note)\nis_same_order = (sub_df[\"case_id\"].tolist() == sample_sub[\"case_id\"].tolist()) if len(sub_df)==len(sample_sub) else False\nreport[\"matches_sample_order\"] = bool(is_same_order)\n\n# ----------------------------\n# 2) Annotation format checks\n# ----------------------------\ndef is_valid_rle_json_list(s):\n    try:\n        runs = json.loads(s)\n        if not isinstance(runs, list):\n            return False, \"not_list\"\n        if len(runs) == 0:\n            return True, \"empty_list_ok\"\n        if len(runs) % 2 != 0:\n            return False, \"odd_length\"\n        # must be ints >= 1 for starts, >=1 for lengths (Kaggle style)\n        prev_start = 0\n        for i in range(0, len(runs), 2):\n            st = runs[i]\n            ln = runs[i+1]\n            if not (isinstance(st, int) and isinstance(ln, int)):\n                return False, \"non_int\"\n            if st < 1 or ln < 1:\n                return False, \"non_positive\"\n            if st < prev_start:\n                return False, \"non_monotonic\"\n            prev_start = st\n        return True, \"ok\"\n    except Exception:\n        return False, \"json_parse_fail\"\n\nbad_rows = []\nn_auth = 0\nn_rle = 0\nn_empty_list = 0\n\nfor idx, r in sub_df.iterrows():\n    ann = r[\"annotation\"]\n    if isinstance(ann, float) and np.isnan(ann):\n        bad_rows.append(dict(case_id=r[\"case_id\"], issue=\"annotation_nan\", annotation=\"\"))\n        continue\n    ann = str(ann)\n    if ann == \"authentic\":\n        n_auth += 1\n        continue\n    ok, reason = is_valid_rle_json_list(ann)\n    if not ok:\n        bad_rows.append(dict(case_id=r[\"case_id\"], issue=f\"bad_rle_{reason}\", annotation=ann[:120]))\n    else:\n        n_rle += 1\n        if reason == \"empty_list_ok\":\n            n_empty_list += 1\n\nreport[\"n_authentic\"] = int(n_auth)\nreport[\"n_rle\"] = int(n_rle)\nreport[\"n_empty_rle_list\"] = int(n_empty_list)\nreport[\"bad_annotation_count\"] = int(len(bad_rows))\n\nif report[\"bad_annotation_count\"] > 0:\n    report[\"errors\"].append(\"Some annotations are not valid ('authentic' or valid JSON RLE list).\")\n\nbad_path = ART_DIR / \"qa_bad_rows.csv\"\npd.DataFrame(bad_rows).to_csv(bad_path, index=False)\nprint(\"Saved bad rows:\", bad_path, \"| rows:\", len(bad_rows))\n\n# ----------------------------\n# 3) Optional decode sanity check (small sample)\n# ----------------------------\n# Decode a handful of RLEs and verify pixel count fits image dimensions.\n# This does not guarantee correctness, but catches obvious indexing errors.\ndef decode_rle_json_list(rle_json, h, w):\n    runs = json.loads(rle_json)\n    mask = np.zeros(h*w, dtype=np.uint8)\n    for i in range(0, len(runs), 2):\n        st = runs[i] - 1  # 1-indexed to 0-indexed\n        ln = runs[i+1]\n        mask[st:st+ln] = 1\n    # reshape back from column-major encoding (we used transpose flatten)\n    mask = mask.reshape((w, h)).T  # invert flatten m.T.flatten\n    return mask\n\ndecode_checks = []\n# take up to 20 masks\nmask_cases = sub_df[sub_df[\"annotation\"]!=\"authentic\"].head(20)\nfor _, rr in mask_cases.iterrows():\n    cid = rr[\"case_id\"]\n    ann = rr[\"annotation\"]\n    # find image\n    m = df_test[df_test[\"case_id\"]==cid]\n    if len(m)==0:\n        decode_checks.append(dict(case_id=cid, ok=False, reason=\"case_id_not_in_test_manifest\"))\n        continue\n    ip = m[\"img_path\"].iloc[0]\n    try:\n        im = Image.open(ip)\n        w, h = im.size\n        mk = decode_rle_json_list(ann, h=h, w=w)\n        ok = (mk.shape[0]==h and mk.shape[1]==w)\n        decode_checks.append(dict(case_id=cid, ok=bool(ok), h=int(h), w=int(w), area=int(mk.sum())))\n    except Exception as e:\n        decode_checks.append(dict(case_id=cid, ok=False, reason=f\"decode_fail: {str(e)[:120]}\"))\n\nreport[\"decode_check_n\"] = int(len(decode_checks))\nreport[\"decode_check_fail_count\"] = int(sum(1 for x in decode_checks if not x.get(\"ok\", False)))\nreport[\"decode_check_examples\"] = [x for x in decode_checks if not x.get(\"ok\", False)][:10]\n\nif report[\"decode_check_fail_count\"] > 0:\n    report[\"warnings\"].append(\"Some RLE decode checks failed (possible encoding/index issue).\")\n\n# ----------------------------\n# 4) Save QA report\n# ----------------------------\nqa_path = ART_DIR / \"qa_report.json\"\nqa_path.write_text(json.dumps(report, indent=2))\nprint(\"Saved QA report:\", qa_path)\nprint(\"QA errors:\", report[\"errors\"])\nprint(\"QA warnings:\", report[\"warnings\"])\n\n# ----------------------------\n# 5) Paper figure: QA summary\n# ----------------------------\nimport matplotlib.pyplot as plt\n\ndef savefig(path, dpi=300):\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    plt.tight_layout()\n    plt.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n    plt.close()\n\nplt.figure(figsize=(7,4))\nplt.bar([\"authentic\", \"rle_mask\"], [report[\"n_authentic\"], report[\"n_rle\"]])\nplt.ylabel(\"Count\")\nplt.title(\"Submission QA: output type counts\")\nsavefig(FIG_DIR / \"Fig8-1_QA_summary.png\")\n\nprint(\"[OK] QA figure saved:\", FIG_DIR / \"Fig8-1_QA_summary.png\")\n\n# ----------------------------\n# 6) Final status print\n# ----------------------------\nif len(report[\"errors\"]) == 0:\n    print(\"\\n[OK] Submission QA PASSED.\")\nelse:\n    print(\"\\n[FAIL] Submission QA found errors. Check qa_report.json and qa_bad_rows.csv.\")\n\n# Keep globals\nglobals().update(dict(\n    QA_REPORT=report,\n    QA_REPORT_PATH=str(qa_path),\n    QA_BAD_ROWS_PATH=str(bad_path),\n))\n# ============================================================\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}